<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Kristine M. Yu - articles</title><link href="http://kmyu.github.io/" rel="alternate"></link><link href="http://kmyu.github.io/feeds/articles.atom.xml" rel="self"></link><id>http://kmyu.github.io/</id><updated>2017-07-03T11:12:00-04:00</updated><entry><title>Supplementary material for article on (in)variability in the Samoan syntax/prosody interface</title><link href="http://kmyu.github.io/blog/supp-material-invariability-samoan-interface.html" rel="alternate"></link><published>2017-07-03T11:12:00-04:00</published><updated>2017-07-03T11:12:00-04:00</updated><author><name>Kristine Yu</name></author><id>tag:kmyu.github.io,2017-07-03:/blog/supp-material-invariability-samoan-interface.html</id><summary type="html">&lt;p&gt;Supplementary material for article on (in)variability in the Samoan syntax/prosody interface&lt;/p&gt;</summary><content type="html">&lt;p&gt;This is supplementary material for &lt;em&gt;(In)variability in the Samoan syntax/prosody interface and consequences for syntactic parsing&lt;/em&gt;. Currently under construction, will be updated!&lt;/p&gt;
&lt;!-- PELICAN_END_SUMMARY --&gt;

&lt;!-- Supplemental data is presented in the following sections: --&gt;

&lt;!-- 1. [Experiments 1/2: Criteria for creak coding](#exp1) --&gt;

&lt;!-- 2. [Experiment 2: Sample perceptual stimuli](#exp2) --&gt;

&lt;!-- 3. [Experiment 3: Sample perceptual stimuli](#exp3) --&gt;

&lt;!-- ##&lt;a id="exp1"&gt;Experiments 1/2: Criteria for coding uttered syllables as "creaky"&lt;/a&gt; ## --&gt;

&lt;!-- The criteria for coding uttered syllables as "creaky" for Experiments --&gt;

&lt;!-- 1 and 2 were given in the paper as follows: --&gt;

&lt;!-- &gt; Target syllables in individual tokens were determined to be creaky by listening and visual inspection of the --&gt;

&lt;!-- &gt; waveform and spectrogram in Praat (Boersma 2010). A token was defined to --&gt;

&lt;!-- &gt; be creaky if it had the auditory percept of creaky voice, as determined --&gt;

&lt;!-- &gt; by the authors and if: --&gt;

&lt;!-- &gt; --&gt;

&lt;!-- &gt; 1.   there were alternating cycles of amplitude and/or frequency or --&gt;

&lt;!-- &gt; irregular glottal pulses in the waveform or wide-band spectrogram, --&gt;

&lt;!-- &gt; 2.   missing values or discontinuities in the f0 track determined by --&gt;

&lt;!-- &gt; Praat's autocorrelation algorithm with default settings[^1], or --&gt;

&lt;!-- &gt; 3.   the appearance of strong subharmonics or lack of harmonic structure in the --&gt;

&lt;!-- &gt; narrow-band spectrogram. Generally these three indicators occurred --&gt;

&lt;!-- &gt; simultaneously. --&gt;

&lt;!-- Below are some samples of implementing the criteria: --&gt;

&lt;!-- 1. Using criteria 1 and 2 --&gt;

&lt;!--    &lt;div align= "left"&gt; --&gt;

&lt;!--     &lt;figure&gt; --&gt;

&lt;!--        &lt;img src="/img/2014/06/cantcr/cant-c11-46-g-s2-criteria.png" --&gt;

&lt;!--     alt = "Fig 1, top left" --&gt;

&lt;!--     width = "800"&gt; --&gt;

&lt;!--     &lt;figcaption&gt;[Click for source wavefile](http://media.krisyu.org/cantcr/exp2-subset-T4/creak/cant_c11_46_g_S2.wav)&lt;/figcaption&gt; --&gt;

&lt;!--     &lt;/figure&gt; --&gt;

&lt;!--     &lt;/div&gt;&lt;p&gt;&lt;/p&gt; --&gt;

&lt;!-- 2. Using criteria 2 and 3 --&gt;

&lt;!--    &lt;div align= "left"&gt; --&gt;

&lt;!--     &lt;figure&gt; --&gt;

&lt;!--        &lt;img src="/img/2014/06/cantcr/cant-c2-16-c-s2-criteria.png" --&gt;

&lt;!--     alt = "Fig 1, top left" --&gt;

&lt;!--     width = "800"&gt; --&gt;

&lt;!--     &lt;figcaption&gt;[Click for source wavefile](http://media.krisyu.org/cantcr/exp2-subset-T4/creak/cant_c2_16_c_S2.wav)&lt;/figcaption&gt; --&gt;

&lt;!--     &lt;/figure&gt; --&gt;

&lt;!--     &lt;/div&gt;&lt;p&gt;&lt;/p&gt; --&gt;

&lt;!-- ##&lt;a id="exp2"&gt;Experiment 2: Sample perceptual stimuli&lt;/a&gt; ## --&gt;

&lt;!-- Note: all sample audio files provided are in WAV format. --&gt;

&lt;!-- These audio files were drawn from in creating perceptual stimuli for --&gt;

&lt;!-- Experiment 2. The subset provided below was used in creating the Tone --&gt;

&lt;!-- 4 stimuli. --&gt;

&lt;!-- 1. Play Tone 4 stimuli coded as "creaky": [[wav](http://media.krisyu.org/cantcr/exp2-subset-T4/all-creak-files.wav)] --&gt;

&lt;!-- 2. Play Tone 4 stimuli coded as "non-creaky": [[wav](http://media.krisyu.org/cantcr/exp2-subset-T4/all-noncreak-files.wav)] --&gt;

&lt;!-- 3. Zipped archives of wav files: [[creaky](http://media.krisyu.org/cantcr/exp2-subset-T4/creak.zip)], [[non-creaky](http://media.krisyu.org/cantcr/exp2-subset-T4/noncreak.zip)] --&gt;

&lt;!-- ##&lt;a id="exp3"&gt;Experiment 3: Sample perceptual stimuli&lt;/a&gt; ## --&gt;

&lt;!-- Note: all sample audio files provided are in WAV format and are the --&gt;

&lt;!-- resynthesized stimuli for "0" f0 shift, in the monosyllabic experiment --&gt;

&lt;!-- (no preceding syllable). --&gt;

&lt;!-- 1. **Sex**: female, **creak type**: narrow [[light](http://media.krisyu.org/cantcr/exp3-wavs/female-narrow-light.wav), [medium](http://media.krisyu.org/cantcr/exp3-wavs/female-narrow-medium.wav), [heavy](http://media.krisyu.org/cantcr/exp3-wavs/female-narrow-heavy.wav)] --&gt;

&lt;!-- 1. **Sex**: female, **creak type**: wide [[light](http://media.krisyu.org/cantcr/exp3-wavs/female-wide-light.wav), [medium](http://media.krisyu.org/cantcr/exp3-wavs/female-wide-medium.wav), [heavy](http://media.krisyu.org/cantcr/exp3-wavs/female-wide-heavy.wav)] --&gt;

&lt;!-- 1. **Sex**: male, **creak type**: narrow [[light](http://media.krisyu.org/cantcr/exp3-wavs/male-narrow-light.wav), [medium](http://media.krisyu.org/cantcr/exp3-wavs/male-narrow-medium.wav), [heavy](http://media.krisyu.org/cantcr/exp3-wavs/male-narrow-heavy.wav)] --&gt;

&lt;!-- 1. **Sex**: male, **creak type**: wide [[light](http://media.krisyu.org/cantcr/exp3-wavs/male-wide-light.wav), [medium](http://media.krisyu.org/cantcr/exp3-wavs/male-wide-medium.wav), [heavy](http://media.krisyu.org/cantcr/exp3-wavs/male-wide-heavy.wav)] --&gt;

&lt;!-- ### Sources for Figures 1 and 2 in paper: --&gt;

&lt;!-- 1. **Figure 1: waveforms** --&gt;

&lt;!--     + (top left) sex: female, creak type: narrow, creak proportion: heavy --&gt;

&lt;!--    &lt;div align= "left"&gt; --&gt;

&lt;!--     &lt;figure&gt; --&gt;

&lt;!--        &lt;img src="/img/2014/06/cantcr/fig1a.png" --&gt;

&lt;!--     alt = "Fig 1, top left" --&gt;

&lt;!--     width = "600"&gt; --&gt;

&lt;!--     &lt;figcaption&gt;[Click for source wavefile](http://media.krisyu.org/cantcr/exp3-wavs/female-narrow-heavy.wav)&lt;/figcaption&gt; --&gt;

&lt;!--     &lt;/figure&gt; --&gt;

&lt;!--     &lt;/div&gt;&lt;p&gt;&lt;/p&gt; --&gt;

&lt;!--     + (top right) sex: male, creak type: narrow, creak proportion: heavy --&gt;

&lt;!--    &lt;div align= "left"&gt; --&gt;

&lt;!--     &lt;figure&gt; --&gt;

&lt;!--        &lt;img src="/img/2014/06/cantcr/fig1a.png" --&gt;

&lt;!--     alt = "Fig 1, top right" --&gt;

&lt;!--     width = "600"&gt; --&gt;

&lt;!--     &lt;figcaption&gt;[Click for source wavefile](http://media.krisyu.org/cantcr/exp3-wavs/male-narrow-heavy.wav)&lt;/figcaption&gt; --&gt;

&lt;!--     &lt;/figure&gt; --&gt;

&lt;!--     &lt;/div&gt;&lt;p&gt;&lt;/p&gt; --&gt;

&lt;!--     + (bottom left) sex: female, creak type: wide, creak proportion: heavy --&gt;

&lt;!--    &lt;div align= "left"&gt; --&gt;

&lt;!--     &lt;figure&gt; --&gt;

&lt;!--        &lt;img src="/img/2014/06/cantcr/fig1a.png" --&gt;

&lt;!--     alt = "Fig 1, bottom left" --&gt;

&lt;!--     width = "600"&gt; --&gt;

&lt;!--     &lt;figcaption&gt;[Click for source wavefile](http://media.krisyu.org/cantcr/exp3-wavs/female-wide-heavy.wav)&lt;/figcaption&gt; --&gt;

&lt;!--     &lt;/figure&gt; --&gt;

&lt;!--     &lt;/div&gt;&lt;p&gt;&lt;/p&gt; --&gt;

&lt;!--    + (bottom right) sex: male, creak type: wide, creak proportion: heavy  --&gt;

&lt;!--    &lt;div align= "left"&gt; --&gt;

&lt;!--     &lt;figure&gt; --&gt;

&lt;!--        &lt;img src="/img/2014/06/cantcr/fig1a.png" --&gt;

&lt;!--     alt = "Fig 1, bottom right" --&gt;

&lt;!--     width = "600"&gt; --&gt;

&lt;!--     &lt;figcaption&gt;[Click for source wavefile](http://media.krisyu.org/cantcr/exp3-wavs/male-wide-heavy.wav)&lt;/figcaption&gt; --&gt;

&lt;!--     &lt;/figure&gt; --&gt;

&lt;!--     &lt;/div&gt;&lt;p&gt;&lt;/p&gt; --&gt;

&lt;!-- 2. **Figure 2: spectrograms** --&gt;

&lt;!--     + (left) sex: female, creak type: narrow, creak proportion: heavy --&gt;

&lt;!--    &lt;div align= "left"&gt; --&gt;

&lt;!--     &lt;figure&gt; --&gt;

&lt;!--        &lt;img src="/img/2014/06/cantcr/fig2a.png" --&gt;

&lt;!--     alt = "Fig 2, left" --&gt;

&lt;!--     width = "600"&gt; --&gt;

&lt;!--     &lt;figcaption&gt;[Click for source wavefile](http://media.krisyu.org/cantcr/exp3-wavs/female-narrow-heavy.wav)&lt;/figcaption&gt; --&gt;

&lt;!--     &lt;/figure&gt; --&gt;

&lt;!--     &lt;/div&gt;&lt;p&gt;&lt;/p&gt; --&gt;

&lt;!--     + (right) sex: female, creak type: pitched, creak proportion: heavy --&gt;

&lt;!--    &lt;div align= "left"&gt; --&gt;

&lt;!--     &lt;figure&gt; --&gt;

&lt;!--        &lt;img src="/img/2014/06/cantcr/fig2b.png" --&gt;

&lt;!--     alt = "Fig 2, right" --&gt;

&lt;!--     width = "600"&gt; --&gt;

&lt;!--     &lt;figcaption&gt;[Click for source wavefile](http://media.krisyu.org/cantcr/exp3-wavs/female-pitched-heavy.wav)&lt;/figcaption&gt; --&gt;

&lt;!--     &lt;/figure&gt; --&gt;

&lt;!--     &lt;/div&gt;&lt;p&gt;&lt;/p&gt; --&gt;

&lt;!-- [^1]: silence threshold = 0.03, voicing threshold = 0.45, octave cost = 0.01, octave-jump cost = 0.35, voiced/unvoiced cost = 0.14 --&gt;</content><category term="Samoan"></category><category term="supplementary-material"></category><category term="media"></category></entry><entry><title>Revised pelican-bootstrap3, github pages hosted website</title><link href="http://kmyu.github.io/blog/revised-pelican-website.html" rel="alternate"></link><published>2016-04-02T20:41:00-04:00</published><updated>2016-04-02T20:41:00-04:00</updated><author><name>Kristine M. Yu</name></author><id>tag:kmyu.github.io,2016-04-02:/blog/revised-pelican-website.html</id><summary type="html">&lt;p&gt;Brief note on resources used for revising website to use pelican-bootstrap3 and be hosted on Github Pages&lt;/p&gt;</summary><content type="html">&lt;p&gt;Thanks to the following tutorials:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://mathamy.com/migrating-to-github-pages-using-pelican.html"&gt;Amy Hanlon&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://seanazlin.com/creating-a-blog-on-GitHub-dot-io-with-Python.html"&gt;Sean Azlin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://beneathdata.com/how-to/how-i-built-this-website/"&gt;Tyler Hartley&lt;/a&gt;
and his &lt;a href="https://github.com/tylerhartley/beneathdata"&gt;github repository&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://docs.getpelican.com/en/3.6.3/tips.html#publishing-to-github"&gt;Pelican documentation for publishing to github&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I've been able to update my website to use a Bootstrap 3 theme for Pelican,
&lt;a href="https://github.com/DandyDev/pelican-bootstrap3"&gt;pelican-bootstrap3&lt;/a&gt;,
and hosted on GitHub.io.&lt;/p&gt;
&lt;h2 id="further-notes-on-using-custom-domain-with-github-user-page"&gt;Further notes on using custom domain with Github user page&lt;/h2&gt;
&lt;p&gt;In case this is helpful to anyone, because this was tricky, here are
some instructions on &lt;a href="https://help.github.com/articles/setting-up-an-apex-domain-and-www-subdomain/"&gt;how to set up an apex and &lt;code&gt;www&lt;/code&gt; sub-domain with a
Github user page&lt;/a&gt;,
see also &lt;a href="https://help.github.com/articles/quick-start-setting-up-a-custom-domain/"&gt;GitHub quickstart guide for setting up a custom domain&lt;/a&gt;. My
apex domain is &lt;code&gt;krisyu.org&lt;/code&gt;. My &lt;code&gt;www&lt;/code&gt; sub-domain is
&lt;code&gt;www.krisyu.org&lt;/code&gt;. I host my website with DreamHost.&lt;/p&gt;
&lt;p&gt;After
you've followed the directions under &lt;em&gt;User Pages&lt;/em&gt; in the
&lt;a href="http://docs.getpelican.com/en/3.6.3/tips.html#publishing-to-github"&gt;Pelican documentation for publishing to github&lt;/a&gt;,
do the following: &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Create a &lt;code&gt;content/extra&lt;/code&gt; directory, and create a &lt;code&gt;CNAME&lt;/code&gt; file in
   this directory with just the custom domain; then make sure to
   modify &lt;code&gt;pelicanconf.py&lt;/code&gt; static path settings to tell Pelican to
   copy this file to output.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;My &lt;code&gt;CNAME&lt;/code&gt; file in &lt;code&gt;content/extra&lt;/code&gt; is
   &lt;a href="https://github.com/krismyu/website-repo/blob/master/content/extra/CNAME"&gt;here&lt;/a&gt;. &lt;/li&gt;
&lt;li&gt;My &lt;code&gt;CNAME&lt;/code&gt; file in the &lt;code&gt;output&lt;/code&gt; generated by Pelican is in the
   root directory &lt;a href="https://github.com/krismyu/krismyu.github.io/blob/master/CNAME"&gt;here&lt;/a&gt;. &lt;/li&gt;
&lt;li&gt;See more in Tip 2 under &lt;em&gt;Extra Tips&lt;/em&gt; in
&lt;a href="http://docs.getpelican.com/en/3.6.3/tips.html#publishing-to-github"&gt;Pelican documentation for publishing to github&lt;/a&gt;,
which has this example modification to &lt;code&gt;pelicanconf.py&lt;/code&gt;:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;STATIC_PATHS = ['images', 'extra/CNAME']
   EXTRA_PATH_METADATA = {'extra/CNAME': {'path': 'CNAME'},}&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Confirm that your Github user page is being published to your
   custom domain.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;See `Confirming your custom domain setup on GitHub at the bottom
 of
 &lt;a href="https://help.github.com/articles/setting-up-your-pages-site-repository/"&gt;this page&lt;/a&gt;. &lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In the settings of my repository
   &lt;a href="https://github.com/krismyu/krismyu.github.io"&gt;krismyu.github.io&lt;/a&gt;,
   it says, under &lt;code&gt;GitHub Pages&lt;/code&gt;,&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Your site is published at http://www.krisyu.org.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://help.github.com/articles/setting-up-an-apex-domain/"&gt;Configure an &lt;code&gt;ANAME&lt;/code&gt; record with your DNS provider&lt;/a&gt;
   (for me, DreamHost).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Set hosting preferences for the apex domain to DNS only (no web
   hosting), for DreamHost, under &lt;code&gt;Manage Domains&lt;/code&gt;, (hat tip
   &lt;a href="https://github.com/imathis/octopress/issues/518"&gt;here&lt;/a&gt;, from
   &lt;code&gt;Abizern&lt;/code&gt;, also
   &lt;a href="https://discussion.dreamhost.com/thread-136634.html"&gt;here&lt;/a&gt; from
   Andrew F).&lt;/li&gt;
&lt;li&gt;Under &lt;code&gt;Manage Domains&lt;/code&gt; click on &lt;code&gt;DNS&lt;/code&gt; for the apex domain. In the
 section &lt;code&gt;Add a custom DNS record to your-apex-domain&lt;/code&gt;, leave
 &lt;code&gt;Name&lt;/code&gt; field blank, and then type in the first IP address provided by
 &lt;a href="https://help.github.com/articles/setting-up-an-apex-domain/"&gt;Github documentation&lt;/a&gt;
 in the section &lt;strong&gt;Configuring &lt;code&gt;A&lt;/code&gt; records with your DNS provider&lt;/strong&gt;
 in the &lt;code&gt;Value&lt;/code&gt; field and click on &lt;code&gt;Add Record Now!&lt;/code&gt;. Do the same
 thing with the second IP address provided in the documentation.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://help.github.com/articles/setting-up-a-www-subdomain/"&gt;Configure a &lt;code&gt;CNAME&lt;/code&gt; record with your DNS provider&lt;/a&gt;
   (for me, Dreamhost).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Make sure that your sub-domain is not registered! Under
 &lt;code&gt;Registrations&lt;/code&gt;, if you see your sub-domain registered, delete it.
 (If you don't do this, you'll get a &lt;code&gt;Not Found&lt;/code&gt; error when you
 visit your apex or sub-domain.)&lt;/li&gt;
&lt;li&gt;Then add a &lt;code&gt;CNAME&lt;/code&gt; file for your sub-domain, following the
 instructions from
 &lt;a href="https://help.github.com/articles/setting-up-a-www-subdomain/"&gt;GitHub documentation&lt;/a&gt;. For
 Dreamhost, under &lt;code&gt;Manage Domains&lt;/code&gt; click on &lt;code&gt;DNS&lt;/code&gt; for the www
 sub-domain. In the section &lt;code&gt;Add a custom DNS record to
 your-apex-domain&lt;/code&gt;, fill in &lt;code&gt;www&lt;/code&gt; in the &lt;code&gt;Name&lt;/code&gt; filed, and type
 &lt;code&gt;YOUR-GITHUB-USERNAME.github.io.&lt;/code&gt; in &lt;code&gt;Value&lt;/code&gt;,
 e.g. &lt;code&gt;krismyu.github.io.&lt;/code&gt; You must have that trailing period.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Check that your DNS record is set up correctly using &lt;code&gt;dig&lt;/code&gt;, see
   Step 4 for GitHub documentation for
   &lt;a href="https://help.github.com/articles/setting-up-an-apex-domain/"&gt;setting up an apex domain&lt;/a&gt;
   and also for
   &lt;a href="https://help.github.com/articles/setting-up-a-www-subdomain/"&gt;setting up a www sub-domain&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Here's an example of the output I got from &lt;code&gt;dig&lt;/code&gt; before the changes I made to
 the DNS entries propagated, for &lt;code&gt;www.krisyu.org&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;~/web/website&lt;span class="o"&gt;(&lt;/span&gt;master&lt;span class="o"&gt;)&lt;/span&gt; $ dig www.krisyu.org +nostats +nocomments +nocmd

&lt;span class="p"&gt;;&lt;/span&gt; &amp;lt;&amp;lt;&amp;gt;&amp;gt; DiG &lt;span class="m"&gt;9&lt;/span&gt;.8.3-P1 &amp;lt;&amp;lt;&amp;gt;&amp;gt; www.krisyu.org +nostats +nocomments +nocmd
&lt;span class="p"&gt;;;&lt;/span&gt; global options: +cmd
&lt;span class="p"&gt;;&lt;/span&gt;www.krisyu.org.            IN  A
www.krisyu.org.     &lt;span class="m"&gt;10463&lt;/span&gt;   IN  A   &lt;span class="m"&gt;208&lt;/span&gt;.113.172.21
~/web/website&lt;span class="o"&gt;(&lt;/span&gt;master&lt;span class="o"&gt;)&lt;/span&gt; $ dig www.krisyu.org +nostats +nocomments +nocmd
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Here's the output I get from these commands now that the changes
I made to the DNS entries has propagated, for &lt;code&gt;krisyu.org&lt;/code&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;~/web/website&lt;span class="o"&gt;(&lt;/span&gt;master *&lt;span class="o"&gt;)&lt;/span&gt; $ dig krisyu.org +nostats +nocomments +nocmd

&lt;span class="p"&gt;;&lt;/span&gt; &amp;lt;&amp;lt;&amp;gt;&amp;gt; DiG &lt;span class="m"&gt;9&lt;/span&gt;.8.3-P1 &amp;lt;&amp;lt;&amp;gt;&amp;gt; krisyu.org +nostats +nocomments +nocmd
&lt;span class="p"&gt;;;&lt;/span&gt; global options: +cmd
&lt;span class="p"&gt;;&lt;/span&gt;krisyu.org.            IN  A
krisyu.org.     &lt;span class="m"&gt;14400&lt;/span&gt;   IN  A   &lt;span class="m"&gt;192&lt;/span&gt;.30.252.154
krisyu.org.     &lt;span class="m"&gt;14400&lt;/span&gt;   IN  A   &lt;span class="m"&gt;192&lt;/span&gt;.30.252.153
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Here's the output I get from these commands now that the changes
I made to the DNS entries have propagated, for &lt;code&gt;www.krisyu.org&lt;/code&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;~/web/website&lt;span class="o"&gt;(&lt;/span&gt;master *&lt;span class="o"&gt;)&lt;/span&gt; $ dig www.krisyu.org +nostats +nocomments +nocmd

&lt;span class="p"&gt;;&lt;/span&gt; &amp;lt;&amp;lt;&amp;gt;&amp;gt; DiG &lt;span class="m"&gt;9&lt;/span&gt;.8.3-P1 &amp;lt;&amp;lt;&amp;gt;&amp;gt; www.krisyu.org +nostats +nocomments +nocmd
&lt;span class="p"&gt;;;&lt;/span&gt; global options: +cmd
&lt;span class="p"&gt;;&lt;/span&gt;www.krisyu.org.            IN  A
www.krisyu.org.     &lt;span class="m"&gt;14400&lt;/span&gt;   IN  CNAME   krismyu.github.io.
krismyu.github.io.  &lt;span class="m"&gt;3600&lt;/span&gt;    IN  CNAME   github.map.fastly.net.
github.map.fastly.net.  &lt;span class="m"&gt;2&lt;/span&gt;   IN  A   &lt;span class="m"&gt;23&lt;/span&gt;.235.39.133
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;It may take some time, on the order of hours or more, for the
   changes you made to the DNS entries to propagate. You can check the
   status of propagation across the globe for your domains &lt;a href="http://viewdns.info/propagation/"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;</content><category term="pelican"></category></entry><entry><title>Supplementary material for article on creak in Cantonese tone perception</title><link href="http://kmyu.github.io/blog/supp-material-cantonese-creak-perception.html" rel="alternate"></link><published>2014-06-08T11:12:00-04:00</published><updated>2014-06-08T11:12:00-04:00</updated><author><name>Kristine Yu</name></author><id>tag:kmyu.github.io,2014-06-08:/blog/supp-material-cantonese-creak-perception.html</id><summary type="html">&lt;p&gt;Sample audio files for Cantonese creak manuscript&lt;/p&gt;</summary><content type="html">&lt;p&gt;This is supplemental material for &lt;em&gt;The role of creaky voice in
Cantonese tone perception&lt;/em&gt;. It includes sample wavefiles from
perceptual stimuli for Experiment 2, for creaky and non-creaky Tone 4
exemplars. We also use a few of these wavefiles to demonstrate
criteria for coding a token file as creaky or not creaky (Experiment
1, 2). Finally, we include sample wavefiles from the perceptual experiment,
Experiment 3. &lt;/p&gt;
&lt;!-- PELICAN_END_SUMMARY --&gt;

&lt;p&gt;Supplemental data is presented in the following sections:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="#exp1"&gt;Experiments 1/2: Criteria for creak coding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#exp2"&gt;Experiment 2: Sample perceptual stimuli&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#exp3"&gt;Experiment 3: Sample perceptual stimuli&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="wzxhzdk1experiments-12-criteria-for-coding-uttered-syllables-as-creakywzxhzdk2"&gt;&lt;a id="exp1"&gt;Experiments 1/2: Criteria for coding uttered syllables as "creaky"&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The criteria for coding uttered syllables as "creaky" for Experiments
1 and 2 were given in the paper as follows:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Target syllables in individual tokens were determined to be creaky by listening and visual inspection of the
waveform and spectrogram in Praat (Boersma 2010). A token was defined to
be creaky if it had the auditory percept of creaky voice, as determined
by the authors and if:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;there were alternating cycles of amplitude and/or frequency or
irregular glottal pulses in the waveform or wide-band spectrogram,&lt;/li&gt;
&lt;li&gt;missing values or discontinuities in the f0 track determined by
Praat's autocorrelation algorithm with default settings&lt;sup id="fnref-1"&gt;&lt;a class="footnote-ref" href="#fn-1"&gt;1&lt;/a&gt;&lt;/sup&gt;, or&lt;/li&gt;
&lt;li&gt;the appearance of strong subharmonics or lack of harmonic structure in the
narrow-band spectrogram. Generally these three indicators occurred
simultaneously.&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;Below are some samples of implementing the criteria:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Using criteria 1 and 2&lt;/p&gt;
&lt;p&gt;&lt;div align= "left"&gt;
&lt;figure&gt;
&lt;img src="/img/2014/06/cantcr/cant-c11-46-g-s2-criteria.png"
alt = "Fig 1, top left"
width = "800"&gt;
&lt;figcaption&gt;&lt;a href="http://media.krisyu.org/cantcr/exp2-subset-T4/creak/cant_c11_46_g_S2.wav"&gt;Click for source wavefile&lt;/a&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Using criteria 2 and 3&lt;/p&gt;
&lt;p&gt;&lt;div align= "left"&gt;
&lt;figure&gt;
&lt;img src="/img/2014/06/cantcr/cant-c2-16-c-s2-criteria.png"
alt = "Fig 1, top left"
width = "800"&gt;
&lt;figcaption&gt;&lt;a href="http://media.krisyu.org/cantcr/exp2-subset-T4/creak/cant_c2_16_c_S2.wav"&gt;Click for source wavefile&lt;/a&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="wzxhzdk3experiment-2-sample-perceptual-stimuliwzxhzdk4"&gt;&lt;a id="exp2"&gt;Experiment 2: Sample perceptual stimuli&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Note: all sample audio files provided are in WAV format.&lt;/p&gt;
&lt;p&gt;These audio files were drawn from in creating perceptual stimuli for
Experiment 2. The subset provided below was used in creating the Tone
4 stimuli.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Play Tone 4 stimuli coded as "creaky": [&lt;a href="http://media.krisyu.org/cantcr/exp2-subset-T4/all-creak-files.wav"&gt;wav&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Play Tone 4 stimuli coded as "non-creaky": [&lt;a href="http://media.krisyu.org/cantcr/exp2-subset-T4/all-noncreak-files.wav"&gt;wav&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;Zipped archives of wav files: [&lt;a href="http://media.krisyu.org/cantcr/exp2-subset-T4/creak.zip"&gt;creaky&lt;/a&gt;], [&lt;a href="http://media.krisyu.org/cantcr/exp2-subset-T4/noncreak.zip"&gt;non-creaky&lt;/a&gt;]&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="wzxhzdk5experiment-3-sample-perceptual-stimuliwzxhzdk6"&gt;&lt;a id="exp3"&gt;Experiment 3: Sample perceptual stimuli&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Note: all sample audio files provided are in WAV format and are the
resynthesized stimuli for "0" f0 shift, in the monosyllabic experiment
(no preceding syllable).&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Sex&lt;/strong&gt;: female, &lt;strong&gt;creak type&lt;/strong&gt;: narrow [&lt;a href="http://media.krisyu.org/cantcr/exp3-wavs/female-narrow-light.wav"&gt;light&lt;/a&gt;, &lt;a href="http://media.krisyu.org/cantcr/exp3-wavs/female-narrow-medium.wav"&gt;medium&lt;/a&gt;, &lt;a href="http://media.krisyu.org/cantcr/exp3-wavs/female-narrow-heavy.wav"&gt;heavy&lt;/a&gt;]&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Sex&lt;/strong&gt;: female, &lt;strong&gt;creak type&lt;/strong&gt;: wide [&lt;a href="http://media.krisyu.org/cantcr/exp3-wavs/female-wide-light.wav"&gt;light&lt;/a&gt;, &lt;a href="http://media.krisyu.org/cantcr/exp3-wavs/female-wide-medium.wav"&gt;medium&lt;/a&gt;, &lt;a href="http://media.krisyu.org/cantcr/exp3-wavs/female-wide-heavy.wav"&gt;heavy&lt;/a&gt;]&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Sex&lt;/strong&gt;: male, &lt;strong&gt;creak type&lt;/strong&gt;: narrow [&lt;a href="http://media.krisyu.org/cantcr/exp3-wavs/male-narrow-light.wav"&gt;light&lt;/a&gt;, &lt;a href="http://media.krisyu.org/cantcr/exp3-wavs/male-narrow-medium.wav"&gt;medium&lt;/a&gt;, &lt;a href="http://media.krisyu.org/cantcr/exp3-wavs/male-narrow-heavy.wav"&gt;heavy&lt;/a&gt;]&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Sex&lt;/strong&gt;: male, &lt;strong&gt;creak type&lt;/strong&gt;: wide [&lt;a href="http://media.krisyu.org/cantcr/exp3-wavs/male-wide-light.wav"&gt;light&lt;/a&gt;, &lt;a href="http://media.krisyu.org/cantcr/exp3-wavs/male-wide-medium.wav"&gt;medium&lt;/a&gt;, &lt;a href="http://media.krisyu.org/cantcr/exp3-wavs/male-wide-heavy.wav"&gt;heavy&lt;/a&gt;]&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="sources-for-figures-1-and-2-in-paper"&gt;Sources for Figures 1 and 2 in paper:&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Figure 1: waveforms&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;(top left) sex: female, creak type: narrow, creak proportion: heavy&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;div align= "left"&gt;
&lt;figure&gt;
&lt;img src="/img/2014/06/cantcr/fig1a.png"
alt = "Fig 1, top left"
width = "600"&gt;
&lt;figcaption&gt;&lt;a href="http://media.krisyu.org/cantcr/exp3-wavs/female-narrow-heavy.wav"&gt;Click for source wavefile&lt;/a&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;(top right) sex: male, creak type: narrow, creak proportion: heavy&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;div align= "left"&gt;
&lt;figure&gt;
&lt;img src="/img/2014/06/cantcr/fig1a.png"
alt = "Fig 1, top right"
width = "600"&gt;
&lt;figcaption&gt;&lt;a href="http://media.krisyu.org/cantcr/exp3-wavs/male-narrow-heavy.wav"&gt;Click for source wavefile&lt;/a&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;(bottom left) sex: female, creak type: wide, creak proportion: heavy&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;div align= "left"&gt;
&lt;figure&gt;
&lt;img src="/img/2014/06/cantcr/fig1a.png"
alt = "Fig 1, bottom left"
width = "600"&gt;
&lt;figcaption&gt;&lt;a href="http://media.krisyu.org/cantcr/exp3-wavs/female-wide-heavy.wav"&gt;Click for source wavefile&lt;/a&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;(bottom right) sex: male, creak type: wide, creak proportion: heavy &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;div align= "left"&gt;
&lt;figure&gt;
&lt;img src="/img/2014/06/cantcr/fig1a.png"
alt = "Fig 1, bottom right"
width = "600"&gt;
&lt;figcaption&gt;&lt;a href="http://media.krisyu.org/cantcr/exp3-wavs/male-wide-heavy.wav"&gt;Click for source wavefile&lt;/a&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Figure 2: spectrograms&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;(left) sex: female, creak type: narrow, creak proportion: heavy&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;div align= "left"&gt;
&lt;figure&gt;
&lt;img src="/img/2014/06/cantcr/fig2a.png"
alt = "Fig 2, left"
width = "600"&gt;
&lt;figcaption&gt;&lt;a href="http://media.krisyu.org/cantcr/exp3-wavs/female-narrow-heavy.wav"&gt;Click for source wavefile&lt;/a&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;(right) sex: female, creak type: pitched, creak proportion: heavy&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;div align= "left"&gt;
&lt;figure&gt;
&lt;img src="/img/2014/06/cantcr/fig2b.png"
alt = "Fig 2, right"
width = "600"&gt;
&lt;figcaption&gt;&lt;a href="http://media.krisyu.org/cantcr/exp3-wavs/female-pitched-heavy.wav"&gt;Click for source wavefile&lt;/a&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn-1"&gt;
&lt;p&gt;silence threshold = 0.03, voicing threshold = 0.45, octave cost = 0.01, octave-jump cost = 0.35, voiced/unvoiced cost = 0.14&amp;#160;&lt;a class="footnote-backref" href="#fnref-1" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="Cantonese"></category><category term="supplementary-material"></category><category term="media"></category></entry><entry><title>Additional examples of elicitation designs</title><link href="http://kmyu.github.io/blog/additional-examples-of-elicitation-designs.html" rel="alternate"></link><published>2013-10-31T11:12:00-04:00</published><updated>2013-10-31T11:12:00-04:00</updated><author><name>Kristine Yu</name></author><id>tag:kmyu.github.io,2013-10-31:/blog/additional-examples-of-elicitation-designs.html</id><summary type="html">&lt;p&gt;This is supplemental material for &lt;em&gt;The experimental state of mind in
elicitation: illustrations from tonal fieldwork&lt;/em&gt; that follows up on
Section 2.4, which recast Hyman (2007)'s work on tonotactics in
Thlantlang Lai in terms of experimental design. It introduces additional examples of using 
experimental design principles to generalize …&lt;/p&gt;</summary><content type="html">&lt;p&gt;This is supplemental material for &lt;em&gt;The experimental state of mind in
elicitation: illustrations from tonal fieldwork&lt;/em&gt; that follows up on
Section 2.4, which recast Hyman (2007)'s work on tonotactics in
Thlantlang Lai in terms of experimental design. It introduces additional examples of using 
experimental design principles to generalize to elicitation methods
beyond Pike's toneme discovery procedure.&lt;/p&gt;
&lt;!-- PELICAN_END_SUMMARY --&gt;

&lt;p&gt;These examples are divided into the following sections:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="#levels"&gt;Coarsening and refining variable levels&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#sec:gen-question"&gt;Generalizing to different research questions&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;A &lt;a href="#references"&gt;references&lt;/a&gt; section follows.&lt;/p&gt;
&lt;h2 id="levels"&gt;Coarsening and refining variable levels&lt;/h2&gt;
&lt;p&gt;One way to generalize beyond Pike's toneme discovery procedure is to
&lt;strong&gt;generalize beyond the set of variables under consideration.&lt;/strong&gt; In
addition to considering other independent variables---explanatory
as well as confounding variables--another way to generalize the set of
variables is if we don’t add any new variables, but we &lt;em&gt;change&lt;/em&gt;
the definition of some of the variables. We could do this in such a
way so that a re-defined variable is incomparable to the old one. For
instance, we could change the levels for a factor SEGMENT from voiced and voiceless to singleton, geminate, and
supergeminate. But there is no subset/superset relation between the
original levels and the new ones, and this kind of re-defining a
variable is effectively the same as adding a new variable.&lt;/p&gt;
&lt;p&gt;There are also two ways we could redefine a variable so that
is still comparable:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Coarsening the partition of the possible instantiations of the
    variable (increasing the number of levels of the variable)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Refining the partition of the possible instantiations of the
    variable (decreasing the number of levels of the variable)&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;When we coarsen the partition, we reduce the number of levels for a
variable, merging levels with one another. When we refine the partition,
we increase the number of levels for a variable, splitting levels. We
might also both coarsen and refine in re-defining a variable.&lt;/p&gt;
&lt;p&gt;One example of coarsening the partition is given in the table below. This is adapted from the study of contextual tonal
variation in Mandarin in Xu (1997, p. 70). The explanatory variable of
tonal class of the target syllable had 4 levels, following the 4-way
tonal contrast in Mandarin (abstracting away from the neutral fifth
tone). However, the explanatory variable of the pre-target tone,
i.e., the tone class of the syllable preceding the target syllable,
collapsed the 4-way distinction for Mandarin tonal classes into a 2-way
distinction based on the tonal offset: both Tone 1, a high tone, and
Tone 2, a rise, were classified as having a high offset, and both Tone 3
(low) and 4 (fall) were classified as having a low offset. In
autosegmental-theoretic terms (Goldsmith 1990, Goldsmith 1976), one
might say that the new variable assumes that contour tones are treated
as tonal sequences (fall = HL, rise = LH) and pays attention only to the
tone at the right edge of the syllable.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Tone&lt;/th&gt;
&lt;th&gt;Old level&lt;/th&gt;
&lt;th&gt;Mapping&lt;/th&gt;
&lt;th&gt;New level&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Tone 1&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;High $\mapsto$ H&lt;/td&gt;
&lt;td&gt;H&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Tone 2&lt;/td&gt;
&lt;td&gt;Rise&lt;/td&gt;
&lt;td&gt;Rise $\mapsto$ H&lt;/td&gt;
&lt;td&gt;H&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Tone 3&lt;/td&gt;
&lt;td&gt;Low&lt;/td&gt;
&lt;td&gt;Low $\mapsto$ L&lt;/td&gt;
&lt;td&gt;L&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Tone 4&lt;/td&gt;
&lt;td&gt;Fall&lt;/td&gt;
&lt;td&gt;Fall $\mapsto$ L&lt;/td&gt;
&lt;td&gt;L&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Another example of coarsening the partition defined by a variable comes
from Keating (2011), a cross-linguistic study of the acoustic parameters
involved in distinguishing phonation types. Here, for the purposes of
standardization for comparison with other languages, the 7-way tonal
contrast in the White Hmong data from Esposito (2012)
was coarsened into a 3-way contrast capturing the rough location of the
tone within the pitch range—either high, mid, or low—for the same data,
for the purposes of the cross-linguistic comparison in Keating (2011),
see the table below:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Tone&lt;/th&gt;
&lt;th&gt;Old level&lt;/th&gt;
&lt;th&gt;Mapping&lt;/th&gt;
&lt;th&gt;New level&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;b-tone&lt;/td&gt;
&lt;td&gt;High-rising&lt;/td&gt;
&lt;td&gt;High-rising $\mapsto$ H&lt;/td&gt;
&lt;td&gt;H&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;null-tone&lt;/td&gt;
&lt;td&gt;Mid&lt;/td&gt;
&lt;td&gt;Mid $\mapsto$ M&lt;/td&gt;
&lt;td&gt;M&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;s-tone&lt;/td&gt;
&lt;td&gt;Low&lt;/td&gt;
&lt;td&gt;Low $\mapsto$ L&lt;/td&gt;
&lt;td&gt;L&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;j-tone&lt;/td&gt;
&lt;td&gt;High-falling&lt;/td&gt;
&lt;td&gt;High-falling $\mapsto$ H&lt;/td&gt;
&lt;td&gt;H&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;v-tone&lt;/td&gt;
&lt;td&gt;Mid-rising&lt;/td&gt;
&lt;td&gt;Mid-rising $\mapsto$ M&lt;/td&gt;
&lt;td&gt;M&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;m-tone&lt;/td&gt;
&lt;td&gt;Low-falling&lt;/td&gt;
&lt;td&gt;Low-falling $\mapsto$ L&lt;/td&gt;
&lt;td&gt;L&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;g-tone&lt;/td&gt;
&lt;td&gt;Mid-falling&lt;/td&gt;
&lt;td&gt;Mid-falling $\mapsto$ M&lt;/td&gt;
&lt;td&gt;M&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;An example of &lt;em&gt;refinement&lt;/em&gt; of the partition induced by a variable would be
the reverse of the mapping for Mandarin tones in Xu (1997): rather than collapsing a 4-way distinction into a
2-way distinction, one would refine a 2-way distinction into a 4-way
distinction. Another instance of refinement would be the addition of a
level for tonal class upon the discovery of evidence for a new tonal
class in the course of fieldwork.&lt;/p&gt;
&lt;p&gt;Those two examples of refinement both involve increasing the number of
levels to some finite number, but refinements may also involve mapping
from a set of a finite number of distinctions, e.g. 4 levels, to a set
of potentially infinitely many distinctions, i.e.the set of &lt;em&gt;real
numbers&lt;/em&gt;.&lt;sup id="fnref-1"&gt;&lt;a class="footnote-ref" href="#fn-1"&gt;1&lt;/a&gt;&lt;/sup&gt; An example of this kind of refinement would be changing a
length variable from counting syllables, e.g. 1 syllable, 2 syllables
$\ldots$, to measuring absolute time, e.g. 343.25 milliseconds, 692.11
milliseconds. This kind of refinement might seem intuitively more
drastic than refining a 2-way tonal distinction into a 4-way one, and it
is: it’s a change in variable type (Stevens 1937), similar to a change
in type in type-theoretical semantics (Gamut 1992, Ch.4; Carpenter 1997
Chs. 2, 3).&lt;/p&gt;
&lt;h2 id="sec:gen-question"&gt;Generalizing to different research questions&lt;/h2&gt;
&lt;p&gt;A more drastic way to generalize beyond Pike’s procedure is to apply
principles of experimental design to other research questions. In this
section, we give examples of research questions treating tone as a
dependent variable rather than an independent variable (&lt;a href="#sec:tone-dv"&gt;Tone as a DV&lt;/a&gt;),
including examining phonetic tonal sandhi, i.e. tonal coarticulation, in White Hmong
(&lt;a href="#sec:hmong"&gt;Example 1&lt;/a&gt;); we also given an example of using a
factorial design in uncovering evidence for a tonal case marker in
Samoan (&lt;a href="#sec:samoan"&gt;Example 2&lt;/a&gt;).&lt;/p&gt;
&lt;h3 id="sec:tone-dv"&gt;Tone as a dependent variable&lt;/h3&gt;
&lt;p&gt;Thus far in this paper, we’ve considered tonal class as an independent
variable manipulated by the fieldworker, but we’ve never considered
tonal class as a dependent variable. This is not because tonal class
cannot be treated as a dependent variable, but simply due to the nature
of our research questions—we’ve focused on making hypotheses about
possible tonal classes and their reflexes in the pitch contour and
refining these hypotheses.&lt;/p&gt;
&lt;p&gt;There are two main situations in which tone might appear in the
dependent variable:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;in explorations of how tonal contrast is produced and perceived&lt;/li&gt;
&lt;li&gt;in explorations of phonological allophony and alternation&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Some example research questions about exploring the dimensions of tonal
contrast are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What effect does tonal class have on the pitch contour over a word?&lt;/li&gt;
&lt;li&gt;What parameters in the speech signal are available for
    discriminating different tonal classes?&lt;/li&gt;
&lt;li&gt;What cues in the speech signal do listeners use to identify tones?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Some examples of work along these lines appear in Connell (2000)
(perception), Khouw (2007) (production and perception), and DiCanio (2009) (production).&lt;/p&gt;
&lt;p&gt;In explorations of phonological allophony and alternation, tone makes an
appearance in the dependent variable because the mapping between
underlying tonemes and surface tones (or between surface tones) is of
primary importance. Underlying form is manipulated as an explanatory
variable, and the dependent variable is the surface form. Note that
there must be a linking hypothesis about the mapping from observables
(perhaps the pitch contour over a word) to surface tones in such an
elicitation experiment. We presented an example of a factorial design
in tonal fieldwork exploring allophony in the body of the paper in
Section 2.4.&lt;/p&gt;
&lt;h3 id="sec:hmong"&gt;Example 1: tonal realization in White Hmong&lt;/h3&gt;
&lt;p&gt;A similar factorial design for tonal bigrams, but for studying the
phonetic realization of tones in White Hmong (Hmong-Mien, China) is
given below. Since the focus is the acoustic variation induced by tonal
classes, there is a large and detailed set of acoustic dependent
variables.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Research question: How are tones in White Hmong acoustically
    realized?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Strategy: Control some known sources of variability in tonal
    realization and manipulate others to study a selected range of tonal
    variability.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Research hypothesis:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Linking hypothesis: Acoustic dimensions relevant for tonal
    discrimination in the production of White Hmong tones include
    f0-based parameters and various spectral parameters.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Experimental unit: elicited sentences&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Explanatory variables&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$N_1$ tone: b, n, s, j, g, m, v&lt;/li&gt;
&lt;li&gt;$N_2$ tone: b, n, s, j, g, m, v
&lt;p&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Confounding variables&lt;ul&gt;
&lt;li&gt;prosodic position: isolation, sentence-medial&lt;/li&gt;
&lt;li&gt;carrier phrase: fixed with two phrases, with target words
    randomly assigned to one of the two phrases&lt;/li&gt;
&lt;li&gt;segmental features of words: fully [+sonorant] (fixed)&lt;/li&gt;
&lt;li&gt;CV skeleton: CVV (fixed)&lt;/li&gt;
&lt;li&gt;pragmatic context: out of the blue (fixed)
&lt;p&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Dependent variables&lt;ul&gt;
&lt;li&gt;mean fundamental frequency&lt;/li&gt;
&lt;li&gt;syllable onset fundamental frequency&lt;/li&gt;
&lt;li&gt;syllable offset fundamental frequency&lt;/li&gt;
&lt;li&gt;mean spectral tilt&lt;/li&gt;
&lt;li&gt;mean harmonic-to-noise ratio&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Block&lt;/th&gt;
&lt;th&gt;IV&lt;/th&gt;
&lt;th&gt;Levels&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Isolation&lt;/td&gt;
&lt;td&gt;$N_1$ tone&lt;/td&gt;
&lt;td&gt;b, n, s, j, g, m, v&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;$N_2$ tone&lt;/td&gt;
&lt;td&gt;b, n, s, j, g, m, v&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Sentence-medial&lt;/td&gt;
&lt;td&gt;$N_1$ tone&lt;/td&gt;
&lt;td&gt;b, n, s, j, g, m, v&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;$N_2$ tone&lt;/td&gt;
&lt;td&gt;b, n, s, j, g, m, v&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="sec:samoan-abs"&gt;Example 2: tonal case marking in Samoan&lt;/h3&gt;
&lt;p&gt;Moving back upwards towards the morphosyntax-prosody interface, this
section gives an example of a 2$\times$2 factorial design examining the
effect of the interaction of case-marking pattern (absolutive-oblique,
ergative-absolutive) and word order (VSO, VOS) on the f0 contour in
Samoan (Polynesian, Samoa), with the goal of examining the hypothesis
that there is a high tone at the left edge of absolutive arguments. The
experimental design involves minimal sets of sentences, keeping
segmental material in test sentences constant except for the segmental
case markers for ergative and oblique case. Some factors are controlled
for optimizing our chances of observing prosodic realization realized in
the f0 contour. First, words are fully sonorant so that the f0 contours
is free from segmental perturbation. Secondly, arguments of long length,
i.e. many words, are used to allow plenty of segmental material for
intonational tonal events to be realized (Bruce 1977).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Research question: Does Samoan have a high tone at the left edge of
    absolutive arguments?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Strategy: Control any variables suspected to induce variation in
    surface realization of underlying tones and vary case-marking
    pattern and word order. To support our hypothesis, we must find an
    &lt;em&gt;interaction&lt;/em&gt; effect on the intonational realization in the
    sentence, such that the presence of high pitch peak at the left edge
    of the second argument occurs when the levels of the two factors
    interact such that the second argument has absolutive case.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Research hypothesis: Samoan has a high tone at the left edge of the
    absolutive argument.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Linking hypothesis: A high tone in Samoan is realized as pitch peak
    realized at the edge of a prosodic word.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Experimental unit: elicited sentence&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Explanatory variables&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;case-marking pattern: absolutive-oblique, ergative-absolutive&lt;/li&gt;
&lt;li&gt;Word order: VSO, VOS
&lt;p&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Confounding variables&lt;ul&gt;
&lt;li&gt;constituent length: long (fixed)&lt;/li&gt;
&lt;li&gt;coordination: absent (fixed)&lt;/li&gt;
&lt;li&gt;segmental features of words: fully [+sonorant] (fixed)&lt;/li&gt;
&lt;li&gt;stress pattern: primary stress on penultimate mora (fixed)&lt;/li&gt;
&lt;li&gt;CV skeleton: CVCVCV (fixed)&lt;/li&gt;
&lt;li&gt;pragmatic context: out of the blue
&lt;p&gt;&lt;/p&gt; &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Dependent variable: presence of high pitch peak at the left edge of
    the second argument&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The 2 $\times$ 2 factorial design is shown in the table below:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Word order&lt;/th&gt;
&lt;th&gt;erg-abs&lt;/th&gt;
&lt;th&gt;abs-obl&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;VSO&lt;/td&gt;
&lt;td&gt;V-erg-abs&lt;/td&gt;
&lt;td&gt;V-abs-obl&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;VSO&lt;/td&gt;
&lt;td&gt;V-abs-erg&lt;/td&gt;
&lt;td&gt;V-obl-abs&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id="references"&gt;References&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Hyman, Larry M. 2007. Elicitation as experimental phonology:
   Thlantlang lai tonology. In Experimental approaches to phonology,
   ed. Maria-Josep Solé, Patrice Speeter Beddor, and Manjari Ohala,
   7–24. Oxford; New York: Oxford University Press.&lt;/li&gt;
&lt;li&gt;Xu, Yi. 1997. Contextual tonal variations in Mandarin. Journal of Phonetics 25. 61–83.&lt;/li&gt;
&lt;li&gt;Goldsmith, John A. 1990. Autosegmental and metrical phonology. Basil Blackwell.&lt;/li&gt;
&lt;li&gt;Goldsmith, John Anton. 1976. Autosegmental phonology. Doctoral
   Dissertation, Massachusetts Institute of Technology.&lt;/li&gt;
&lt;li&gt;Keating, Patricia, Christina Esposito, Marc Garellek, Sameer Khan,
   and Jianjing Kuang. 2011. Phonation contrasts across languages. In
   Proceedings of the 17th International Congress of Phonetic
   Sciences, 1046–1049. Hong Kong, China.&lt;/li&gt;
&lt;li&gt;Esposito, Christina M. 2012. An acoustic and electroglottographic
   study of White Hmong tone and phonation. Journal of Phonetics
   40:466–476.&lt;/li&gt;
&lt;li&gt;Stevens, S. S., J. Volkmann, and E. B. Newman. 1937. A scale for
   the measurement of the psychological magnitude pitch. The Journal
   of the Acoustical Society of America 8:185–190.&lt;/li&gt;
&lt;li&gt;Gamut, L.T.F. 1992. Logic, language and meaning. Chicago:
   Chicago University Press.&lt;/li&gt;
&lt;li&gt;Carpenter, Bob. 1997. Type-logical semantics. Cambridge,
   Massachusetts: MIT Press.&lt;/li&gt;
&lt;li&gt;Connell, Bruce. 2000. The perception of lexical tone in
   Mambila. Language and Speech 43:163–182.&lt;/li&gt;
&lt;li&gt;Khouw, Edward, and Valter Ciocca. 2007. Perceptual correlates of
    Cantonese tones. Journal of Phonetics 35:104–117.&lt;/li&gt;
&lt;li&gt;DiCanio, Christian T. 2009. The phonetics of register in Takhian
    Thong Chong. Journal of the International Phonetic Association 39:162–188.&lt;/li&gt;
&lt;li&gt;Bruce, Gösta. 1977. Swedish word accents in sentence perspective. Lund: CWK Gleerup.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn-1"&gt;
&lt;p&gt;The set of &lt;em&gt;real numbers&lt;/em&gt; contains numbers like 3.0, 1.542, $\pi$,
2.9, 2.99, 2.999, 2.9999999999999999$\ldots$.&amp;#160;&lt;a class="footnote-backref" href="#fnref-1" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="ldc-kiy"></category><category term="fieldwork"></category><category term="praat"></category><category term="tutorial"></category></entry><entry><title>Preparing data for the LD&amp;C paper</title><link href="http://kmyu.github.io/blog/preparing-data-for-ldc-paper.html" rel="alternate"></link><published>2013-10-31T11:12:00-04:00</published><updated>2013-10-31T11:12:00-04:00</updated><author><name>Kristine Yu</name></author><id>tag:kmyu.github.io,2013-10-31:/blog/preparing-data-for-ldc-paper.html</id><summary type="html">&lt;p&gt;Tutorial for LDC paper: preparing data presented in paper&lt;/p&gt;</summary><content type="html">&lt;p&gt;This is supplemental material for &lt;em&gt;The experimental state of mind in
elicitation: illustrations from tonal fieldwork&lt;/em&gt; that describes how
the fundamental frequency contours were extracted and plotted in the
paper for the sections illustrating toneme discovery in Kiriri
(Sections 2.2.1 and 2.3.3).&lt;/p&gt;
&lt;!-- PELICAN_END_SUMMARY --&gt;

&lt;p&gt;As a starting point, I assume that the raw audio has been
processed as described in the tutorials
&lt;a href="processing-audio-files-praat.html"&gt;Processing audio (with Praat)&lt;/a&gt; and
&lt;a href="processing-audio-files-sox.html"&gt;Processing audio (with SoX)&lt;/a&gt;,
i.e. downsampled to 16 kHz, with Channel 1 (the consultant's channel)
extracted.&lt;/p&gt;
&lt;p&gt;Processing and segmenting of the soundfile was done with the free
and open source sound file analysis software
&lt;a href="http://www.praat.org"&gt;Praat&lt;/a&gt;, and f0 extraction was done using the
RAPT algorithm &lt;code&gt;get_f0&lt;/code&gt; (Talkin 1995). &lt;/p&gt;
&lt;p&gt;The procedure for processing the data for each elicitation session
described in the paper is given in the following sections:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="#20111207"&gt;20111207-1-kiy-ap-wordlist and 20111207-1-kiy-ap-wordlist&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#20111208"&gt;20111208-6-kiy-ap-nps-vps&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#20111213"&gt;20111213-1-kiy-ap-framedwordlist&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;A &lt;a href="#references"&gt;references&lt;/a&gt; section follows.&lt;/p&gt;
&lt;p&gt;All files used in analysis are available for download in the
&lt;code&gt;preparing-data-for-ldc-paper/&lt;/code&gt; &lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/"&gt;sub-directory&lt;/a&gt; in the
&lt;code&gt;tutorials/&lt;/code&gt;
&lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/"&gt;directory&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="wzxhzdk720111207-1-kiy-ap-wordlist-and-20111207-1-kiy-ap-wordlistwzxhzdk8"&gt;&lt;a id="20111207"&gt;20111207-1-kiy-ap-wordlist and 20111207-1-kiy-ap-wordlist&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Data from the elicitation sessions 20111207-1-kiy-ap-wordlist and
20111207-1-kiy-ap-wordlist appears in the paper in Figure 5 in Section
2.2.1. All files used in analysis are available for download
&lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111207/"&gt;here&lt;/a&gt;. I
detail the procedure for audio file segmenting and annotation and f0
extraction for only 20111207-1-kiy-ap-wordlist below. The procedure
for 20111207-2-kiy-ap-wordlist was identical.&lt;/p&gt;
&lt;h3 id="initial-audio-file-segmenting-and-annotation"&gt;Initial audio file segmenting and annotation&lt;/h3&gt;
&lt;p&gt;First, I annotated the audio recording file
&lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111207/1/data/20111207-1-kiy-ap-wordlist.wav"&gt;20111207-1-kiy-ap-wordlist.wav&lt;/a&gt;
and produced the TextGrid
&lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111207/1/data/20111207-1-kiy-ap-wordlist.TextGrid"&gt;20111207-1-kiy-ap-wordlist.TextGrid&lt;/a&gt;,
following procedures in the tutorial on
&lt;a href="www.krisyu.org/blog/posts/2013/06/annotating-audio-files/"&gt;annotating sound files&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;Some of the annotation was automated. First, I marked empty intervals,
i.e. intervals without recorded material of interest, with
&lt;code&gt;XXX&lt;/code&gt;, so that scripts would ignore those intervals. Then, using the text file
&lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111207/1/info/20111207-1-kiy-ap-wordlist-kiy.txt"&gt;20111207-1-kiy-ap-wordlist-kiy.txt&lt;/a&gt;,
I automatically populated TextGrid intervals with labels using a
&lt;a href="http://www.fon.hum.uva.nl/praat/manual/Scripting.html"&gt;Praat script&lt;/a&gt;
originally authored by Mietta Lennes,
&lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111207/1/analysis/scripts/label_from_text_file.praat"&gt;label_from_text_file&lt;/a&gt;. I
then used another Lennes script,
&lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111207/1/analysis/scripts/save_intervals_to_wav_sound_files.praat"&gt;save_intervals_to_wav_sound_files&lt;/a&gt;,
to save each of the intervals to separate, short WAV files, one per
elicitation item. These files were automatically named with
incrementing integers, e.g. 20111207-1-kiy-ap-wordlist-kiy-1 for item 1; the file name for each of these individual files
refers to the item code, which can be found in &lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111207/1/info/20111207-1-kiy-ap-wordlist.txt"&gt;the dictionary file&lt;/a&gt;. All of these files are in the
&lt;code&gt;tokens&lt;/code&gt; &lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111207/1/data/tokens/"&gt;directory&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Finally, I trimmed each of these files with the assistance of a script
&lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111207/1/analysis/scripts/trim_ends.praat"&gt;trim_ends&lt;/a&gt;.
For each file, I manually indicated boundaries to cut off silence at
the beginning and end of the file; the script than moved these
boundaries to the nearest zero crossing (where the audio amplitude was
0) and trimmed the files accordingly. These trimmed files are in the
&lt;code&gt;trimmed&lt;/code&gt; &lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111207/1/data/trimmed/"&gt;directory&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="f0-extraction-with-rapt-get_f0"&gt;f0 extraction with RAPT (get_f0)&lt;/h3&gt;
&lt;p&gt;I performed f0 extraction with the following scripts:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;run_rapt.sh&lt;/code&gt; [&lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111207/1/analysis/scripts/run_rapt.sh"&gt;script&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;code&gt;calc_f0_rapt.sh&lt;/code&gt; [&lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111207/1/analysis/scripts/calc_f0_rapt.sh"&gt;script&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;code&gt;proc_esps_files.py&lt;/code&gt; [&lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111207/1/analysis/scripts/proc_esps_files.py"&gt;script&lt;/a&gt;]&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The shell script &lt;code&gt;run_rapt.sh&lt;/code&gt; called the shell script
&lt;code&gt;calc_f0_rapt.sh&lt;/code&gt; to perform f0 extraction and then the
Python script
&lt;code&gt;proc_esps_files.py&lt;/code&gt; to aggregate the f0 data into a single
file and to assign time stamps to f0 values.&lt;sup id="fnref-1"&gt;&lt;a class="footnote-ref" href="#fn-1"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;F0 extraction was done at 10ms increments with
&lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111207/1/analysis/scripts/get_f0"&gt;get_f0&lt;/a&gt;;
The &lt;a href="http://speechtechie.wordpress.com/2010/05/20/using-an-esps-parameter-file-for-get_f0/"&gt;parameter file&lt;/a&gt; used for extraction was &lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111207/1/analysis/scripts/Pget_f0"&gt;Pget_f0&lt;/a&gt;. Output files have &lt;code&gt;.f0&lt;/code&gt; file extensions and are located in the &lt;code&gt;f0&lt;/code&gt; &lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111207/1/analysis/f0/"&gt;directory&lt;/a&gt;. These files were converted
into plain text files with &lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111207/1/analysis/scripts/pplain"&gt;pplain&lt;/a&gt;, producing output files with &lt;code&gt;.f0.p&lt;/code&gt; file extensions, also located in the &lt;code&gt;f0&lt;/code&gt; &lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111207/1/analysis/f0/"&gt;directory&lt;/a&gt;. The aggregated f0 data produced by &lt;code&gt;proc_esps_files.py&lt;/code&gt; is &lt;code&gt;espsData.txt&lt;/code&gt;, located &lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111207/1/analysis/f0/espsData.txt"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="plot-of-f0-contours-in-r"&gt;Plot of f0 contours in R&lt;/h3&gt;
&lt;p&gt;I used the free and open-source statistical software
&lt;a href="http://www.r-project.org/"&gt;R&lt;/a&gt; for further data processing---in
particular, Hadley Wickham's &lt;a href="http://ggplot2.org/"&gt;ggplot2&lt;/a&gt; package for plotting.&lt;/p&gt;
&lt;p&gt;The scripts for generating the plots are available as:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;plot-20111207-knitr.R&lt;/code&gt;: pure R code [&lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111207/analysis/plot-20111207-knitr.R"&gt;file&lt;/a&gt;]&lt;/li&gt;
&lt;li&gt;&lt;code&gt;plot-20111207-knitr.Rnw&lt;/code&gt;: Sweave file
   [&lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111207/analysis/plot-20111207-knitr.Rnw"&gt;file&lt;/a&gt;],
   with interspersed $\LaTeX$ code and R code, compiled with the R
   package &lt;a href="http://yihui.name/knitr/"&gt;knitr&lt;/a&gt; using the
   Makefile &lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111207/analysis/Makefile"&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;plot-20111207-knitr.pdf&lt;/code&gt;: Output from Sweave file
   [&lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111207/analysis/plot-20111207-knitr.pdf"&gt;file&lt;/a&gt;]&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="wzxhzdk33-20111208-6-kiy-ap-nps-vpswzxhzdk34"&gt;&lt;a id="20111208"&gt; 20111208-6-kiy-ap-nps-vps&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Data from the elicitation session 20111208-6-kiy-ap-nps-vps appears in
the paper in Tables 2 and 3 and Figures 6 and 7 in Section 2.2.1, as
well as in Table A.1 in the Appendix. All files used in analysis are
available for download &lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111208-6/"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The procedure for analyzing data for 20111208-6-kiy-ap-nps-vps follows
the procedure for 20111207 detailed above. Files from analysis are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Dictionary file: &lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111208-6/info/20111208-6-kiy-ap-nps-vps-hash.txt"&gt;20111208-6-kiy-ap-nps-vps-hash.txt&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Original wav file: &lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111208-6/data/20111208-6-kiy-ap-nps-vps.wav"&gt;20111208-6-kiy-ap-nps-vps.wav&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Textgrid: &lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111208-6/data/20111208-6-kiy-ap-nps-vps.TextGrid.trim"&gt;20111208-6-kiy-ap-nps-vps.TextGrid.trim&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Individual item files: &lt;code&gt;tokens/&lt;/code&gt; &lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111208-6/data/tokens/"&gt;directory&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Trimmed individual files: &lt;code&gt;trimmed/&lt;/code&gt;
   &lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111208-6/data/trimmed/"&gt;directory&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;f0 output files: &lt;code&gt;f0/&lt;/code&gt; &lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111208-6/analysis/f0/"&gt;directory&lt;/a&gt;   &lt;/li&gt;
&lt;li&gt;Code for plotting figures:
   [&lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111208-6/analysis/plot-20111208-knitr.R"&gt;R code&lt;/a&gt;,
   &lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111208-6/analysis/plot-20111208-knitr.Rnw"&gt;Sweave&lt;/a&gt;,
   &lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111208-6/analysis/Makefile"&gt;Makefile&lt;/a&gt;, &lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111208-6/analysis/plot-20111208-knitr.Rnw"&gt;pdf&lt;/a&gt;]&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="wzxhzdk35-20111213-1-kiy-ap-framedwordlistwzxhzdk36"&gt;&lt;a id="20111213"&gt; 20111213-1-kiy-ap-framedwordlist&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Data from the elicitation session 20111213-1-kiy-ap-framedwordlist appears in
the paper in Tables 5-7 and Figures 9-11 in Section 2.3.3, as
well as in Table A.2 in the Appendix. All files used in analysis are
available for download &lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111213-1/"&gt;here&lt;/a&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Dictionary file: &lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111213-1/info/20111213-1-kiy-ap-framedwordlist.txt"&gt;20111213-1-kiy-ap-framedwordlist.txt&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Original wav file: &lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111213-1/data/20111213-1-kiy-ap-framedwordlist.wav"&gt;20111213-1-kiy-ap-framedwordlist.wav&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Textgrid file: &lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111213-1/data/20111213-1-kiy-ap-framedwordlist.TextGrid"&gt;20111213-1-kiy-ap-framedwordlist.TextGrid&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Individual item files: &lt;code&gt;tokens/&lt;/code&gt; &lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111213-1/data/tokens/"&gt;directory&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;f0 output files: &lt;code&gt;f0/&lt;/code&gt; &lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111213-1/analysis/f0/"&gt;directory&lt;/a&gt;   &lt;/li&gt;
&lt;li&gt;Code for plotting figures:
   [&lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111213-1/analysis/plot-20111213-knitr.R"&gt;R code&lt;/a&gt;,
   &lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111213-1/analysis/plot-20111213-knitr.Rnw"&gt;Sweave&lt;/a&gt;,
   &lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111213-1/analysis/Makefile"&gt;Makefile&lt;/a&gt;, &lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111213-1/analysis/plot-20111213-knitr.Rnw"&gt;pdf&lt;/a&gt;]&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The analysis procedure for 20111213-1-kiy-ap-framedwordlist closely
followed the procedures given above, except that no trimming
occurred. Instead, timestamps for the beginning and end of the
intervals corresponding to the first and second words in the
disyllabic items were collected with a shell script
&lt;code&gt;get_timestamps.sh&lt;/code&gt; 
&lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111213-1/analysis/scripts/get_timestamps.sh"&gt;here&lt;/a&gt;. This
script extracted the timepoints marking the boundaries of the
segmented words from the TextGrid file
&lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111213-1/data/20111213-1-kiy-ap-framedwordlist.TextGrid"&gt;20111213-1-kiy-ap-framedwordlist.TextGrid&lt;/a&gt;. The
output from the script was &lt;code&gt;word-timestamps.txt&lt;/code&gt;
&lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-data-for-ldc-paper/20111213-1/analysis/word-timestamps.txt"&gt;here&lt;/a&gt;. These
timestamps were used to split extracted f0 contours into the f0
contour over word 1 and the f0 contour over word 2 in each disyllabic
utterance in R. &lt;/p&gt;
&lt;p&gt;Also, time-normalized f0 plots were produced: mean f0 calculated over
each of 30 frames of equal duration over each word. The functions in the
R code that performed this were &lt;code&gt;extract.samples&lt;/code&gt;,
&lt;code&gt;extract.rapt.mean.f0.samp&lt;/code&gt;, and
&lt;code&gt;cast.f0&lt;/code&gt;. Warning: these functions are not written to work
efficiently and I'm sure they could be improved!! See the R code files
for details on the functions.&lt;/p&gt;
&lt;h2 id="wzxhzdk47referenceswzxhzdk48"&gt;&lt;a id="references"&gt;References&lt;/a&gt;&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Talkin, David. 1995. A robust algorithm for pitch tracking
   (RAPT). In Speech coding and synthesis, ed. W. B. Kleijn and
   K. K. Paliwal, 495–518. Elsevier Science Inc.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn-1"&gt;
&lt;p&gt;There is a &lt;a href="http://harris.sas.upenn.edu/pipermail/splunch/2010-March/000240.html"&gt;known round-off error for get_f0&lt;/a&gt; which is not
accounted for in the script, but the error happens to not occur for
the sampling rate of the recorded file and the timestep for f0
extraction chosen here.&amp;#160;&lt;a class="footnote-backref" href="#fnref-1" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="ldc-kiy"></category><category term="fieldwork"></category><category term="praat"></category><category term="tutorial"></category></entry><entry><title>Overview of tutorials for Language Documentation &amp; Conservation</title><link href="http://kmyu.github.io/blog/ldc-kiy-overview.html" rel="alternate"></link><published>2013-06-28T09:33:00-04:00</published><updated>2013-06-28T09:33:00-04:00</updated><author><name>Kristine Yu</name></author><id>tag:kmyu.github.io,2013-06-28:/blog/ldc-kiy-overview.html</id><summary type="html">&lt;p&gt;Overview of set of tutorials for Language Documentation &amp;amp; Conservation special issue on &lt;em&gt;How to study a tone language&lt;/em&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;The following posts are a set of tutorials for my paper for Language
Documentation &amp;amp; Conservation.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="recording-in-the-field.html"&gt;Recording in the field&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="processing-audio-files-praat.html"&gt;Processing audio files (with Praat)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="processing-audio-files-sox.html"&gt;Processing audio files (with SoX)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="organizing-elicitation-items.html"&gt;Organizing elicitation items&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="preparing-elicitation-items-for-presentation.html"&gt;Preparing elicitation items for presentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="annotating-audio-files.html"&gt;Annotating audio files&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="working-with-f0-contours.html"&gt;Working with f0 contours&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="additional-examples-of-elicitation-designs.html"&gt;Additional examples of elicitation designs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="preparing-data-for-ldc-paper.html"&gt;Preparing data for the LD&amp;amp;C paper&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="ldc-kiy"></category><category term="fieldwork"></category><category term="tutorial"></category></entry><entry><title>Processing audio files (with Praat)</title><link href="http://kmyu.github.io/blog/processing-audio-files-praat.html" rel="alternate"></link><published>2013-06-24T17:10:00-04:00</published><updated>2013-06-24T17:10:00-04:00</updated><author><name>Kristine Yu</name></author><id>tag:kmyu.github.io,2013-06-24:/blog/processing-audio-files-praat.html</id><summary type="html">&lt;p&gt;This tutorial introduces how to process audio files from fieldwork
recordings with &lt;a href="http://www.praat.org"&gt;Praat&lt;/a&gt;. See the tutorial
&lt;a href="processing-audio-files-sox.html"&gt;Processing audio (with SoX)&lt;/a&gt; for
the sister tutorial using &lt;a href="http://sox.sourceforge.net"&gt;SoX&lt;/a&gt; command line utilities.&lt;/p&gt;
&lt;!-- PELICAN_END_SUMMARY --&gt;

&lt;p&gt;Following an &lt;a href = "#intro"&gt;introductory section&lt;/a&gt;, the tutorial shows how to use &lt;a href =
"http://www.praat.org/"&gt;Praat&lt;/a&gt; 
information about a soundfile and make two different modifications to …&lt;/p&gt;</summary><content type="html">&lt;p&gt;This tutorial introduces how to process audio files from fieldwork
recordings with &lt;a href="http://www.praat.org"&gt;Praat&lt;/a&gt;. See the tutorial
&lt;a href="processing-audio-files-sox.html"&gt;Processing audio (with SoX)&lt;/a&gt; for
the sister tutorial using &lt;a href="http://sox.sourceforge.net"&gt;SoX&lt;/a&gt; command line utilities.&lt;/p&gt;
&lt;!-- PELICAN_END_SUMMARY --&gt;

&lt;p&gt;Following an &lt;a href = "#intro"&gt;introductory section&lt;/a&gt;, the tutorial shows how to use &lt;a href =
"http://www.praat.org/"&gt;Praat&lt;/a&gt; 
information about a soundfile and make two different modifications to
the soundfile:&lt;sup id="fnref-1"&gt;&lt;a class="footnote-ref" href="#fn-1"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#display"&gt;Displaying information about the audio file&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#channel"&gt;Extracting a single channel from the file&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#downsample"&gt;Downsampling the audio file&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="wzxhzdk8wzxhzdk9-introduction"&gt;&lt;a id="intro"&gt;&lt;/a&gt; Introduction&lt;/h2&gt;
&lt;p&gt;Praat is powerful cross-platform, free and
&lt;a href="http://www.fon.hum.uva.nl/praat/download_sources.html"&gt;open source&lt;/a&gt; software created and maintained by Paul Boersma and David
Weenink at the University of Amsterdam. It is widely used in phonetics
and phonology and beyond. You can download for your platform at the
following links:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.fon.hum.uva.nl/praat/download_mac.html"&gt;Mac&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.fon.hum.uva.nl/praat/download_win.html"&gt;Windows&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.fon.hum.uva.nl/praat/download_linux.html"&gt;Linux&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It is regularly updated, so if you haven't downloaded a new version in
a few months, you might take a look and see if there's a newer version available.
The help files are extensive and include a set of
&lt;a href="http://www.fon.hum.uva.nl/praat/manual/Intro.html"&gt;introductory tutorials&lt;/a&gt;. There
is also a helpful &lt;a href="http://uk.groups.yahoo.com/group/praat-users/"&gt;Praat Users group&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="instructions-for-tutorials"&gt;Instructions for tutorials&lt;/h3&gt;
&lt;p&gt;The files for the tutorials can be found
&lt;a href="http://media.krisyu.org/ldc-kiy"&gt;this directory&lt;/a&gt; under
&lt;code&gt;tutorials/processing-audio-files&lt;/code&gt;
(&lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/processing-audio-files/"&gt;here&lt;/a&gt;). Once
you've downloaded the &lt;code&gt;ldc-kiy&lt;/code&gt; repository, you can navigate to the
&lt;code&gt;tutorials/processing-audio-files/your-turn/20111213/&lt;/code&gt; sub-directory to access
all the files used in the tutorial. Ignore the other sub-directory in
&lt;code&gt;your-turn&lt;/code&gt; called &lt;code&gt;batch-demo&lt;/code&gt;, which is only for the &lt;a href="../processing-audio-files-praat"&gt;SoX tutorial&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;The &lt;code&gt;tutorials/processing-audio-files/demo/&lt;/code&gt; directory contains all the files used and generated during the
tutorial for your reference (again, ignore the &lt;code&gt;batch-demo&lt;/code&gt; directory). The &lt;code&gt;your-turn/&lt;/code&gt; directory is for you to
play in and contains only the raw audio files the tutorial works with,
and not any of the generated files from the tutorial. &lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="wzxhzdk10wzxhzdk11displaying-audio-file-information"&gt;&lt;a id="display"&gt;&lt;/a&gt;Displaying audio file information&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Launch &lt;code&gt;Praat&lt;/code&gt;. &lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Select &lt;code&gt;Open &amp;gt; Open long sound...&lt;/code&gt; from the menu at the top of
the &lt;code&gt;Praat Objects&lt;/code&gt; window, as shown below. &lt;/p&gt;
&lt;p&gt;&lt;div align = "center"&gt;
&lt;figure&gt;
&lt;img src="/img/2013/06/praat-long-sound.jpg"
alt = "Open long sound in Praat"
width = "400"&gt;
&lt;figcaption&gt; &lt;tt&gt;Open long sound&lt;/tt&gt; command.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;A &lt;code&gt;LongSound&lt;/code&gt; is distinct from a &lt;code&gt;Sound&lt;/code&gt; object type in Praat. As
it says in the &lt;a href="http://www.fon.hum.uva.nl/praat/manual/LongSound.html"&gt;manual&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A LongSound object gives you the ability to view and label a
sound file that resides on disk. You will want to use it for
sounds that are too long to read into memory as a Sound object
(typically, a few minutes).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In the &lt;code&gt;your-turn/&lt;/code&gt; directory, select
    &lt;code&gt;20111213/raw/20111213-1-kiy-ap-framedwordlist.wav&lt;/code&gt; to be
    opened. Now there should be a &lt;code&gt;LongSound
    20111213/raw/20111213-1-kiy-ap-framedwordlist&lt;/code&gt; object listed in
    your object window. Note that it is highlighted in light blue. That
    means that it is selected. You can select an object by clicking on
    it in the object window.&lt;/p&gt;
&lt;p&gt;&lt;div align = "center"&gt;
  &lt;figure&gt;
  &lt;img src="/img/2013/06/praat-longsound-obj.jpg"
  alt = "LongSound object in object window"
   width = "400"&gt;
  &lt;figcaption&gt; LongSound object
  &lt;tt&gt;20111213/raw/20111213-1-kiy-ap-framedwordlist&lt;/tt&gt; in object window.&lt;/figcaption&gt;
  &lt;/figure&gt;
  &lt;/div&gt;&lt;p&gt;&lt;/p&gt;
4. With &lt;code&gt;LongSound 20111213/raw/20111213-1-kiy-ap-framedwordlist&lt;/code&gt;
   selected, click on the &lt;code&gt;Info&lt;/code&gt; button at the bottom of the object
   window, as shown below. This will pop up the &lt;code&gt;Praat Info&lt;/code&gt; window
   with information about the audio file displayed, including the file
   format, duration of the file, sampling rate, and bit depth.&lt;sup id="fnref-2"&gt;&lt;a class="footnote-ref" href="#fn-2"&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;&lt;div align = "center"&gt;
&lt;figure&gt;
&lt;img src="/img/2013/06/praat-info.jpg"
alt = "Display info about the LongSound object"
width = "500"&gt;
&lt;figcaption&gt; Display info about the LongSound object.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Here's what it says in the &lt;code&gt;Praat Info&lt;/code&gt; window:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Object id: &lt;span class="m"&gt;1&lt;/span&gt;
Object type: Sound
Object name: &lt;span class="m"&gt;20111213&lt;/span&gt;-1-kiy-ap-framedwordlist
Date: Thu Jun &lt;span class="m"&gt;27&lt;/span&gt; &lt;span class="m"&gt;16&lt;/span&gt;:45:21 &lt;span class="m"&gt;2013&lt;/span&gt;

Duration: &lt;span class="m"&gt;347&lt;/span&gt;.832 seconds
File name: /Users/amoebe/Documents/mind/proj/kiy-ldc/tutorials/processing-audio-files/your-turn/20111213/raw/20111213-1-kiy-ap-framedwordlist.wav
File type: WAV
Number of channels: &lt;span class="m"&gt;2&lt;/span&gt;
Encoding: linear &lt;span class="m"&gt;16&lt;/span&gt; bit little-endian
Sampling frequency: &lt;span class="m"&gt;48000&lt;/span&gt; Hz
Size: &lt;span class="m"&gt;16695936&lt;/span&gt; samples
Start of sample data: &lt;span class="m"&gt;44&lt;/span&gt; bytes from the start of the file
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Some highlights:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Object name&lt;/code&gt; lists the basename of the file, without the file
  extension.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Duration&lt;/code&gt; tells us that the file is 347.832 seconds in total.  &lt;/li&gt;
&lt;li&gt;&lt;code&gt;File name&lt;/code&gt; lists the full path of the file on the hard drive.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;File type&lt;/code&gt; lists that the file format is a WAV file, a lossless file format.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Number of channels&lt;/code&gt; indicates that there are 2 channels in the file
  (Channel 1 was for the consultant; Channel 2 for the
  translator/elicitor).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Encoding&lt;/code&gt; indicates that the bit depth is 16 bit. (&lt;code&gt;little-endian&lt;/code&gt;
  indicates the byte ordering in the file.)  &lt;/li&gt;
&lt;li&gt;&lt;code&gt;Sampling frequency&lt;/code&gt; indicates the audio file was sampled at 48000 Hz (or equivalently, 48 kHz)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The sample rate of 48kHz is much higher than needed for working with
speech so we can &lt;a href="#downsample"&gt;downsample&lt;/a&gt; the file to keep the file
size down. We also want to
extract just one of the 2 channels, the channel reserved for the
consultant (Channel 1), for further data analysis.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="wzxhzdk12wzxhzdk13extracting-a-channel"&gt;&lt;a id="channel"&gt;&lt;/a&gt;Extracting a channel&lt;/h2&gt;
&lt;p&gt;None of the file modification steps we show next can be performed on a
&lt;code&gt;LongSound&lt;/code&gt; object, so you'll need to open
&lt;code&gt;20111213-1-kiy-ap-framedwordlist.wav&lt;/code&gt; again using the &lt;code&gt;Open &amp;gt; Read
from file...&lt;/code&gt; command to open the file as a &lt;code&gt;Sound&lt;/code&gt; object.&lt;/p&gt;
&lt;div align = "center"&gt;
    &lt;figure&gt;
    &lt;img src="/img/2013/06/praat-read.jpg"
    alt = "Read from file in Praat"
    width = "400"&gt;
    &lt;figcaption&gt; &lt;tt&gt;Read from file&lt;/tt&gt; command.&lt;/figcaption&gt;
    &lt;/figure&gt;
    &lt;/div&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;You can
also remove the &lt;code&gt;LongSound&lt;/code&gt; object by selecting it (click on it so
it's highlighted in blue) and clicking the &lt;code&gt;Remove&lt;/code&gt; button at the
bottom of the object window.&lt;/p&gt;
&lt;p&gt;We recorded the elicitation session with two channels,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Channel 1 (left channel): consultant&lt;/li&gt;
&lt;li&gt;Channel 2 (right channel): elicitor/translator&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To extract a channel from the stereo audio file, we do the following:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;With &lt;code&gt;Sound 20111213/raw/20111213-1-kiy-ap-framedwordlist&lt;/code&gt; selected
   in the Object Window (so that it is highlighted in blue), click on
   the &lt;code&gt;Convert&lt;/code&gt; menu at the bottom right of the Object window and
   select &lt;code&gt;Extract one channel...&lt;/code&gt;. &lt;/p&gt;
&lt;p&gt;&lt;div align = "center"&gt;
&lt;figure&gt;
&lt;img src="/img/2013/06/praat-extract.jpg"
alt = "Read from file in Praat"
width = "500"&gt;
&lt;figcaption&gt; &lt;tt&gt;Extract one channel&lt;/tt&gt; command.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In the &lt;code&gt;Sound: Extract channel&lt;/code&gt; dialog box, type &lt;code&gt;1&lt;/code&gt; in &lt;code&gt;Channel
   (number, Left, or Right)&lt;/code&gt; to extract the Left Channel, which is the
   consultant's channel for the file and click &lt;code&gt;OK&lt;/code&gt;. A new &lt;code&gt;Sound
   20111213/raw/20111213-1-kiy-ap-framedwordlist&lt;/code&gt; object will appear
   immediately under the original one and will be already selected.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If you'd like to save this new file, you can do so with the top
   menu command &lt;code&gt;Save &amp;gt; Save as WAV file...&lt;/code&gt; in a new folder you
   create in &lt;code&gt;your-turn/20111213/&lt;/code&gt; called &lt;code&gt;data/&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You can also click on the &lt;code&gt;View and Edit&lt;/code&gt; button near the top righthand
   corner in the Object Window (with the new Sound object selected) to
   examine the extracted channel. &lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id="wzxhzdk14wzxhzdk15downsampling"&gt;&lt;a id="downsample"&gt;&lt;/a&gt;Downsampling&lt;/h2&gt;
&lt;p&gt;Below, we downsample the sampling rate of the file
 &lt;code&gt;20111213-1-kiy-ap-framedwordlist.wav&lt;/code&gt; from 48kHz to 16kHz and write
 the downsampled file to a new file
 &lt;code&gt;20111213-1-kiy-ap-framedwordlist-stereo.wav&lt;/code&gt; in a new directory in
 &lt;code&gt;your-turn/20111213/1&lt;/code&gt; we call &lt;code&gt;data/&lt;/code&gt;. We give the new filename a
 &lt;code&gt;-stereo&lt;/code&gt; suffix to remind ourselves that this file still has 2
 channels. It's good to keep the stereo (2-channel) file around for
 reference, since it includes information about how items were
 elicited if we need to check those details later.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Warning: I've had Praat crash on me rather consistently trying to
  resample large files, including when I tried to downsample the
  original audio file &lt;code&gt;20111213-1-kiy-ap-framedwordlist.wav&lt;/code&gt;. Try
  downsampling &lt;em&gt;after extracting the consultant's channel&lt;/em&gt;, as
  described &lt;a href="#channel"&gt;above&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;With the new, single-channel &lt;code&gt;Sound 20111213/raw/20111213-1-kiy-ap-framedwordlist&lt;/code&gt;
   selected, click on the &lt;code&gt;Convert&lt;/code&gt; menu at the bottom right of the
   Object window and select &lt;code&gt;Resample&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;div align = "center"&gt;
 &lt;figure&gt;
    &lt;img src="/img/2013/06/praat-resample.jpg"
 alt = "Click on &lt;code&gt;Resample&lt;/code&gt; command"
 width = "500"&gt;
 &lt;figcaption&gt; &lt;tt&gt;Resample&lt;/tt&gt; command.&lt;/figcaption&gt;
 &lt;/figure&gt;
 &lt;/div&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In the &lt;code&gt;Sound:Resample&lt;/code&gt; dialog box, type in &lt;code&gt;16000&lt;/code&gt; in &lt;code&gt;New
   sampling frequency (Hz)&lt;/code&gt; to resample to 16kHz. You can leave
   &lt;code&gt;Precision&lt;/code&gt; at the default of &lt;code&gt;50&lt;/code&gt;. This determines the
   &lt;a href="http://www.fon.hum.uva.nl/praat/manual/Sound__Resample___.html"&gt;quality of the interpolation&lt;/a&gt;
   used to reconstruct the signal in resampling. Click &lt;code&gt;OK&lt;/code&gt;. You may
   have to wait a bit, but a new &lt;code&gt;Sound
   20111213-1-kiy-ap-framedwordlist&lt;/code&gt; object will appear below the
   original, selected (highlighted in blue).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If you'd like to save this new file, you can do so with the top
   menu command &lt;code&gt;Save &amp;gt; Save as WAV file...&lt;/code&gt; in a new folder you
   create in &lt;code&gt;your-turn/20111213/&lt;/code&gt; called &lt;code&gt;data/&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You can also check that the sampling rate is indeed 16kHz by
   re-opening the newly saved file as a &lt;code&gt;LongSound&lt;/code&gt; object and
   displaying information about the audio file, as described in the
   &lt;a href="#display"&gt;first section&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn-1"&gt;
&lt;p&gt;I don't know of a way to reduce bit depth in Praat. See the
&lt;a href="../processing-audio-files-sox/#bit"&gt;SoX tutorial&lt;/a&gt; for a way to do it
with SoX. There is also a way to do it in Audacity by setting &lt;code&gt;Default
Sample Format&lt;/code&gt; in &lt;code&gt;Preferences &amp;gt; Quality &amp;gt;&lt;/code&gt; before opening the sound
file in the program, as described in the
&lt;a href="http://manual.audacityteam.org/man/Quality_Preferences"&gt;manual&lt;/a&gt;.&amp;#160;&lt;a class="footnote-backref" href="#fnref-1" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn-2"&gt;
&lt;p&gt;It's critical to open the file as a &lt;code&gt;LongSound&lt;/code&gt; to get this
information. If you open the file as a &lt;code&gt;Sound&lt;/code&gt; object using &lt;code&gt;Open &amp;gt;
Read from file...&lt;/code&gt;, clicking on the &lt;code&gt;Info&lt;/code&gt; button will display (after
a bit of a wait) properties of the signal like average, min, and max amplitude and will
not display file format or bit depth.&amp;#160;&lt;a class="footnote-backref" href="#fnref-2" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="ldc-kiy"></category><category term="fieldwork"></category><category term="coding"></category><category term="shell"></category><category term="praat"></category><category term="audio"></category><category term="tutorial"></category></entry><entry><title>Annotating audio files</title><link href="http://kmyu.github.io/blog/annotating-audio-files.html" rel="alternate"></link><published>2013-06-24T11:12:00-04:00</published><updated>2013-06-24T11:12:00-04:00</updated><author><name>Kristine Yu</name></author><id>tag:kmyu.github.io,2013-06-24:/blog/annotating-audio-files.html</id><summary type="html">&lt;p&gt;Tutorial for LDC paper: annotating audio files&lt;/p&gt;</summary><content type="html">&lt;div align = "center"&gt;
&lt;figure&gt;
&lt;img src="/img/2013/06/praat-finish.jpg"
alt = "Annotating sound files in Praat" width = "700"&gt;
&lt;figcaption&gt; Annotating sound files in Praat.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;This tutorial introduces how to &lt;a href="http://www.fon.hum.uva.nl/praat/manual/Intro_7__Annotation.html"&gt;annotate&lt;/a&gt; sound files using the free
and open source sound file analysis software
&lt;a href="http://www.praat.org"&gt;Praat&lt;/a&gt;. It assumes that the raw audio has been
processed as described in the tutorials
&lt;a href="../processing-audio-files-praat"&gt;Processing audio (with Praat)&lt;/a&gt; and
&lt;a href="../processing-audio-files-sox"&gt;Processing audio (with SoX)&lt;/a&gt;,
i.e. downsampled to 16 kHz, with Channel 1 (the consultant's channel)
extracted. It then explains how to mark timepoints of events in the
sound file and to anotate these events with textual labels, using
Praat's TextGrids. Such annotated files can be used in the tone
classification software &lt;a href="http://lp20.org/toney/"&gt;Toney&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The rest of the tutorial discusses headphones for listening to
speech sound files and how to annotate sound files in Praat and has
the following sections: &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="#intro"&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#headphones"&gt;Headphones&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#mark"&gt;Marking timepoints in sound files&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#annot"&gt;Annotating timepoints in sound files&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="wzxhzdk21wzxhzdk22-introduction"&gt;&lt;a id="intro"&gt;&lt;/a&gt; Introduction&lt;/h2&gt;
&lt;p&gt;A soundfile is hard to access data from when it is an undifferentiated
blob. It's really helpful to have timestamps marking relevant events
so that one can easily go right to the part in the recording corresponding to
these events. One might keep a running list of timepoints during the
elicitation session when crucial bits happen. Or one might modify the
soundfile itself to indicate landmarks.&lt;/p&gt;
&lt;p&gt;The solution one can implement
in Praat is to keep timepoints and associated events in a text file
called a
&lt;a href="http://www.fon.hum.uva.nl/praat/manual/TextGrid.html"&gt;TextGrid&lt;/a&gt;,
separate from the audio file. The sound file and the TextGrid can be
opened together to link them via the timepoints (which serve as
&lt;a href="organizing-elicitation-items.html/#hash"&gt;dictionary keys&lt;/a&gt; so that one
can easily access any given annotated timepoint and/or labeled
event. The advantage of this solution over keeping a running list of
timepoints in a journal is that the annotations can be directly linked
up with the sound file. The advantage of this solution over modifying
the original sound file is that the annotation file is extremely
lightweight and portable (as it is just a plain text file, as shown below) and can be readily
processed with any text processing scripts for efficient batch
processing and modifications to annotations have nothing to do with
the soundfile so there's no potential for accidental changes to the
actual recording or opportunities to corrupt it.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# The first bit of 20111213-2-kiy-ap-framedwordlist.TextGrid&lt;/span&gt;
&lt;span class="c1"&gt;# I&amp;#39;ve added some comments to explain what the text means.&lt;/span&gt;
&lt;span class="c1"&gt;# For more on what tiers are, read on in the tutorial.&lt;/span&gt;
File &lt;span class="nb"&gt;type&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;ooTextFile&amp;quot;&lt;/span&gt;
Object &lt;span class="nv"&gt;class&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;TextGrid&amp;quot;&lt;/span&gt;

&lt;span class="nv"&gt;xmin&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="c1"&gt;# this is a timestamp for the start of the file&lt;/span&gt;
&lt;span class="nv"&gt;xmax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;256&lt;/span&gt;.4826875 &lt;span class="c1"&gt;# timestamp for end of file&lt;/span&gt;
tiers? &amp;lt;exists&amp;gt; 
&lt;span class="nv"&gt;size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;4&lt;/span&gt; &lt;span class="c1"&gt;# number of tiers&lt;/span&gt;
item &lt;span class="o"&gt;[]&lt;/span&gt;: 
    item &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;: &lt;span class="c1"&gt;# first tier&lt;/span&gt;
        &lt;span class="nv"&gt;class&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;IntervalTier&amp;quot;&lt;/span&gt; &lt;span class="c1"&gt;# Tier 1 is an Interval Tier&lt;/span&gt;
        &lt;span class="nv"&gt;name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;target&amp;quot;&lt;/span&gt; &lt;span class="c1"&gt;# name of Tier 1&lt;/span&gt;
        &lt;span class="nv"&gt;xmin&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="c1"&gt;# timestamp for start of Tier 1 &lt;/span&gt;
        &lt;span class="nv"&gt;xmax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;256&lt;/span&gt;.4826875 &lt;span class="c1"&gt;# timestamp for end of Tier 1&lt;/span&gt;
        intervals: &lt;span class="nv"&gt;size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;81&lt;/span&gt; &lt;span class="c1"&gt;# number of intervals in Tier 1&lt;/span&gt;
        intervals &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;: &lt;span class="c1"&gt;# first interval in Tier 1&lt;/span&gt;
            &lt;span class="nv"&gt;xmin&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="c1"&gt;# timestamp for start of Interval 1 in Tier 1&lt;/span&gt;
            &lt;span class="nv"&gt;xmax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;24&lt;/span&gt;.747999999999998 &lt;span class="c1"&gt;# timestamp: end of Interval 1,Tier 1&lt;/span&gt;
            &lt;span class="nv"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;xxx&amp;quot;&lt;/span&gt; &lt;span class="c1"&gt;# the text label for Interval 1, Tier 1&lt;/span&gt;
        intervals &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;: &lt;span class="c1"&gt;# second interval in Tier 1&lt;/span&gt;
            &lt;span class="nv"&gt;xmin&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;24&lt;/span&gt;.747999999999998 
            &lt;span class="nv"&gt;xmax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;25&lt;/span&gt;.492 
            &lt;span class="nv"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;xxx&amp;quot;&lt;/span&gt; 
        intervals &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;: &lt;span class="c1"&gt;# third interval in Tier 1&lt;/span&gt;
            &lt;span class="nv"&gt;xmin&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;25&lt;/span&gt;.492 
            &lt;span class="nv"&gt;xmax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;38&lt;/span&gt;.252 
            &lt;span class="nv"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;xxx&amp;quot;&lt;/span&gt; 
        intervals &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="m"&gt;4&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;:
            &lt;span class="nv"&gt;xmin&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;38&lt;/span&gt;.252 
            &lt;span class="nv"&gt;xmax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;40&lt;/span&gt;.17475333677905 
            &lt;span class="nv"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;xxx&amp;quot;&lt;/span&gt; 
        intervals &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="m"&gt;5&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;:
            &lt;span class="nv"&gt;xmin&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;40&lt;/span&gt;.17475333677905 
            &lt;span class="nv"&gt;xmax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;46&lt;/span&gt;.708 
            &lt;span class="nv"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;xxx&amp;quot;&lt;/span&gt; 
        intervals &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="m"&gt;6&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;:
            &lt;span class="nv"&gt;xmin&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;46&lt;/span&gt;.708 
            &lt;span class="nv"&gt;xmax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;53&lt;/span&gt;.724 
            &lt;span class="nv"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;xxx&amp;quot;&lt;/span&gt; 
        intervals &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;:
            &lt;span class="nv"&gt;xmin&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;53&lt;/span&gt;.724 
            &lt;span class="nv"&gt;xmax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;54&lt;/span&gt;.08763090207048 
            &lt;span class="nv"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;paRai-li:1&amp;quot;&lt;/span&gt; 
        intervals &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="m"&gt;8&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;:
            &lt;span class="nv"&gt;xmin&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;54&lt;/span&gt;.08763090207048 
            &lt;span class="nv"&gt;xmax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;54&lt;/span&gt;.476 
            &lt;span class="nv"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;li-paRai:R&amp;quot;&lt;/span&gt; 
&lt;/pre&gt;&lt;/div&gt;


&lt;h3 id="instructions-for-tutorials"&gt;Instructions for tutorials&lt;/h3&gt;
&lt;p&gt;The files for the tutorials can be found in my
&lt;a href="http://media.krisyu.org/ldc-kiy/tutorials"&gt;here&lt;/a&gt; in
&lt;code&gt;annotating-audio-files/&lt;/code&gt;
(&lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/annotating-audio-files/"&gt;here&lt;/a&gt;). If
you download the whole
&lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/annotating-audio-files/"&gt;annotating-audio-files directory&lt;/a&gt;,
you can navigate to the &lt;code&gt;your-turn/&lt;/code&gt; sub-directory to access all the files used in the tutorial. &lt;/p&gt;
&lt;p&gt;The &lt;code&gt;tutorials/annotating-audio-files/demo/&lt;/code&gt; directory contains all
the files used and generated during the tutorial for your
reference. The &lt;code&gt;your-turn/&lt;/code&gt; directory is for you to play in and
contains only the raw audio file the tutorial works with and one
"blank" TextGrid file.&lt;/p&gt;
&lt;h2 id="wzxhzdk23wzxhzdk24headphones"&gt;&lt;a id="text"&gt;&lt;/a&gt;Headphones&lt;/h2&gt;
&lt;p&gt;For analyzing sound files, it's helpful to be able to listen to them
through headphones, especially if the signal is weak. Headphones help
isolate the speech signal from the ambient sounds in the external
environment and help make details of the sound more apparent. It's
important to use headphones that have a &lt;strong&gt;flat frequency response&lt;/strong&gt; so
that they don't alter the sound quality. Headphones for listening to
music sometimes have bass and/or treble emphasis.&lt;/p&gt;
&lt;p&gt;Below, we show a
frequency response comparison from
&lt;a href="www.headphone.com/buildAGraph.php"&gt;www.headphone.com/buildAGraph.php&lt;/a&gt;
for four headphones: &lt;a href="http://pro.sony.com/bbsc/ssr/product-MDR7506"&gt;Sony MDR-7506&lt;/a&gt; (blue),
&lt;a href="http://en-us.sennheiser.com/professional-dj-headphones-noise-cancelling-hd-280-pro"&gt;Sennheiser HD280 Pro&lt;/a&gt; (red), &lt;a href="http://avlex.com/products/hd-668b/"&gt;Superlux HD 668B&lt;/a&gt; (green), and
&lt;a href="http://en-us.sennheiser.com/over-ear-headphone-momentum-stereo"&gt;Sennheiser Momentum&lt;/a&gt; (orange). The Superlux HD 668B has bass emphasis with a large plateau
below 100 Hz, and the Sennheiser Momentum has some bass emphasis with
a large dip in frequency response in the treble region around 5000
Hz, and the Superlux HD 668B has a peak for
emphasis in the higher treble range for "higher highs". In contrast,
the Sony MDR-7506 and Sennheiser HD280 Pro both have quite flat
frequency responses: this is what we want for phonetic data analysis. &lt;/p&gt;
&lt;div align = "center"&gt;
&lt;figure&gt;
&lt;img
src="/img/2013/06/freqresponse.png"
alt = "Frequency response comparison for Sony MDR-7506, Sennheiser
HD280 Pro, Superlux HD 668B, and Sennheiser Momentum." width = "1000"&gt;
&lt;figcaption&gt;Frequency response comparison for Sony MDR-7506, Sennheiser
HD280 Pro, Superlux HD 668B, and Sennheiser Momentum. [&lt;a href = "http://www.headphone.com/buildAGraph.php"&gt;www.headphone.com/buildAGraph.php&lt;/a&gt;]&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;&lt;/p&gt;

&lt;hr&gt;
&lt;h2 id="wzxhzdk25wzxhzdk26marking-timepoints-in-sound-files"&gt;&lt;a id="mark"&gt;&lt;/a&gt;Marking timepoints in sound files&lt;/h2&gt;
&lt;p&gt;In this section, we explain how to perform &lt;strong&gt;segmentation&lt;/strong&gt; of the
sound file, i.e. how to set down timepoints marking relevant
events. We'll be working with &lt;code&gt;20111213-2-kiy-ap-framedwordlist.wav&lt;/code&gt;
in &lt;code&gt;ldc-kiy/tutorials/annotating-audio-files/your-turn/&lt;/code&gt;, which is
already downsampled and includes only the consultant's channel.&lt;/p&gt;
&lt;h3 id="creating-a-new-textgrid"&gt;Creating a new TextGrid&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Launch &lt;code&gt;Praat&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Select &lt;code&gt;Open &amp;gt; Open long sound file...&lt;/code&gt; from the menu at the top of
the &lt;code&gt;Praat Objects&lt;/code&gt; window, as shown below.&lt;/p&gt;
&lt;p&gt;&lt;div align = "center"&gt;
&lt;figure&gt;
&lt;img src="/img/2013/06/praat-long-sound.jpg"
alt = "Open long sound file in Praat"
width = "400"&gt;
&lt;figcaption&gt; &lt;tt&gt;Open long sound file&lt;/tt&gt; command.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Select &lt;code&gt;20111213-2-kiy-ap-framedwordlist.wav&lt;/code&gt; in the directory
   &lt;code&gt;ldc-kiy/tutorials/annotating-audio-files/your-turn/&lt;/code&gt; and click on
   &lt;code&gt;Choose&lt;/code&gt;. There should now be a &lt;code&gt;LongSound
   20111213-2-kiy-ap-framedwordlist.wav&lt;/code&gt; object listed in the Object Window.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You can &lt;a href="../processing-audio-files-praat/#display"&gt;display the audio file information&lt;/a&gt; to confirm that the
   sampling rate is 16kHz, the bit depth is 16-bit, and that there is
   a single channel.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The &lt;code&gt;LongSound 20111213-2-kiy-ap-framedwordlist.wav&lt;/code&gt; object should
   be selected, i.e., highlighted in blue, already. With it selected,
   click on the &lt;code&gt;Annotate &amp;gt; To Text Grid...&lt;/code&gt; command on the right, as
   shown below:&lt;/p&gt;
&lt;p&gt;&lt;div align = "center"&gt;
&lt;figure&gt;
&lt;img src="/img/2013/06/praat-annotate.jpg"
alt = "The &lt;tt&gt;To Text Grid...&lt;/tt&gt; command"
width = "450"&amp;gt;&lt;br&gt;
&lt;figcaption&gt; The &lt;tt&gt;To Text Grid...&lt;/tt&gt; command.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In the &lt;code&gt;LongSound: To TextGrid...&lt;/code&gt; dialog box, there are two
   fields: &lt;code&gt;Tier names&lt;/code&gt; and &lt;code&gt;Point tiers&lt;/code&gt;. Praat distinguishes between
   two types of timestamps and separates annotation for them into
   different &lt;em&gt;tiers&lt;/em&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Interval tiers&lt;/strong&gt; are for marking events that span some
    duration, like a vowel, a word, a sentence.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Point tiers&lt;/strong&gt; are for marking events that occur
    instantaneously at a single point in time, like the midpoint
    of a vowel, the pitch peak in a word, the right edge of a
    prosodic phrase.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Include tier names for both interval and point tiers in &lt;code&gt;Tier
   names&lt;/code&gt;, separated by spaces, and in order from the topmost
   tier (closest to the bottom of the waveform/spectrogram) to
   the bottomost bier (at the bottom of the window). Type in the
   tiernames for any point tiers again in &lt;code&gt;Point tiers&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;For our file, we'll start with just an &lt;code&gt;item&lt;/code&gt; tier, to set
   boundaries for each of the elicitation items, which are listed in
   &lt;code&gt;20111213-2-kiy-ap-framedwordlist.txt&lt;/code&gt; in &lt;code&gt;your-turn&lt;/code&gt;. So type
   &lt;code&gt;item&lt;/code&gt; in the field &lt;code&gt;Tier names&lt;/code&gt; and leave &lt;code&gt;Point tiers&lt;/code&gt; blank, and
   click &lt;code&gt;OK&lt;/code&gt;:&lt;/p&gt;
&lt;div align = "center"&gt;
&lt;figure&gt;
&lt;img src="/img/2013/06/praat-tier-dialog.jpg"
alt = "The LongSound: To Text Grid...dialog box" width = "450"&gt;&lt;br&gt;
&lt;figcaption&gt; The &lt;code&gt;LongSound: To TextGrid...&lt;/code&gt; dialog box.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h3 id="editing-the-textgrid"&gt;Editing the TextGrid&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Now there should be a new &lt;code&gt;TextGrid
   20111213-2-kiy-ap-framedwordlist&lt;/code&gt; object listed under &lt;code&gt;LongSound
   20111213-2-kiy-ap-framedwordlist.wav&lt;/code&gt; in the Object window. It
   should already be selected. To annotate the sound file in the
   TextGrid, we select both of the objects together. Hit &lt;code&gt;Shift&lt;/code&gt; and
   left-click on &lt;code&gt;LongSound 20111213-2-kiy-ap-framedwordlist.wav&lt;/code&gt; to
   select that as well. Then click on &lt;code&gt;View &amp;amp; Edit&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;&lt;div align = "center"&gt;
&lt;figure&gt;
&lt;img src="/img/2013/06/praat-select-objects.jpg"
alt = "Select the LongSound and TextGrid objects"
width = "450"&gt;&lt;br&gt;
&lt;figcaption&gt; Select the &lt;tt&gt;LongSound&lt;/tt&gt; and &lt;tt&gt;TextGrid&lt;/tt&gt; objects.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Now the sound file and TextGrid are linked up in a way that you can
   annotate the sound file "directly" and have your annotations stored in the
   TextGrid file! Perhaps the most important thing about working with TextGrids is to
   &lt;strong&gt;remember to save your work&lt;/strong&gt;. You can do this with the &lt;code&gt;File &amp;gt;
   Save TextGrid as text file...&lt;/code&gt; command, shown below:&lt;/p&gt;
&lt;p&gt;&lt;div align = "center"&gt;
&lt;figure&gt;
&lt;img src="/img/2013/06/praat-save-textgrid.jpg"
alt = "Save TextGrid as text file... command"
width = "450"&gt;&lt;br&gt;
&lt;figcaption&gt; &lt;tt&gt;Save TextGrid as text file...&lt;/tt&gt; command.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The screencast below gives an introduction to
   marking interval boundaries in the textgrid and labeling the
   intervals, including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.fon.hum.uva.nl/praat/manual/TextGridEditor.html"&gt;Creating new tiers and intervals and playing intervals&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.fon.hum.uva.nl/praat/manual/Keyboard_shortcuts.html"&gt;Navigating the soundfile and textgrid with keyboard shortcuts&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The files used in the tutorial are in &lt;code&gt;tutorials/annotating-audio-files/your_turn/&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;20111213-2-kiy-ap-framedwordlist.wav&lt;/code&gt; is the sound file&lt;/li&gt;
&lt;li&gt;&lt;code&gt;20111213-2-kiy-ap-framedwordlist.txt&lt;/code&gt; lists the elicitation items elicited&lt;/li&gt;
&lt;/ul&gt;
&lt;p align = "center"&gt;
&lt;video controls&gt;
  &lt;source src="http://media.krisyu.org/ldc-kiy/videos/marking-timepoints.mp4" type="video/mp4"&gt;
  &lt;source src="http://media.krisyu.org/ldc-kiy/videos/marking-timepoints.ogv" type="video/ogg"&gt;
  Your browser does not support the video tag.
&lt;/video&gt;
Screencast: Marking interval boundary timepoints in the TextGrid.
&lt;/p&gt;

&lt;hr&gt;
&lt;h2 id="wzxhzdk27wzxhzdk28annotating-timepoints-in-sound-files"&gt;&lt;a id="annot"&gt;&lt;/a&gt;Annotating timepoints in sound files&lt;/h2&gt;
&lt;p&gt;We'll finish up with showing how to add textual labels to intervals, and show how to use a script to efficiently do this. &lt;/p&gt;
&lt;h3 id="adding-text-labels-to-intervals"&gt;Adding text labels to intervals&lt;/h3&gt;
&lt;p&gt;In the screencast below, we show how to add textual annotations to a
TextGrid file. The files used are in &lt;code&gt;tutorials/annotating-audio-filex/your_turn/&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;20111213-2-kiy-ap-framedwordlist.wav&lt;/code&gt; is the sound file&lt;/li&gt;
&lt;li&gt;&lt;code&gt;20111213-2-kiy-ap-framedwordlist.txt&lt;/code&gt; lists the elicitation items elicited&lt;/li&gt;
&lt;li&gt;&lt;code&gt;20111213-2-kiy-ap-framedwordlist_item_newlines_blank.TextGrid&lt;/code&gt; is
  the TextGrid we start with, which has boundaries set down already in
  the appropriate places to mark elicitation items.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The screencast includes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Adding textual annotations to label intervals&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.fon.hum.uva.nl/praat/manual/Phonetic_symbols.html"&gt;Using phonetic symbols in textgrid labelling&lt;/a&gt;      &lt;/li&gt;
&lt;/ul&gt;
&lt;p align = "center"&gt;
&lt;video controls&gt;
  &lt;source src="http://media.krisyu.org/ldc-kiy/videos/annotating-timepoints.mp4" type="video/mp4"&gt;
  &lt;source src="http://media.krisyu.org/ldc-kiy/videos/annotating-timepoints.ogv" type="video/ogg"&gt;
  Your browser does not support the video tag.
&lt;/video&gt;
Screencast: Annotating interval boundary timepoints in the TextGrid.
&lt;/p&gt;

&lt;h3 id="using-a-script-to-semi-automatically-label-intervals"&gt;Using a script to semi-automatically label intervals&lt;/h3&gt;
&lt;p&gt;Wait a minute---why are we typing all these labels out again in the
TextGrids when they are already in our textfile
&lt;code&gt;20111213-2-kiy-ap-framedwordlist.txt&lt;/code&gt;(http://media.krisyu.org/ldc-kiy/tutorials/annotating-audio-files/20111213-2-kiy-ap-framedwordlist.txt)
and spreadsheet &lt;code&gt;20111213-2-kiy-ap-framedwordlist.xlsx&lt;/code&gt;(http://media.krisyo.org/ldc-kiy/tutorials/annotating-audio-files/20111213-2-kiy-ap-framedwordlist.xlsx)?&lt;/p&gt;
&lt;p&gt;Good question! We can save some time and reduce the change of
introducing errors from typos by extracting the labels from the
textfile or spreadsheet and then using a &lt;a href="http://www.fon.hum.uva.nl/praat/manual/Scripting.html"&gt;Praat script&lt;/a&gt; to populate the
TextGrid intervals with the labels. We'll show how to extract labels from a
spreadsheet in Excel in the section
&lt;a href="#excel-labels"&gt;Creating files for semi-automatic TextGrid annotation from Excel&lt;/a&gt; and how to extract labels from a
textfile using command-line utilities in the section &lt;a href="#shell-labels"&gt;Extracting labels for TextGrids from text files in the shell&lt;/a&gt;. Then we'll show how to use a Praat script to use these labels to
annotate the intervals in the TextGrid in &lt;a href="#praat-script"&gt;Semi-automatic TextGrid annotation with a script&lt;/a&gt;.&lt;/p&gt;
&lt;h4 id="wzxhzdk29wzxhzdk30-creating-files-for-semi-automatic-textgrid-annotation-from-excel"&gt;&lt;a id = "excel-labels"&gt;&lt;/a&gt; Creating files for semi-automatic TextGrid annotation from Excel&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Launch Excel and open &lt;code&gt;20111213-2-kiy-ap-framedwordlist.xlsx&lt;/code&gt;&lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/annotating-audio-files/20111213-2-kiy-ap-framedwordlist.xlsx"&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Let's say we want to annotate the intervals in the &lt;code&gt;item&lt;/code&gt; tier in
   the TextGrid file with the orthographic representations for
   Kirikiri. Then we can select the column of Kirikiri (not including
   the header row) and hit &lt;code&gt;Edit &amp;gt; Copy&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;&lt;div align = "center"&gt;
&lt;figure&gt;
&lt;img src="/img/2013/06/excel-copy.jpg"
alt = "Copying the Kirikiri labels from the spreadsheet." width = "450"&gt;&lt;br&gt;
&lt;figcaption&gt;Copying the Kirikiri labels from the spreadsheet.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;&lt;p&gt;&lt;/p&gt;
3. Now we can launch some text-editing application, for instance
   Notepad on Windows or TextEdit for Mac and invoke a Paste
   command. The important thing is to make sure that you are working
   in &lt;strong&gt;plain text&lt;/strong&gt;. For instance, if you do an &lt;code&gt;Edit &amp;gt; Paste&lt;/code&gt;
   command without first invoking &lt;code&gt;Format &amp;gt; Make Plain Text&lt;/code&gt; in
   TextEdit, you get strange table-like formatting, as shown below.   &lt;/p&gt;
&lt;p&gt;&lt;div align = "center"&gt;
&lt;figure&gt;
&lt;img src="/img/2013/06/textedit-plain.jpg"
alt = "Make Plain Text in TextEdit." width = "450"&gt;&lt;br&gt;
&lt;figcaption&gt;&lt;code&gt;Make Plain Text&lt;/code&gt; command in TextEdit.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;&lt;p&gt;&lt;/p&gt;
4. Save your text file. The text files we'll use further on in the
   tutorials are in &lt;code&gt;tutorials/annotating-audio-files/your_turn/&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/annotating-audio-files/numeric-labels.txt"&gt;&lt;code&gt;numeric-labels.txt&lt;/code&gt;&lt;/a&gt;: item numbers&lt;/li&gt;
&lt;li&gt;&lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/annotating-audio-files/kiy-labels.txt"&gt;&lt;code&gt;kiy-labels.txt&lt;/code&gt;&lt;/a&gt;: Kirikiri orthographic representations&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;!--&lt;p align = "center"&gt;
&lt;video controls&gt;
  &lt;source src="/videos/2013/06/label-from-excel.mp4" type="video/mp4"&gt;
  Your browser does not support the video tag.
&lt;/video&gt;
Screencast: Extracting labels for TextGrid annotation from a spreadsheet.
&lt;/p&gt;--&gt;

&lt;h4 id="wzxhzdk31wzxhzdk32-extracting-labels-for-textgrids-from-text-files-in-the-shell"&gt;&lt;a id="shell-labels"&gt;&lt;/a&gt; Extracting labels for TextGrids from text files in the shell&lt;/h4&gt;
&lt;p&gt;We start with the tab-delimited text file &lt;code&gt;20111213-2-kiy-ap-framedwordlist.txt&lt;/code&gt;&lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/annotating-audio-files/20111213-2-kiy-ap-framedwordlist.txt"&gt;here&lt;/a&gt;, which looks like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;item    gloss   kirikiri        tone1   tone2   suffix  word1   word2
&lt;span class="m"&gt;1&lt;/span&gt;       &lt;span class="k"&gt;for&lt;/span&gt; the bandicoot       paRai li        &lt;span class="m"&gt;1&lt;/span&gt;       R       benefactive     paRai   li
&lt;span class="m"&gt;2&lt;/span&gt;       &lt;span class="k"&gt;for&lt;/span&gt; the bat     torii li        &lt;span class="m"&gt;1&lt;/span&gt;       R       benefactive     torii   li
&lt;span class="m"&gt;3&lt;/span&gt;       &lt;span class="k"&gt;for&lt;/span&gt; the pigeon  maRuu li        &lt;span class="m"&gt;1&lt;/span&gt;       R       benefactive     maRuu   li
&lt;span class="m"&gt;4&lt;/span&gt;       &lt;span class="k"&gt;for&lt;/span&gt; the dog     nabii li        &lt;span class="m"&gt;2&lt;/span&gt;       R       benefactive     nabii   li
&lt;span class="m"&gt;5&lt;/span&gt;       &lt;span class="k"&gt;for&lt;/span&gt; the gecko   kaza li &lt;span class="m"&gt;2&lt;/span&gt;       R       benefactive     kaza    li
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Let's say we want to label the intervals in the TextGrid with the
   Kirikiri orthographic representations. We can extract the
   &lt;code&gt;kirikiri&lt;/code&gt; column and write it to a new text file &lt;code&gt;kiy-labels.txt&lt;/code&gt;
   using &lt;code&gt;cut&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;cut -f3 &lt;span class="m"&gt;20111213&lt;/span&gt;-2-kiy-ap-framedwordlist.txt &lt;span class="p"&gt;|&lt;/span&gt; sed &lt;span class="s1"&gt;&amp;#39;1d&amp;#39;&lt;/span&gt; &amp;gt; kiy-labels.txt
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The &lt;code&gt;-f3&lt;/code&gt; says to extract the 3rd field. &lt;code&gt;sed '1d'&lt;/code&gt; removes the
first line, which is the header &lt;code&gt;kirikiri&lt;/code&gt;. Here's an extract from
the new file:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;amoebe@moebius :: more kiy-labels.txt
paRai li
torii li
maRuu li
nabii li
kaza li
fivaa li
fO li
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We can do the same to extract the &lt;code&gt;item&lt;/code&gt; column if we want to label
  the intervals in the TextGrid with numeric item IDs, but another
  way we could create &lt;code&gt;item&lt;/code&gt; labels is to simply create a new text
  file with the integers 1-24, using &lt;code&gt;jot&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;jot &lt;span class="m"&gt;24&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt; &amp;gt;&amp;gt; numeric-labels.txt
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The first 10 lines in the file look like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;amoebe@moebius :: more numeric-labels.txt 
&lt;span class="m"&gt;1&lt;/span&gt;
&lt;span class="m"&gt;2&lt;/span&gt;
&lt;span class="m"&gt;3&lt;/span&gt;
&lt;span class="m"&gt;4&lt;/span&gt;
&lt;span class="m"&gt;5&lt;/span&gt;
&lt;span class="m"&gt;6&lt;/span&gt;
&lt;span class="m"&gt;7&lt;/span&gt;
&lt;span class="m"&gt;8&lt;/span&gt;
&lt;span class="m"&gt;9&lt;/span&gt;
&lt;span class="m"&gt;10&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;It turns out, as we'll see in the &lt;a href="#praat-script"&gt;next section&lt;/a&gt;,
that it can also be helpful to have blank lines between each
label. These commands do the trick, with some help from &lt;code&gt;sed
G&lt;/code&gt;; the &lt;code&gt;sed '$d'&lt;/code&gt; command is for stripping the trailing newline at
the end of the file:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;jot &lt;span class="m"&gt;24&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; sed G &lt;span class="p"&gt;|&lt;/span&gt; sed &lt;span class="s1"&gt;&amp;#39;$d&amp;#39;&lt;/span&gt; &amp;gt; numeric-labels-newlines.txt
cut -f3 &lt;span class="m"&gt;20111213&lt;/span&gt;-2-kiy-ap-framedwordlist.txt &lt;span class="p"&gt;|&lt;/span&gt; sed &lt;span class="s1"&gt;&amp;#39;1d&amp;#39;&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; sed G &lt;span class="p"&gt;|&lt;/span&gt;
sed &lt;span class="s1"&gt;&amp;#39;$d&amp;#39;&lt;/span&gt; &amp;gt;  kiy-labels-newlines.txt
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The file &lt;code&gt;kiy-labels-newlines.txt&lt;/code&gt; looks like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;amoebe@moebius :: more kiy-labels-newlines.txt
paRai li

torii li

maRuu li

nabii li

kaza li

fivaa li
&lt;/pre&gt;&lt;/div&gt;


&lt;h4 id="wzxhzdk33wzxhzdk34-semi-automatic-textgrid-annotation-with-a-script"&gt;&lt;a id="praat-script"&gt;&lt;/a&gt; Semi-automatic TextGrid annotation with a script&lt;/h4&gt;
&lt;p&gt;In the screencast below, we show how to add textual annotations to a
TextGrid file semi-automatically using a script. First we demonstrate
how to annotated with the &lt;code&gt;kiy-labels.txt&lt;/code&gt; file and then we annotate
with the &lt;code&gt;numeric-labels.txt&lt;/code&gt; file. The files used are in &lt;code&gt;tutorials/annotating-audio-filex/your_turn/&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;20111213-2-kiy-ap-framedwordlist.wav&lt;/code&gt; is the sound file&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;label_from_text_file2.praat&lt;/code&gt; is the Praat script (which is just a
  text file)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;20111213-2-kiy-ap-framedwordlist_item_blank.TextGrid&lt;/code&gt; is
  the TextGrid we start with, which has boundaries set down already in
  the appropriate places to mark elicitation items. It also contains
  &lt;code&gt;xxx&lt;/code&gt; annotations in the intervals between the intervals for
  elicitation items.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kiy-labels.txt&lt;/code&gt; and &lt;code&gt;numeric-labels.txt&lt;/code&gt; contain the labels that go
  in &lt;code&gt;20111213-2-kiy-ap-framedwordlist_item_blank.TextGrid&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p align = "center"&gt;
&lt;video controls&gt;
  &lt;source src="http://media.krisyu.org/ldc-kiy/videos/praat-scripting.mp4" type="video/mp4"&gt;
  &lt;source src="http://media.krisyu.org/ldc-kiy/videos/praat-scripting.ogv" type="video/ogg"&gt;
  Your browser does not support the video tag.
&lt;/video&gt;
Screencast: Semi-automatic annotation of interval labels in the
TextGrid using a Praat script.
&lt;/p&gt;

&lt;p&gt;If you'd like, you can also repeat the procedure with a TextGrid which
has not had &lt;code&gt;xxx&lt;/code&gt; annotated in the intervals to be ignored. In this
case, the text files with the labels have blank lines between each
label so that the script will skip the intervals to be ignored between
each elicitation item interval (there's only one such junk interval
between each elicitation item interval).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;20111213-2-kiy-ap-framedwordlist_item_newlines_blank.TextGrid&lt;/code&gt; is
  another TextGrid we start with, which has boundaries set down already in
  the appropriate places to mark elicitation items. It contains empty
  intervals (no annotations) in the intervals between the intervals for
  elicitation items.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kiy-labels-newlines.txt&lt;/code&gt; and &lt;code&gt;numeric-labels-newlines.txt&lt;/code&gt; contain the labels that go
  in &lt;code&gt;20111213-2-kiy-ap-framedwordlist_item_newlines_blank.TextGrid&lt;/code&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Perhaps the trickiest thing when one is starting out working with
Praat scripts is figuring out how to specify file and directory paths
in the script. &lt;/p&gt;
&lt;p&gt;For Mac OS X, one way to do this is in &lt;code&gt;Finder&lt;/code&gt;. Right click on the
file of interest (here: &lt;code&gt;kiy-labels.txt&lt;/code&gt;) and click on &lt;code&gt;Get info&lt;/code&gt;. The
directory the file is in will come up in &lt;code&gt;Where&lt;/code&gt; in the
&lt;code&gt;kiy-labels.txt Info&lt;/code&gt; window, as shown below and you can select and
copy it. You just need to tack on the file name at the end. So on my machine, the path to &lt;code&gt;kiy-labels.txt&lt;/code&gt; is &lt;code&gt;/Users/amoebe/Documents/mind/proj/kiy-ldc/tutorials/annotating-audio-files/your-turn/kiy-labels.txt&lt;/code&gt;.&lt;/p&gt;
&lt;div align = "center"&gt;
&lt;figure&gt;
&lt;img src="/img/2013/06/path-mac.jpg"
alt = "Using Get Info to get the file path in Finder." width = "500"&gt;&lt;br&gt;
&lt;figcaption&gt;Using &lt;tt&gt;Get Info&lt;/tt&gt; to get the file path in &lt;tt&gt;Finder&lt;/tt&gt;.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;In Windows, you can copy the file path too in Explorer using the
command &lt;code&gt;Copy as path&lt;/code&gt;, as described
&lt;a href="http://www.pcworld.com/article/251406/windows_tips_copy_a_file_path_show_or_hide_extensions.html"&gt;here&lt;/a&gt;. Supposedly
this works in Windows Vista, Windows 7, and Windows 8.&lt;/p&gt;
&lt;p&gt;In the shell, the &lt;code&gt;pwd&lt;/code&gt; command will tell print the working directory:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;~/ldc/tutorials/annotating-audio-files/your-turn&lt;span class="o"&gt;](&lt;/span&gt;master *&lt;span class="o"&gt;)&lt;/span&gt;
amoebe@moebius :: ls
&lt;span class="m"&gt;20111213&lt;/span&gt;-2-kiy-ap-framedwordlist.TextGrid.blank            kiy-labels &lt;span class="o"&gt;(&lt;/span&gt;Autosaved&lt;span class="o"&gt;)&lt;/span&gt;.txt
&lt;span class="m"&gt;20111213&lt;/span&gt;-2-kiy-ap-framedwordlist.txt                   kiy-labels-newlines.txt
&lt;span class="m"&gt;20111213&lt;/span&gt;-2-kiy-ap-framedwordlist.wav                   kiy-labels.txt
&lt;span class="m"&gt;20111213&lt;/span&gt;-2-kiy-ap-framedwordlist_item.TextGrid             label_from_text_file2.praat
&lt;span class="m"&gt;20111213&lt;/span&gt;-2-kiy-ap-framedwordlist_item_blank.TextGrid           numeric-labels-newlines.txt
&lt;span class="m"&gt;20111213&lt;/span&gt;-2-kiy-ap-framedwordlist_item_newlines_blank.TextGrid  numeric-labels.txt

&lt;span class="o"&gt;[&lt;/span&gt;~/ldc/tutorials/annotating-audio-files/your-turn&lt;span class="o"&gt;](&lt;/span&gt;master *&lt;span class="o"&gt;)&lt;/span&gt;
amoebe@moebius :: &lt;span class="nb"&gt;pwd&lt;/span&gt;
/Users/amoebe/ldc/tutorials/annotating-audio-files/your-turn
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You can also print the working directory in your command prompt &lt;a href="http://www.brudenossg.com/tip2.php"&gt;as I've done&lt;/a&gt;. &lt;/p&gt;</content><category term="ldc-kiy"></category><category term="fieldwork"></category><category term="praat"></category><category term="tutorial"></category></entry><entry><title>Organizing elicitation items</title><link href="http://kmyu.github.io/blog/organizing-elicitation-items.html" rel="alternate"></link><published>2013-06-23T16:45:00-04:00</published><updated>2013-06-23T16:45:00-04:00</updated><author><name>Kristine Yu</name></author><id>tag:kmyu.github.io,2013-06-23:/blog/organizing-elicitation-items.html</id><summary type="html">&lt;p&gt;In this tutorial, we cover strategies for organizing data within an
elicitation session as well as across elicitation sessions, including:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="#hash"&gt;Using dictionaries as data structures&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#spreadsheet"&gt;Working with spreadsheets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#text"&gt;Working with text files in the shell&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#files"&gt;Organizing files&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- PELICAN_END_SUMMARY --&gt;

&lt;p&gt;The section &lt;a href="#text"&gt;Working with text files in the shell&lt;/a&gt; can be
skipped for …&lt;/p&gt;</summary><content type="html">&lt;p&gt;In this tutorial, we cover strategies for organizing data within an
elicitation session as well as across elicitation sessions, including:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="#hash"&gt;Using dictionaries as data structures&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#spreadsheet"&gt;Working with spreadsheets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#text"&gt;Working with text files in the shell&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#files"&gt;Organizing files&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- PELICAN_END_SUMMARY --&gt;

&lt;p&gt;The section &lt;a href="#text"&gt;Working with text files in the shell&lt;/a&gt; can be
skipped for users that want to stick with working with spreadsheets
rather than working with command-line utilities.&lt;/p&gt;
&lt;p&gt;The files referred to in the tutorial can be found in
&lt;a href="http://media.krisyu.org/ldc-kiy/"&gt;this directory&lt;/a&gt; in
the &lt;code&gt;tutorials/organizing-elicitation-items/&lt;/code&gt; &lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/organizing-elicitation-items/"&gt;sub-directory&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="wzxhzdk28wzxhzdk29using-dictionaries-as-data-structures"&gt;&lt;a id="hash"&gt;&lt;/a&gt;Using dictionaries as data structures&lt;/h2&gt;
&lt;p&gt;Dictionaries are abstract data structures in widespread use in
computer science that associate unique, immutable &lt;strong&gt;keys&lt;/strong&gt; with
&lt;strong&gt;values&lt;/strong&gt;. The idea of a dictionary is useful not only for practical
concerns in organizing a body of elicitation items and sessions, but
also as a way of guiding thinking in fieldwork from elicitation design
to statistical analysis of data.&lt;/p&gt;
&lt;p&gt;Consider as an example the elicitation session represented by
&lt;code&gt;20111213-1-kiy-ap-framedwordlist.txt&lt;/code&gt;. How might we identify each
elicitation item in our corpus of fieldwork data? For instance, take
&lt;em&gt;paRai giRu&lt;/em&gt; `bandicoot's elbow'. During our elicitation session, our
orthographic representation for this was &lt;em&gt;paRai giRu&lt;/em&gt;. It might be
transparent to simply identify this elicitation item as &lt;code&gt;paRai giRu&lt;/code&gt;
and name the soundfile for this item &lt;code&gt;paRai giRu.wav&lt;/code&gt;,&lt;sup id="fnref-1"&gt;&lt;a class="footnote-ref" href="#fn-1"&gt;1&lt;/a&gt;&lt;/sup&gt; but this strategy for
nomenclature could be problematic for the following reasons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;One-to-many mappings&lt;/strong&gt; If we elicited &lt;em&gt;paRai giRu&lt;/em&gt; in another
  elicitation session, what would we call it? If we identified it as
  &lt;em&gt;paRai giRu&lt;/em&gt;, we would have trouble distinguishing the two different
  elicitaiton items (elicited in different elicitation sessions). Or
  what if we elicited &lt;em&gt;paRai giRu&lt;/em&gt; multiple times in a single session?
  One idea would be to include elicitation session and repetition
  information in the identifier,
  e.g. &lt;code&gt;20111213-1-kiy-ap-framedwordlist- paRai giRu - rep 1&lt;/code&gt;. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Mutability.&lt;/strong&gt; What if later down the road, we changed our
  transcription of the item, e.g. if we decided to
  exclusively use IPA transcriptions or to develop a different
  practical orthography? Then we'd have to change our identifier for
  the item everywhere it is referenced. We might also later completely
  change our system for naming files. Changing filenames in either
  case could be a potentially tedious and error-prone process. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Character encoding.&lt;/strong&gt; If we decided to change our transcription to include
  IPA symbols or any other
  non-&lt;a href="http://computer.howstuffworks.com/bytes2.htm"&gt;ASCII&lt;/a&gt;
  characters, the character encoding of the filename might get garbled
  &lt;a href="http://scripts.sil.org/cms/scripts/page.php?item_id=FontFAQ_CrossPlatform"&gt;across platforms&lt;/a&gt;.
  It's safer to restrict characters in filenames to be drawn from the
  &lt;a href="http://www.w3schools.com/tags/ref_ascii.asp"&gt;ASCII character set&lt;/a&gt;. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Association of additional information about elicitation item.&lt;/strong&gt; As we explore the dimensions of tonal
  contrast, there are a number of different variables we might want to
  keep track of for each elicitation item. For instance, for this
  item, we might want to associate the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;elicitation session: 201111213-1-kiy-ap-framedwordlist&lt;/li&gt;
&lt;li&gt;gloss: `bandicoot's elbow'&lt;/li&gt;
&lt;li&gt;tone of first word: T1&lt;/li&gt;
&lt;li&gt;tone of second word: T1&lt;/li&gt;
&lt;li&gt;frame: T1-T1&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We could have a elicitation item nomenclature that would give us a
  identifier like &lt;code&gt;201111213-1-kiy-ap-framedwordlist - paRai giRu -
  bandicoot's elbow - T1 - T1&lt;/code&gt;.
  Later on, as we learn more about Kirikiri, there might be still
  additional information we'd like to associate. We could encode this
  information in the filename, but the filename could get very long,
  and we'd have to change the filename if we decided to change what
  information we wanted to associate. We might also change the values
  for the individual fields of association, e.g. perhaps we might
  hypothesize later that T1 actually should be split into two distinct
  tonemes, T1a and T1b. Then we'd need to change the values of &lt;em&gt;tone
  of first word&lt;/em&gt;, &lt;em&gt;tone of second word&lt;/em&gt;, and &lt;em&gt;frame&lt;/em&gt; for many
  elicitation items, another instance of the problem of mutability.&lt;/p&gt;
&lt;p&gt;One good solution to these problems is to use the dictionary data
structure for keeping track of elicitation items. &lt;/p&gt;
&lt;h3 id="barcodes-for-elicitation-items"&gt;Barcodes for elicitation items&lt;/h3&gt;
&lt;p align="center"&gt;
&lt;a href="/img/2013/06/codigobarras.svg"&gt;&lt;img style = "float:middle" class="size-full"
alt="Barcode image from http://openclipart.org/detail/81883/codigde-barras--by-asrafil" src="/img/2013/06/codigobarras.svg" width="200" /&gt;&lt;/a&gt; 
&lt;/p&gt;

&lt;p&gt;An alternative to identifiers like &lt;code&gt;201111213-1-kiy-ap-framedwordlist - paRai giRu -
  bandicoot's elbow - T1 - T1&lt;/code&gt;, is to use &lt;strong&gt;keys&lt;/strong&gt;---to assign
a unique, immutable barcode to each elicitation item and keep track of
  elicitation items using the dictionary data structure. Any additional
  information can be associated to the elicitation item via the
  barcode. Even if the additional information associated changes, the
  identifier for the elicitation item remains constant. The associated
  information can be held in a spreadsheet, associated to the unique
  identifiers. The columns in the spreadsheet with the associated
  information may change, but the identifiers and filenames remain constant.&lt;/p&gt;
&lt;p&gt;In this section, we give some tips for generating tables with
the &lt;strong&gt;values&lt;/strong&gt; associated with the &lt;strong&gt;keys&lt;/strong&gt; for elicitation
items. First, we'll discuss generating tables in spreadsheets in Excel. Then
we'll discuss generating tables in text files.&lt;/p&gt;
&lt;p&gt;We give two example tables below,&lt;sup id="fnref-3"&gt;&lt;a class="footnote-ref" href="#fn-3"&gt;3&lt;/a&gt;&lt;/sup&gt; where the keys are listed in the
&lt;code&gt;item&lt;/code&gt; column as integers 1, 2, 3, 4, 5, .... These keys are really
shorthand for keys like &lt;code&gt;20111213-1-kiy-ap-framedwordlist-1&lt;/code&gt;,
&lt;code&gt;20111213-1-kiy-ap-framedwordlist-2&lt;/code&gt;, etc., which are the full keys used for
file naming, e.g. &lt;code&gt;20111213-1-kiy-ap-framedwordlist-1.wav&lt;/code&gt;.
Table 1 shows an extract from the dictionary for
20111213-1-kiy-ap-framedwordlist, from the text file
&lt;code&gt;20111213-1-kiy-ap-framedwordlist.txt&lt;/code&gt;
&lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/organizing-elicitation-items/20111213-1-kiy-ap-framedwordlist.txt"&gt;here&lt;/a&gt;. Table
2 shows an extract from the spreadsheet
&lt;code&gt;20111215-2-kiy-ap-framedwordlist.xlsx&lt;/code&gt;, available
&lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/organizing-elicitation-items/20111215-2-kiy-ap-framedwordlist.xlsx"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We'll use &lt;code&gt;20111215-2-kiy-ap-framedwordlist.xlsx&lt;/code&gt; to demonstrate some
tips for efficiency and semi-automated entry in working with
spreadsheets. We use Microsoft Excel for demonstration, but similar
approaches are available in other spreadsheet software programs.&lt;/p&gt;
&lt;h3 id="example-tables-illustrating-dictionary-data-structures-for-organizing-elicitation-items"&gt;Example tables illustrating dictionary data structures for organizing elicitation items&lt;/h3&gt;
&lt;table&gt;
    &lt;caption&gt;Table 1: Extract from 20111213-1-kiy-ap-framedwordlist dictionary&lt;/caption&gt;
    &lt;thead&gt;
    &lt;tr&gt;
        &lt;td&gt;item&lt;/td&gt;
        &lt;td&gt;kirikiri&lt;/td&gt;
        &lt;td&gt;gloss&lt;/td&gt;
        &lt;td&gt;tone1&lt;/td&gt;
        &lt;td&gt;tone2&lt;/td&gt;
        &lt;td&gt;frame&lt;/td&gt;
        &lt;td&gt;word1&lt;/td&gt;
        &lt;td&gt;word2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
        &lt;td&gt;1&lt;/td&gt;
        &lt;td&gt;paRai giRu&lt;/td&gt;
        &lt;td&gt;bandicoot's elbow&lt;/td&gt;
        &lt;td&gt;T1&lt;/td&gt;
        &lt;td&gt;T1&lt;/td&gt;
        &lt;td&gt;11&lt;/td&gt;
        &lt;td&gt;paRai&lt;/td&gt;
        &lt;td&gt;giRu&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;2&lt;/td&gt;
        &lt;td&gt;kaza giRu&lt;/td&gt;
        &lt;td&gt;gecko's elbow&lt;/td&gt;
        &lt;td&gt;T2&lt;/td&gt;
        &lt;td&gt;T1&lt;/td&gt;
        &lt;td&gt;21&lt;/td&gt;
        &lt;td&gt;kaza&lt;/td&gt;
        &lt;td&gt;giRu&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;3&lt;/td&gt;
        &lt;td&gt;fivaa giRu&lt;/td&gt;
        &lt;td&gt;snail's elbow&lt;/td&gt;
        &lt;td&gt;T3&lt;/td&gt;
        &lt;td&gt;T1&lt;/td&gt;
        &lt;td&gt;31&lt;/td&gt;
        &lt;td&gt;fivaa&lt;/td&gt;
        &lt;td&gt;giRu&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;4&lt;/td&gt;
        &lt;td&gt;naraa giRu&lt;/td&gt;
        &lt;td&gt;wasp's elbow&lt;/td&gt;
        &lt;td&gt;T4&lt;/td&gt;
        &lt;td&gt;T1&lt;/td&gt;
        &lt;td&gt;41&lt;/td&gt;
        &lt;td&gt;naraa&lt;/td&gt;
        &lt;td&gt;giRu&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;5&lt;/td&gt;
        &lt;td&gt;tava giRu&lt;/td&gt;
        &lt;td&gt;catfish's elbow&lt;/td&gt;
        &lt;td&gt;T5&lt;/td&gt;
        &lt;td&gt;T1&lt;/td&gt;
        &lt;td&gt;51&lt;/td&gt;
        &lt;td&gt;tava&lt;/td&gt;
        &lt;td&gt;giRu&lt;/td&gt;
    &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
    &lt;caption&gt;Table 2: Extract from 20111215-2-kiy-ap-framedwordlist dictionary&lt;/caption&gt;
    &lt;thead&gt;
    &lt;tr&gt;
        &lt;td&gt;item&lt;/td&gt;
        &lt;td&gt;word.1&lt;/td&gt;
        &lt;td&gt;word.2&lt;/td&gt;
        &lt;td&gt;verb&lt;/td&gt;
        &lt;td&gt;gloss.1&lt;/td&gt;
        &lt;td&gt;gloss.2&lt;/td&gt;
        &lt;td&gt;gloss.verb&lt;/td&gt;
        &lt;td&gt;tone.1&lt;/td&gt;
        &lt;td&gt;tone.2&lt;/td&gt;
        &lt;td&gt;bitone&lt;/td&gt;
        &lt;td&gt;sent.kiy&lt;/td&gt;
        &lt;td&gt;sent.eng&lt;/td&gt;
    &lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
    &lt;tr&gt;
        &lt;td&gt;1&lt;/td&gt;
        &lt;td&gt;kE&lt;/td&gt;
        &lt;td&gt;ndE&lt;/td&gt;
        &lt;td&gt;fuwa&lt;/td&gt;
        &lt;td&gt;ant&lt;/td&gt;
        &lt;td&gt;centipede&lt;/td&gt;
        &lt;td&gt;sees&lt;/td&gt;
        &lt;td&gt;T1&lt;/td&gt;
        &lt;td&gt;T1&lt;/td&gt;
        &lt;td&gt;T1.T1&lt;/td&gt;
        &lt;td&gt;kE ndE fuwa.&lt;/td&gt;
        &lt;td&gt;The ant sees the centipede.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;2&lt;/td&gt;
        &lt;td&gt;kE&lt;/td&gt;
        &lt;td&gt;fa&lt;/td&gt;
        &lt;td&gt;fuwa&lt;/td&gt;
        &lt;td&gt;ant&lt;/td&gt;
        &lt;td&gt;younger.sibling&lt;/td&gt;
        &lt;td&gt;sees&lt;/td&gt;
        &lt;td&gt;T1&lt;/td&gt;
        &lt;td&gt;T2&lt;/td&gt;
        &lt;td&gt;T1.T2&lt;/td&gt;
        &lt;td&gt;kE fa fuwa.&lt;/td&gt;
        &lt;td&gt;The ant sees the younger.sibling.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;3&lt;/td&gt;
        &lt;td&gt;kE&lt;/td&gt;
        &lt;td&gt;nO&lt;/td&gt;
        &lt;td&gt;fuwa&lt;/td&gt;
        &lt;td&gt;ant&lt;/td&gt;
        &lt;td&gt;meat&lt;/td&gt;
        &lt;td&gt;sees&lt;/td&gt;
        &lt;td&gt;T1&lt;/td&gt;
        &lt;td&gt;T2&lt;/td&gt;
        &lt;td&gt;T1.T2&lt;/td&gt;
        &lt;td&gt;kE nO fuwa.&lt;/td&gt;
        &lt;td&gt;The ant sees the meat.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;4&lt;/td&gt;
        &lt;td&gt;kE&lt;/td&gt;
        &lt;td&gt;fO&lt;/td&gt;
        &lt;td&gt;fuwa&lt;/td&gt;
        &lt;td&gt;ant&lt;/td&gt;
        &lt;td&gt;wallaby&lt;/td&gt;
        &lt;td&gt;sees&lt;/td&gt;
        &lt;td&gt;T1&lt;/td&gt;
        &lt;td&gt;T3&lt;/td&gt;
        &lt;td&gt;T1.T3&lt;/td&gt;
        &lt;td&gt;kE fO fuwa.&lt;/td&gt;
        &lt;td&gt;The ant sees the wallaby.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;5&lt;/td&gt;
        &lt;td&gt;kE&lt;/td&gt;
        &lt;td&gt;fO&lt;/td&gt;
        &lt;td&gt;fuwa&lt;/td&gt;
        &lt;td&gt;ant&lt;/td&gt;
        &lt;td&gt;honeybee&lt;/td&gt;
        &lt;td&gt;sees&lt;/td&gt;
        &lt;td&gt;T1&lt;/td&gt;
        &lt;td&gt;T3&lt;/td&gt;
        &lt;td&gt;T1.T3&lt;/td&gt;
        &lt;td&gt;kE fO fuwa.&lt;/td&gt;
        &lt;td&gt;The ant sees the honeybee.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;6&lt;/td&gt;
        &lt;td&gt;kE&lt;/td&gt;
        &lt;td&gt;ya&lt;/td&gt;
        &lt;td&gt;fuwa&lt;/td&gt;
        &lt;td&gt;ant&lt;/td&gt;
        &lt;td&gt;mother&lt;/td&gt;
        &lt;td&gt;sees&lt;/td&gt;
        &lt;td&gt;T1&lt;/td&gt;
        &lt;td&gt;T5&lt;/td&gt;
        &lt;td&gt;T1.T5&lt;/td&gt;
        &lt;td&gt;kE ya fuwa.&lt;/td&gt;
        &lt;td&gt;The ant sees the mother.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;7&lt;/td&gt;
        &lt;td&gt;kE&lt;/td&gt;
        &lt;td&gt;fa&lt;/td&gt;
        &lt;td&gt;fuwa&lt;/td&gt;
        &lt;td&gt;ant&lt;/td&gt;
        &lt;td&gt;sago.grub&lt;/td&gt;
        &lt;td&gt;sees&lt;/td&gt;
        &lt;td&gt;T1&lt;/td&gt;
        &lt;td&gt;T5&lt;/td&gt;
        &lt;td&gt;T1.T5&lt;/td&gt;
        &lt;td&gt;kE fa fuwa.&lt;/td&gt;
        &lt;td&gt;The ant sees the sago.grub.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;8&lt;/td&gt;
        &lt;td&gt;ndE&lt;/td&gt;
        &lt;td&gt;kE&lt;/td&gt;
        &lt;td&gt;fuwa&lt;/td&gt;
        &lt;td&gt;centipede&lt;/td&gt;
        &lt;td&gt;ant&lt;/td&gt;
        &lt;td&gt;sees&lt;/td&gt;
        &lt;td&gt;T1&lt;/td&gt;
        &lt;td&gt;T1&lt;/td&gt;
        &lt;td&gt;T1.T1&lt;/td&gt;
        &lt;td&gt;ndE kE fuwa.&lt;/td&gt;
        &lt;td&gt;The centipede sees the ant.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;9&lt;/td&gt;
        &lt;td&gt;ndE&lt;/td&gt;
        &lt;td&gt;fa&lt;/td&gt;
        &lt;td&gt;fuwa&lt;/td&gt;
        &lt;td&gt;centipede&lt;/td&gt;
        &lt;td&gt;younger.sibling&lt;/td&gt;
        &lt;td&gt;sees&lt;/td&gt;
        &lt;td&gt;T1&lt;/td&gt;
        &lt;td&gt;T2&lt;/td&gt;
        &lt;td&gt;T1.T2&lt;/td&gt;
        &lt;td&gt;ndE fa fuwa.&lt;/td&gt;
        &lt;td&gt;The centipede sees the younger.sibling.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;10&lt;/td&gt;
        &lt;td&gt;ndE&lt;/td&gt;
        &lt;td&gt;nO&lt;/td&gt;
        &lt;td&gt;fuwa&lt;/td&gt;
        &lt;td&gt;centipede&lt;/td&gt;
        &lt;td&gt;meat&lt;/td&gt;
        &lt;td&gt;sees&lt;/td&gt;
        &lt;td&gt;T1&lt;/td&gt;
        &lt;td&gt;T2&lt;/td&gt;
        &lt;td&gt;T1.T2&lt;/td&gt;
        &lt;td&gt;ndE nO fuwa.&lt;/td&gt;
        &lt;td&gt;The centipede sees the meat.&lt;/td&gt;
    &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;hr&gt;
&lt;h2 id="wzxhzdk30wzxhzdk31working-with-spreadsheets"&gt;&lt;a id="spreadsheet"&gt;&lt;/a&gt;Working with spreadsheets&lt;/h2&gt;
&lt;p&gt;For Table 2 above, we only filled in a portion of the columns by
hand. Many of the columns are fully specified by other columns. For
instance, &lt;code&gt;sent.kiy&lt;/code&gt; entries are simply concatenated from &lt;code&gt;tone.1&lt;/code&gt; and
&lt;code&gt;tone.2&lt;/code&gt; entries. Such fully specified columns can be automatically
filled in, as we demonstrate below. &lt;/p&gt;
&lt;p&gt;To follow along, download
&lt;code&gt;20111215-2-kiy-ap-framedwordlist-initial.xlsx&lt;/code&gt;
&lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/organizing-elicitation-items/20111215-2-kiy-ap-framedwordlist-initial.xlsx"&gt;here&lt;/a&gt;. We'll
show how the columns &lt;code&gt;bitone&lt;/code&gt;, &lt;code&gt;sent.kiy&lt;/code&gt; and &lt;code&gt;sent.eng&lt;/code&gt; can all be filled in
automatically from other columns using the &lt;code&gt;CONCATENATE&lt;/code&gt; command.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Filling in the &lt;strong&gt;bitone&lt;/strong&gt; entries&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;code&gt;bitone&lt;/code&gt; entry is simply the concatenation of &lt;code&gt;tone.1&lt;/code&gt; and
&lt;code&gt;tone.2&lt;/code&gt;. We can generate the bitone entries automatically by clicking
on Cell J2, the first cell in the bitone column, and typing
the following command and hitting &lt;code&gt;Return&lt;/code&gt;/&lt;code&gt;Enter&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# Concatenate the TONE.1 entry, a period, and the TONE.2 entry
=CONCATENATE([@[tone.1]],&amp;quot;.&amp;quot;,[@[tone.2]])
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The period serves as a delimiter between the two tones. We can then
&lt;em&gt;fill down&lt;/em&gt; this command down the entire bitone column by hovering the
mouse at the bottom right hand corner of Cell J2 and double-clicking. We show a screenshot of the command in the spreadsheet below. Click
on the image to open a new window with a larger sized version of the image.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/2013/05/20111215-2-kiy-ap-concat-bitone.png"&gt;&lt;img
    class="size-full wp-image-135" alt="Concatenating bitones"
    src="/img/2013/05/20111215-2-kiy-ap-concat-bitone.png" width="800" /&gt;&lt;/a&gt; &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Filling in the &lt;strong&gt;sent.kiy&lt;/strong&gt; entries&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Similarly, we can generate the &lt;code&gt;sent.kiy&lt;/code&gt; entries from concatenating
the &lt;code&gt;word.1&lt;/code&gt;, &lt;code&gt;word.2&lt;/code&gt;, and &lt;code&gt;verb&lt;/code&gt; entries, with some space delimiters
and an ending period:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# Concatenate the WORD.1 entry, a space, the WORD.2 entry, a space, the VERB entry, and a period.
=CONCATENATE([@[word.1]],&amp;quot; &amp;quot;,[@[word.2]],&amp;quot; &amp;quot;,[@verb],&amp;quot;.&amp;quot;)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We show a screenshot of the command in the spreadsheet below. Click
on the image to open a new window with a larger sized version of the image.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/2013/05/20111215-2-kiy-ap-concat-sent-kiy.png"&gt;&lt;img
class="size-full wp-image-135" alt="Concatenating Kirikiri sentences"
src="/img/2013/05/20111215-2-kiy-ap-concat-sent-kiy.png"
width="800" /&gt;&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Filling in the &lt;strong&gt;sent.eng&lt;/strong&gt; entries&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Finally, we can fill in the &lt;code&gt;sent.eng&lt;/code&gt; entries by concatenating
&lt;code&gt;gloss.1&lt;/code&gt;, &lt;code&gt;gloss.verb&lt;/code&gt;, and &lt;code&gt;gloss.2&lt;/code&gt;, plus an additional determiner
"the" and some spaces and an ending period:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# Concatenate &amp;quot;The &amp;quot;, the GLOSS.1 entry, a space, the GLOSS.VERB entry, a space, &amp;quot;the&amp;quot;, the GLOSS.2 entry, and a period.
=CONCATENATE(&amp;quot;The &amp;quot;,[@[gloss.1]],&amp;quot; &amp;quot;, [@[gloss.verb]],&amp;quot; &amp;quot;,&amp;quot;the &amp;quot;, [@[gloss.2]], &amp;quot;.&amp;quot;)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We show a screenshot of the command in the spreadsheet below. Click
on the image to open a new window with a larger sized version of the image.&lt;/p&gt;
&lt;p&gt;&lt;a href="/img/2013/05/20111215-2-kiy-ap-concat-sent-eng.png"&gt;&lt;img
class="size-full wp-image-135" alt="Concatenating English sentences"
src="/img/2013/05/20111215-2-kiy-ap-concat-sent-eng.png"
width="800" /&gt;&lt;/a&gt; &lt;/p&gt;
&lt;p&gt;The &lt;em&gt;fill down&lt;/em&gt; trick also works for the &lt;code&gt;item&lt;/code&gt; column. If you type
the first few rows in (1, 2, 3) and then click and drag to select
those three cells, you can use the same &lt;em&gt;fill down&lt;/em&gt; trick described
above to fill in the rest of the item entries.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="wzxhzdk42wzxhzdk43working-with-text-files-in-the-shell"&gt;&lt;a id="text"&gt;&lt;/a&gt;Working with text files in the shell&lt;/h2&gt;
&lt;p&gt;For command line aficionados (see
&lt;a href="..//processing-audio-files-sox/#intro"&gt;the introductory section&lt;/a&gt;
of
&lt;a href="..//processing-audio-files-sox/"&gt;Processing audio files (with SoX)&lt;/a&gt;
for more on the command line), an alternative to working with
spreadsheet software programs like Excel is to work directly with text
files from the command line. Here we'll show how to do the same steps
as above in Excel at the command line, beginning with converting text
file line endings across platforms.&lt;/p&gt;
&lt;h3 id="text-file-formats-and-line-endings"&gt;Text file formats and line endings&lt;/h3&gt;
&lt;p&gt;A common issue that comes up in dealing with text files is that there
are
&lt;a href="http://www.rfc-editor.org/EOLstory.txt"&gt;different characters&lt;/a&gt; &lt;a href="http://www.codinghorror.com/blog/2010/01/the-great-newline-schism.html"&gt;for line endings&lt;/a&gt;,
i.e. newline characters, across platforms.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;organizing-elicitation-items/&lt;/code&gt; directory contains three
tab-delimited text files and two CSV (comma separated values) files:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;amoebe@moebius :: ls *.txt*
&lt;span class="m"&gt;20111213&lt;/span&gt;-1-kiy-ap-framedwordlist.txt       &lt;span class="m"&gt;20111215&lt;/span&gt;-2-kiy-ap-framedwordlist.txt.unix
&lt;span class="m"&gt;20111215&lt;/span&gt;-2-kiy-ap-framedwordlist.txt

amoebe@moebius :: ls *.csv*
&lt;span class="m"&gt;20111215&lt;/span&gt;-2-kiy-ap-framedwordlist.csv       &lt;span class="m"&gt;20111215&lt;/span&gt;-2-kiy-ap-framedwordlist.csv.unix
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The files with the &lt;code&gt;.unix&lt;/code&gt; suffix have been converted to have UNIX
line endings, while the files with just a &lt;code&gt;.txt&lt;/code&gt; or &lt;code&gt;.csv&lt;/code&gt; suffix were
generated in Microsoft Excel using &lt;code&gt;File &amp;gt; Save As&lt;/code&gt; and have Mac line
endings. If we do a simple &lt;code&gt;cat&lt;/code&gt; command to display
&lt;code&gt;20111215-2-kiy-ap-framedwordlist.txt&lt;/code&gt;, the output looks funny---it's
a single line (you need to drag the scroll bar at the bottom of the
code snippet window in order to see this!).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Extract from output of cat command&lt;/span&gt;
amoebe@moebius :: cat &lt;span class="m"&gt;20111215&lt;/span&gt;-2-kiy-ap-framedwordlist.txt
1tem    kErd.1  ndEd.2  fuwa    antss.1 centipedeloss.vesees    T1ne.1  T1ne.2  T1.T1e  kE ndE fuwa.    The ant se2s the ckEtipedefa    fuwa    ant younger.sibling sees    T1  T2  T1.T2   kE fa fuwa. The ant se3s the ykEnger.snOling. fuwa  ant meat    sees    T1  T2  T1.T2   kE nO fuwa. The ant sees the m4at.    kE    fO  fuwa    ant wallaby sees    T1  T3  T1.T3   kE fO fuwa. The ant sees the w5llaby. kE    fO  fuwa    ant honeybee    sees    T1  T3  T1.T3   kE fO fuwa. The ant se6s the hkEeybee.ya    fuwa    ant mother  sees    T1  T5  T1.T5   kE ya fuwa. The ant sees the m7ther.  kE    fa  fuwa    ant sago.grub   sees    T1  T5  T1.T5   kE fa fuwa. The ant se&lt;span class="sb"&gt;```&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If we invoke &lt;code&gt;cat -v&lt;/code&gt; to display non-printing characters, we can see
that line endings are delimited with &lt;code&gt;^M&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Extract from output of cat -v command which prints non-printing characters&lt;/span&gt;
amoebe@moebius :: cat -v &lt;span class="m"&gt;20111215&lt;/span&gt;-2-kiy-ap-framedwordlist.txt
item    word.1  word.2  verb    gloss.1 gloss.2 gloss.verb  tone.1  tone.2  bitone  sent.kiy    sent.eng^M1 kE  ndE fuwa    ant centipede   sees    T1  T1  T1.T1   kE ndE fuwa.    The ant sees the centipede.^M2  kE  fa  fuwa    ant younger.sibling sees    T1  T2  T1.T2   kE fa fuwa. The ant sees the younger.sibling.^M3    kE  nO  fuwa    ant meat    sees    T1  T2  T1.T2   kE nO fuwa. The ant sees the meat.^M4   kE  fO  fuwa    ant wallaby sees    T1  TT1.T3  kE fO fuwa. The ant sees the wallaby.^M5    kE  fO  fuwa    ant honeybee    sees    TT3 T1.T3   kE fO fuwa. The ant sees the honeybee.^M
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;These are non-UNIX line endings used for Mac as well as
Windows/DOS. Fortunately, we can convert the line endings using a
variety of command-line utilities, such as the dedicated utility
&lt;a href="https://ccrma.stanford.edu/~craig/utility/flip/"&gt;flip&lt;/a&gt;,&lt;sup id="fnref-3"&gt;&lt;a class="footnote-ref" href="#fn-3"&gt;3&lt;/a&gt;&lt;/sup&gt; as well as
&lt;a href="http://kb.iu.edu/data/acux.html"&gt;standard&lt;/a&gt;
&lt;a href="http://hints.macworld.com/article.php?story=20001206164827794"&gt;command&lt;/a&gt;
&lt;a href="http://superuser.com/questions/71507/convert-unix-line-endings-to-windows"&gt;utilities&lt;/a&gt;
like &lt;code&gt;tr&lt;/code&gt;, &lt;code&gt;awk&lt;/code&gt;, and &lt;code&gt;sed&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Below, we'll demonstrate using &lt;code&gt;flip&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;amoebe@moebius :: flip

Usage: flip [-t|-u|-d|-m] filename[s]
   Converts ASCII files between Unix, MS-DOS/Windows, or Macintosh newline formats

   Options: 
      -u  =  convert file(s) to Unix newline format (newline)
      -d  =  convert file(s) to MS-DOS/Windows newline format (linefeed + newline)
      -m  =  convert file(s) to Macintosh newline format (linefeed)
      -t  =  display current file type, no file modifications
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Warning:
&lt;code&gt;flip&lt;/code&gt; converts files in place, i.e., it overwrites the original file
with the modified file with converted line endings.&lt;/strong&gt; You can find the
&lt;code&gt;flip&lt;/code&gt; executable in the &lt;code&gt;flip/&lt;/code&gt; directory in
&lt;code&gt;tutorials/organizing-elicitation-items/&lt;/code&gt;, which I compiled from
&lt;a href="https://ccrma.stanford.edu/~craig/utility/flip/flip.cpp"&gt;source&lt;/a&gt;
using the C++ compiler &lt;code&gt;g++&lt;/code&gt; on Mac OSX:&lt;sup id="fnref-4"&gt;&lt;a class="footnote-ref" href="#fn-4"&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;g++ -o flip flip.cpp
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You can copy the &lt;code&gt;flip&lt;/code&gt; executable to a directory in your PATH such as
&lt;code&gt;/usr/local/bin/&lt;/code&gt;, or you can run it from the &lt;code&gt;flip/&lt;/code&gt; directory by
invoking &lt;code&gt;./flip&lt;/code&gt;. Below we show using &lt;code&gt;flip -u&lt;/code&gt; to convert the MAC
line endings to UNIX line endings. Since &lt;code&gt;flip&lt;/code&gt; converts the line
endings in the orginal file and overwrites it, we first copy the text
files to new text files named with &lt;code&gt;.unix&lt;/code&gt; suffixes.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Convert line endings from Mac to Unix for tab-delimited file&lt;/span&gt;
cp &lt;span class="m"&gt;20111215&lt;/span&gt;-2-kiy-ap-framedwordlist.txt &lt;span class="m"&gt;20111215&lt;/span&gt;-2-kiy-ap-framedwordlist.txt.unix
flip -u &lt;span class="m"&gt;20111215&lt;/span&gt;-2-kiy-ap-framedwordlist.txt.unix

&lt;span class="c1"&gt;# Convert line endings from Mac to Unix for CSV file&lt;/span&gt;
cp &lt;span class="m"&gt;20111215&lt;/span&gt;-2-kiy-ap-framedwordlist.csv &lt;span class="m"&gt;20111215&lt;/span&gt;-2-kiy-ap-framedwordlist.csv.unix
flip -u &lt;span class="m"&gt;20111215&lt;/span&gt;-2-kiy-ap-framedwordlist.csv.unix
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now the output of &lt;code&gt;cat&lt;/code&gt; prints with proper line breaks:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Extract from output of cat command after flip line ending conversion&lt;/span&gt;
amoebe@moebius :: cat &lt;span class="m"&gt;20111215&lt;/span&gt;-2-kiy-ap-framedwordlist.txt.unix
item    word.1  word.2  verb    gloss.1 gloss.2 gloss.verb  tone.1  tone.2  bitone  sent.kiy    sent.eng
&lt;span class="m"&gt;1&lt;/span&gt;   kE  ndE fuwa    ant centipede   sees    T1  T1  T1.T1   kE ndE fuwa.    The ant sees the centipede.
&lt;span class="m"&gt;2&lt;/span&gt;   kE  fa  fuwa    ant younger.sibling sees    T1  T2  T1.T2   kE fa fuwa. The ant sees the younger.sibling.
&lt;span class="m"&gt;3&lt;/span&gt;   kE  nO  fuwa    ant meat    sees    T1  T2  T1.T2   kE nO fuwa. The ant sees the meat.
&lt;span class="m"&gt;4&lt;/span&gt;   kE  fO  fuwa    ant wallaby sees    T1  T3  T1.T3   kE fO fuwa. The ant sees the wallaby.
&lt;span class="m"&gt;5&lt;/span&gt;   kE  fO  fuwa    ant honeybee    sees    T1  T3  T1.T3   kE fO fuwa. The ant sees the honeybee.
&lt;/pre&gt;&lt;/div&gt;


&lt;h3 id="command-line-utilities-for-adding-associated-information"&gt;Command-line utilities for adding associated information&lt;/h3&gt;
&lt;p&gt;We'll demonstrate using command-line utilities for adding associated
information with &lt;code&gt;20111215-2-kiy-ap-framedwordlist&lt;/code&gt;.
Let's start with just the first nine columns, &lt;code&gt;item&lt;/code&gt;, &lt;code&gt;word.1&lt;/code&gt;,
&lt;code&gt;word.2&lt;/code&gt;, &lt;code&gt;verb&lt;/code&gt;, &lt;code&gt;gloss.1&lt;/code&gt;, &lt;code&gt;gloss.2&lt;/code&gt;, &lt;code&gt;gloss.verb&lt;/code&gt;, &lt;code&gt;tone.1&lt;/code&gt;, and
&lt;code&gt;tone.2&lt;/code&gt;, which we write to the file
&lt;code&gt;20111215-2-kiy-ap-framedwordlist-initial.txt&lt;/code&gt;. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Extract only columns that can&amp;#39;t be automatically filled in, columns 1-9&lt;/span&gt;
&lt;span class="c1"&gt;# Write to file 20111215-2-kiy-ap-framedwordlist-initial.txt&lt;/span&gt;
cut -f1-9 &lt;span class="m"&gt;20111215&lt;/span&gt;-2-kiy-ap-framedwordlist.txt.unix &amp;gt; &lt;span class="m"&gt;20111215&lt;/span&gt;-2-kiy-ap-framedwordlist-initial.txt
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now how can we generate &lt;code&gt;bitone&lt;/code&gt;, &lt;code&gt;sent.kiy&lt;/code&gt;, and &lt;code&gt;sent.eng&lt;/code&gt;? One way
is to use the &lt;a href="http://www.grymoire.com/Unix/Awk.html"&gt;&lt;code&gt;awk&lt;/code&gt; command utility&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;To generate the &lt;code&gt;bitone&lt;/code&gt; column, we invoke the following command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# -F &amp;quot;\t&amp;quot; indicates that the input file is tab-delimited&lt;/span&gt;
&lt;span class="c1"&gt;# $0 indicates all fields, so print $0 prints all columns (fields) in the file&lt;/span&gt;
&lt;span class="c1"&gt;# We also print a tab-character between the original columns $0 and the new column &lt;/span&gt;
&lt;span class="c1"&gt;# We pipe the output through head -3 to print just the first 3 lines of the output file&lt;/span&gt;

&lt;span class="c1"&gt;# $8.&amp;quot;$9 indicates field 8, followed by a &amp;quot;.&amp;quot;, followed by field 9&lt;/span&gt;
awk -F &lt;span class="s2"&gt;&amp;quot;\t&amp;quot;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;{print $0,&amp;quot;\t&amp;quot;$8&amp;quot;.&amp;quot;$9}&amp;#39;&lt;/span&gt; &lt;span class="m"&gt;20111215&lt;/span&gt;-2-kiy-ap-framedwordlist-initial.txt &lt;span class="p"&gt;|&lt;/span&gt; head -3
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;to get the output:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;amoebe@moebius :: awk -F &lt;span class="s2"&gt;&amp;quot;\t&amp;quot;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;{print $0,&amp;quot;\t&amp;quot;$8&amp;quot;.&amp;quot;$9}&amp;#39;&lt;/span&gt; &lt;span class="m"&gt;20111215&lt;/span&gt;-2-kiy-ap-framedwordlist-initial.txt &lt;span class="p"&gt;|&lt;/span&gt; head -3
item    word.1  word.2  verb    gloss.1 gloss.2 gloss.verb  tone.1  tone.2  tone.1.tone.2
&lt;span class="m"&gt;1&lt;/span&gt;   kE  ndE fuwa    ant centipede   sees    T1  T1  T1.T1
&lt;span class="m"&gt;2&lt;/span&gt;   kE  fa  fuwa    ant younger.sibling sees    T1  T2  T1.T2
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;To generate the &lt;code&gt;sent.kiy&lt;/code&gt; column, we can invoke:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# $2, $3, $4 indicates field 2 followed by field 3 followed by field,&lt;/span&gt;
&lt;span class="c1"&gt;#  with each field delimited by spaces (the default delimiter for awk)&lt;/span&gt;

awk -F &lt;span class="s2"&gt;&amp;quot;\t&amp;quot;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;{print $0,&amp;quot;\t&amp;quot;$2,$3,$4}&amp;#39;&lt;/span&gt; &lt;span class="m"&gt;20111215&lt;/span&gt;-2-kiy-ap-framedwordlist-initial.txt &lt;span class="p"&gt;|&lt;/span&gt; head -3
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This generates the output:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;amoebe@moebius :: awk -F &lt;span class="s2"&gt;&amp;quot;\t&amp;quot;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;{print $0,&amp;quot;\t&amp;quot;$2,$3,$4}&amp;#39;&lt;/span&gt; &lt;span class="m"&gt;20111215&lt;/span&gt;-2-kiy-ap-framedwordlist-initial.txt &lt;span class="p"&gt;|&lt;/span&gt; head -3
item    word.1  word.2  verb    gloss.1 gloss.2 gloss.verb  tone.1  tone.2  word.1 word.2 verb
&lt;span class="m"&gt;1&lt;/span&gt;   kE  ndE fuwa    ant centipede   sees    T1  T1  kE ndE fuwa
&lt;span class="m"&gt;2&lt;/span&gt;   kE  fa  fuwa    ant younger.sibling sees    T1  T2  kE fa fuwa
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Finally, we generate the &lt;code&gt;sent.eng&lt;/code&gt; column as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# This is similar to the previous command, but with some &amp;quot;the&amp;quot;&amp;#39;s&lt;/span&gt;
&lt;span class="c1"&gt;# concatenated in&lt;/span&gt;
awk -F &lt;span class="s2"&gt;&amp;quot;\t&amp;quot;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;{print $0,&amp;quot;\t&amp;quot;&amp;quot;The&amp;quot;, $5, $7, &amp;quot;the&amp;quot;, $6&amp;quot;.&amp;quot;}&amp;#39;&lt;/span&gt; &lt;span class="m"&gt;20111215&lt;/span&gt;-2-kiy-ap-framedwordlist-initial.txt &lt;span class="p"&gt;|&lt;/span&gt; head -3
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;with the output:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;amoebe@moebius :: awk -F &lt;span class="s2"&gt;&amp;quot;\t&amp;quot;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;{print $0,&amp;quot;\t&amp;quot;&amp;quot;The&amp;quot;, $5, $7, &amp;quot;the&amp;quot;, $6&amp;quot;.&amp;quot;}&amp;#39;&lt;/span&gt; &lt;span class="m"&gt;20111215&lt;/span&gt;-2-kiy-ap-framedwordlist-initial.txt &lt;span class="p"&gt;|&lt;/span&gt; head -3
item    word.1  word.2  verb    gloss.1 gloss.2 gloss.verb  tone.1  tone.2  The gloss.1 gloss.verb the gloss.2.
&lt;span class="m"&gt;1&lt;/span&gt;   kE  ndE fuwa    ant centipede   sees    T1  T1  The ant sees the centipede.
&lt;span class="m"&gt;2&lt;/span&gt;   kE  fa  fuwa    ant younger.sibling sees    T1  T2  The ant sees the younger.sibling.
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;One (verbose) way to chain these commands is to pipe them to each
other. We can redirect the output to the file &lt;code&gt;20111215-2-kiy-ap-framedwordlist-new.txt&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;awk -F &lt;span class="s2"&gt;&amp;quot;\t&amp;quot;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;{print $0,&amp;quot;\t&amp;quot;$8&amp;quot;.&amp;quot;$9}&amp;#39;&lt;/span&gt; &lt;span class="m"&gt;20111215&lt;/span&gt;-2-kiy-ap-framedwordlist-initial.txt &lt;span class="p"&gt;|&lt;/span&gt; awk -F &lt;span class="s2"&gt;&amp;quot;\t&amp;quot;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;{print $0,&amp;quot;\t&amp;quot;$2,$3,$4}&amp;#39;&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; awk -F &lt;span class="s2"&gt;&amp;quot;\t&amp;quot;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;{print $0,&amp;quot;\t&amp;quot;&amp;quot;The&amp;quot;, $5, $7, &amp;quot;the&amp;quot;, $6&amp;quot;.&amp;quot;}&amp;#39;&lt;/span&gt; &amp;gt; &lt;span class="m"&gt;20111215&lt;/span&gt;-2-kiy-ap-framedwordlist-new.txt&lt;span class="sb"&gt;```&lt;/span&gt;

Examining the first three lines of
&lt;span class="sb"&gt;`&lt;/span&gt;&lt;span class="m"&gt;20111215&lt;/span&gt;-2-kiy-ap-framedwordlist-new.txt&lt;span class="sb"&gt;`&lt;/span&gt; shows that we accomplished
what we want, except the table headers are screwed up.

&lt;span class="sb"&gt;```&lt;/span&gt;bash
amoebe@moebius :: head -3 &lt;span class="m"&gt;20111215&lt;/span&gt;-2-kiy-ap-framedwordlist-new.txtitem  word.1  word.2  verb    gloss.1 gloss.2 gloss.verb  tone.1  tone.2  tone.1.tone.2   word.1 word.2 verb  The gloss.1 gloss.verb the gloss.2.
&lt;span class="m"&gt;1&lt;/span&gt;   kE  ndE fuwa    ant centipede   sees    T1  T1  T1.T1   kE ndE fuwa     The ant sees the centipede.
&lt;span class="m"&gt;2&lt;/span&gt;   kE  fa  fuwa    ant younger.sibling sees    T1  T2  T1.T2   kE fa fuwa  The ant sees the younger.sibling.
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We can correct the table headers by targeting just the first row
using &lt;code&gt;NR==1&lt;/code&gt;, and replacing fields $10-$12 with the appropriate
heading. We write to the file &lt;code&gt;20111215-2-kiy-ap-framedwordlist-final.txt&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;awk -F &lt;span class="s2"&gt;&amp;quot;\t&amp;quot;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;NR==1 {$10=&amp;quot;bitone&amp;quot;;$11=&amp;quot;sent.kiy&amp;quot;;$12=&amp;quot;sent.eng&amp;quot;}1&amp;#39;&lt;/span&gt; &lt;span class="m"&gt;20111215&lt;/span&gt;-2-kiy-ap-framedwordlist-new.txt &amp;gt; &lt;span class="m"&gt;20111215&lt;/span&gt;-2-kiy-ap-framedwordlist-final.txt
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;A quick examination of the output file &lt;code&gt;20111215-2-kiy-ap-framedwordlist-final.txt&lt;/code&gt; shows we got what we wanted.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;amoebe@moebius :: head -3 &lt;span class="m"&gt;20111215&lt;/span&gt;-2-kiy-ap-framedwordlist-final.txt 
item word.1 word.2 verb gloss.1 gloss.2 gloss.verb tone.1 tone.2  bitone sent.kiy sent.eng
&lt;span class="m"&gt;1&lt;/span&gt;   kE  ndE fuwa    ant centipede   sees    T1  T1  T1.T1   kE ndE fuwa     The ant sees the centipede.
&lt;span class="m"&gt;2&lt;/span&gt;   kE  fa  fuwa    ant younger.sibling sees    T1  T2  T1.T2   kE fa fuwa  The ant sees the younger.sibling.
&lt;/pre&gt;&lt;/div&gt;


&lt;hr&gt;
&lt;h2 id="wzxhzdk44wzxhzdk45organizing-files"&gt;&lt;a id="files"&gt;&lt;/a&gt;Organizing files&lt;/h2&gt;
&lt;p&gt;One issue that comes up with having a lot of recorded data is the
proliferation of audio files that needs to be dealt with. Some tips
for managing the multitudes of files are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Standardize directory structure/naming and file naming.&lt;/strong&gt; File
  organization is not the place to be creative. If you standardize how
  you set up your directory (folder) structure and how you name
  directories and files, it's a lot easier to know where to find
  things and have an efficient workflow in working with the files,
  especially if you are using any scripts.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Use filenames as dictionary keys and keep associated information
  in spreadsheets/text files.&lt;/strong&gt; This means to keep filenames
  immutable and unique, as we saw in
  &lt;a href="#hash"&gt;Using dictionaries as data structures&lt;/a&gt;, and to include
  spreadsheets and/or text files associating additional information
  about elicitation items to the corresponding files via the
  filenames. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Keep directory names and filenames limited to the ASCII character set and avoid spaces
  and case-sensitivity.&lt;/strong&gt; Special characters in filenames can get you
  in trouble across platforms and in working with scripts. It's safer
  to stay within the alphanumeric ([a-z], [0-9]) ASCII character set and keep special characters
  to associated spreadsheets/text files. Spaces in filenames are
  &lt;a href="http://superuser.com/questions/29111/what-technical-reasons-exist-for-not-using-space-characters-in-file-names"&gt;best avoided&lt;/a&gt;
  because while they make filenames human-friendly, they make
  filenames machine-unfriendly---they can cause problems with command
  line interpretation and locating the file and create issues across
  different operating systems. Using case sensitivity to distinguish
  filenames or directory names like &lt;code&gt;data-files&lt;/code&gt; and &lt;code&gt;Data-Files&lt;/code&gt; is also dangerous because any
  program that is case-insensitive cannot distinguish such names.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;If it's necessary to rename files, use utilities to do bulk
  renaming.&lt;/strong&gt; This can help avoid random errors, but you'll need to be
  careful about systematic errors. There are applications available for Windows, Mac, and
  many command line utilities that can do the trick:
          + &lt;a href="http://lifehacker.com/5139592/ant-renamer-is-a-lightweight-but-powerful-renaming-utility"&gt;Recommendations for Windows&lt;/a&gt;
          + &lt;a href="http://manytricks.com/namemangler/"&gt;Name Mangler&lt;/a&gt; and
    &lt;a href="http://lifehacker.com/5825387/namechanger-for-mac-quickly-renames-groups-of-files"&gt;NameChanger&lt;/a&gt; for Mac
          + &lt;a href="http://unix.stackexchange.com/questions/1136/batch-renaming-files"&gt;Command&lt;/a&gt; &lt;a href="http://hints.macworld.com/article.php?story=20010509130450691"&gt;line&lt;/a&gt; &lt;a href="http://superuser.com/questions/25378/mass-renaming-nix-version"&gt;utilities&lt;/a&gt;  &lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="examples-of-directory-structure-and-filenaming"&gt;Examples of directory structure and filenaming&lt;/h3&gt;
&lt;p&gt;Here's an example of directory structure and filenaming for Kirikiri
data from the
&lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/organizing-elicitation-items/"&gt;the organizing-elicitation-tiems sub-directory&lt;/a&gt;
in the directory &lt;code&gt;data/&lt;/code&gt;, which contains all of the data recorded and
associated files.&lt;sup id="fnref-5"&gt;&lt;a class="footnote-ref" href="#fn-5"&gt;5&lt;/a&gt;&lt;/sup&gt; &lt;/p&gt;
&lt;p&gt;Each elicitation session date gets its own directory in &lt;code&gt;data/&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;data
├── 20111207
├── 20111208
├── 20111209
├── 20111212
├── 20111213
├── 20111214
├── 20111215
└── 20111216

8 directories
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Here's the directory structure for &lt;code&gt;data/20111207/&lt;/code&gt;. Each elicitation
session gets its own directory, &lt;code&gt;1/&lt;/code&gt; and &lt;code&gt;2/&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;20111207
├── 1
│   ├── analysis
│   │   ├── f0
│   │   └── scripts
│   ├── data
│   │   ├── tokens
│   │   └── trimmed
│   └── info
├── 2
│   ├── analysis
│   │   ├── f0
│   │   └── scripts
│   ├── data
│   │   ├── tokens
│   │   └── trimmed
│   └── info
└── analysis
    └── figs

18 directories
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Within each elicitation session directory, there's three directories:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;analysis/&lt;/code&gt;: this contains extracted f0 information and scripts&lt;/li&gt;
&lt;li&gt;&lt;code&gt;data/&lt;/code&gt;: this contains the audio files&lt;/li&gt;
&lt;li&gt;&lt;code&gt;info/&lt;/code&gt;: this contains spreadsheets and textfiles with elicitation
  item information&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There's also an &lt;code&gt;analysis&lt;/code&gt; directory in &lt;code&gt;data/20111207/&lt;/code&gt; which
  contains files related to an analysis combining data from the two
  elicitation sessions.&lt;/p&gt;
&lt;p&gt;Similarly, the directory structure for &lt;code&gt;20111213/&lt;/code&gt; also contains
sub-directories for each elicitation session, &lt;code&gt;1/&lt;/code&gt; and &lt;code&gt;2/&lt;/code&gt;, each of
which include &lt;code&gt;analysis/&lt;/code&gt;, &lt;code&gt;data/&lt;/code&gt;, and &lt;code&gt;info/&lt;/code&gt; directories. A
separate &lt;code&gt;info/&lt;/code&gt; directory in &lt;code&gt;20111213/&lt;/code&gt; contains spreadsheets and
textfiles combining information about both sessions.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;20111213
├── 1
│   ├── analysis
│   │   ├── auto
│   │   ├── f0
│   │   ├── figs
│   │   └── scripts
│   ├── data
│   │   ├── raw
│   │   └── tokens
│   └── info
├── 2
│   ├── analysis
│   │   └── scripts
│   ├── data
│   │   └── raw
│   └── info
└── info
    └── raw-excel-files-from-rebecca

18 directories
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Within the &lt;code&gt;20111213/1/data&lt;/code&gt; directory the filenames are listed below:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;20111213/1/data
├── 20111213-1-kiy-ap-framedwordlist-stereo.wav
├── 20111213-1-kiy-ap-framedwordlist.TextGrid
├── 20111213-1-kiy-ap-framedwordlist.TextGrid.blank
├── 20111213-1-kiy-ap-framedwordlist.wav
├── raw
│   └── 20111213-1-kiy-ap-framedwordlist.wav
└── tokens
    ├── 20111213-1-kiy-ap-framedwordlist-1.TextGrid
    ├── 20111213-1-kiy-ap-framedwordlist-1.wav
    ├── 20111213-1-kiy-ap-framedwordlist-10.TextGrid
    ├── 20111213-1-kiy-ap-framedwordlist-10.wav
    ├── 20111213-1-kiy-ap-framedwordlist-11.TextGrid
    ├── 20111213-1-kiy-ap-framedwordlist-11.wav
    ├── 20111213-1-kiy-ap-framedwordlist-12.TextGrid
    ├── 20111213-1-kiy-ap-framedwordlist-12.wav
    ├── 20111213-1-kiy-ap-framedwordlist-13.TextGrid
    ├── 20111213-1-kiy-ap-framedwordlist-13.wav
    ├── 20111213-1-kiy-ap-framedwordlist-14.TextGrid
    ├── 20111213-1-kiy-ap-framedwordlist-14.wav
    ├── 20111213-1-kiy-ap-framedwordlist-15.TextGrid
    ├── 20111213-1-kiy-ap-framedwordlist-15.wav
    ├── 20111213-1-kiy-ap-framedwordlist-16.TextGrid
    ├── 20111213-1-kiy-ap-framedwordlist-16.wav
    ├── 20111213-1-kiy-ap-framedwordlist-17.TextGrid
    ├── 20111213-1-kiy-ap-framedwordlist-17.wav
    ├── 20111213-1-kiy-ap-framedwordlist-18.TextGrid
    ├── 20111213-1-kiy-ap-framedwordlist-18.wav
    ├── 20111213-1-kiy-ap-framedwordlist-19.TextGrid
    ├── 20111213-1-kiy-ap-framedwordlist-19.wav
    ├── 20111213-1-kiy-ap-framedwordlist-2.TextGrid
    ├── 20111213-1-kiy-ap-framedwordlist-2.wav
    ├── 20111213-1-kiy-ap-framedwordlist-20.TextGrid
    ├── 20111213-1-kiy-ap-framedwordlist-20.wav
    ├── 20111213-1-kiy-ap-framedwordlist-21.TextGrid
    ├── 20111213-1-kiy-ap-framedwordlist-21.wav
    ├── 20111213-1-kiy-ap-framedwordlist-22.TextGrid
    ├── 20111213-1-kiy-ap-framedwordlist-22.wav
    ├── 20111213-1-kiy-ap-framedwordlist-23.TextGrid
    ├── 20111213-1-kiy-ap-framedwordlist-23.wav
    ├── 20111213-1-kiy-ap-framedwordlist-24.TextGrid
    ├── 20111213-1-kiy-ap-framedwordlist-24.wav
    ├── 20111213-1-kiy-ap-framedwordlist-25.TextGrid
    ├── 20111213-1-kiy-ap-framedwordlist-25.wav
    ├── 20111213-1-kiy-ap-framedwordlist-3.TextGrid
    ├── 20111213-1-kiy-ap-framedwordlist-3.wav
    ├── 20111213-1-kiy-ap-framedwordlist-4.TextGrid
    ├── 20111213-1-kiy-ap-framedwordlist-4.wav
    ├── 20111213-1-kiy-ap-framedwordlist-5.TextGrid
    ├── 20111213-1-kiy-ap-framedwordlist-5.wav
    ├── 20111213-1-kiy-ap-framedwordlist-6.TextGrid
    ├── 20111213-1-kiy-ap-framedwordlist-6.wav
    ├── 20111213-1-kiy-ap-framedwordlist-7.TextGrid
    ├── 20111213-1-kiy-ap-framedwordlist-7.wav
    ├── 20111213-1-kiy-ap-framedwordlist-8.TextGrid
    ├── 20111213-1-kiy-ap-framedwordlist-8.wav
    ├── 20111213-1-kiy-ap-framedwordlist-9.TextGrid
    └── 20111213-1-kiy-ap-framedwordlist-9.wav

2 directories, 55 files
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The &lt;code&gt;raw/&lt;/code&gt; directory contains the original recorded file, and files in
&lt;code&gt;data/&lt;/code&gt; are the downsampled, Channel 1 audio files processed from the
raw audio file and their associated Praat annotation files. The &lt;code&gt;tokens/&lt;/code&gt; directory holds audio files of
individual elicitation items extracted from the elicitation session
recorded file in &lt;code&gt;data/&lt;/code&gt; and associated Praat annotation files.&lt;/p&gt;
&lt;p&gt;The elicitation session files are named after the elicitation session
ID, &lt;code&gt;20111213-1-kiy-ap-framedwordlist&lt;/code&gt;. The individual token files are
named with a suffix that is the elicitation item ID,
e.g. &lt;code&gt;20111213-1-kiy-ap-framedwordlist-1&lt;/code&gt;,
&lt;code&gt;20111213-1-kiy-ap-framedwordlist-2&lt;/code&gt;, etc.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn-1"&gt;
&lt;p&gt;It's also a bad idea to include spaces in filenames, as we
discuss in the section &lt;a href="#files"&gt;Organizing files&lt;/a&gt;.&amp;#160;&lt;a class="footnote-backref" href="#fnref-1" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn-2"&gt;
&lt;p&gt;We created these HTML tables using the web-based
&lt;a href="http://truben.no/latex/table/"&gt;table editor&lt;/a&gt;, which is handy
for converting tables between various text formats (CSV,
tab-delimited, space-delimited) and LaTeX and html formats and other
formats used in web development.&amp;#160;&lt;a class="footnote-backref" href="#fnref-2" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn-3"&gt;
&lt;p&gt;Flip also has a GUI implementation called &lt;a href="https://code.google.com/p/linebreak/"&gt;LineBreak&lt;/a&gt;.&amp;#160;&lt;a class="footnote-backref" href="#fnref-3" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn-4"&gt;
&lt;p&gt;&lt;code&gt;g++&lt;/code&gt; is available from &lt;a href="https://developer.apple.com/xcode/"&gt;Xcode&lt;/a&gt; command line tools, which
you can install from the Mac App Store by downloading Xcode and
&lt;code&gt;Command Line Tools&lt;/code&gt; for installation in the &lt;a href="http://stackoverflow.com/questions/9329243/xcode-4-4-command-line-tools"&gt;Download preference pane&lt;/a&gt;.&amp;#160;&lt;a class="footnote-backref" href="#fnref-4" title="Jump back to footnote 4 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn-5"&gt;
&lt;p&gt;The directory structure graphics are done via the command line
utility &lt;a href="http://mama.indstate.edu/users/ice/tree/"&gt;&lt;code&gt;tree&lt;/code&gt;&lt;/a&gt;.&amp;#160;&lt;a class="footnote-backref" href="#fnref-5" title="Jump back to footnote 5 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="ldc-kiy"></category><category term="fieldwork"></category><category term="tutorial"></category></entry><entry><title>Processing audio files (with SoX)</title><link href="http://kmyu.github.io/blog/processing-audio-files-sox.html" rel="alternate"></link><published>2013-06-23T16:45:00-04:00</published><updated>2013-06-23T16:45:00-04:00</updated><author><name>Kristine Yu</name></author><id>tag:kmyu.github.io,2013-06-23:/blog/processing-audio-files-sox.html</id><summary type="html">&lt;p&gt;This tutorial introduces how to process audio files from fieldwork
recordings with &lt;a href="http://sox.sourceforge.net/"&gt;SoX&lt;/a&gt;, a command-line
utility for working with soundfiles.&lt;sup id="fnref-1"&gt;&lt;a class="footnote-ref" href="#fn-1"&gt;1&lt;/a&gt;&lt;/sup&gt; See the tutorial
&lt;a href="processing-audio-files-praat.html"&gt;Processing audio (with Praat)&lt;/a&gt; for
the sister tutorial using Praat.&lt;/p&gt;
&lt;!-- PELICAN_END_SUMMARY --&gt;

&lt;p&gt;Following an &lt;a href = "#intro"&gt;introductory section&lt;/a&gt;, the tutorial
shows how to use &lt;a href="http://sox.sourceforge.net/"&gt;SoX&lt;/a&gt; command utilities to view information …&lt;/p&gt;</summary><content type="html">&lt;p&gt;This tutorial introduces how to process audio files from fieldwork
recordings with &lt;a href="http://sox.sourceforge.net/"&gt;SoX&lt;/a&gt;, a command-line
utility for working with soundfiles.&lt;sup id="fnref-1"&gt;&lt;a class="footnote-ref" href="#fn-1"&gt;1&lt;/a&gt;&lt;/sup&gt; See the tutorial
&lt;a href="processing-audio-files-praat.html"&gt;Processing audio (with Praat)&lt;/a&gt; for
the sister tutorial using Praat.&lt;/p&gt;
&lt;!-- PELICAN_END_SUMMARY --&gt;

&lt;p&gt;Following an &lt;a href = "#intro"&gt;introductory section&lt;/a&gt;, the tutorial
shows how to use &lt;a href="http://sox.sourceforge.net/"&gt;SoX&lt;/a&gt; command utilities to view information about a
soundfile, make three different modifications to the soundfile, and
batch process audio files:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#display"&gt;Displaying information about the audio file&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#downsample"&gt;Downsampling the audio file&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#bit"&gt;Reducing the bit depth of the file&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#channel"&gt;Extracting a single channel from the file&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#batch"&gt;Batch processing&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="wzxhzdk25wzxhzdk26-introduction"&gt;&lt;a id="intro"&gt;&lt;/a&gt; Introduction&lt;/h2&gt;
&lt;p&gt;What is SoX? The &lt;a href="http://sox.sourceforge.net/"&gt;homepage for SoX&lt;/a&gt; calls it "the Swiss Army knife of
sound processing programs" and gives the following description:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;SoX is a cross-platform (Windows, Linux, MacOS X, etc.) command line utility that can convert various formats of computer audio files in to other formats. It can also apply various effects to these sound files, and, as an added bonus, SoX can play and record audio files on most platforms.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Why &lt;a href="http://www.computerhope.com/issues/ch000619.htm" title="Computer Hope general comparison"&gt;use&lt;/a&gt; &lt;a href="http://www.linuxdevcenter.com/pub/a/linux/2001/11/15/learnunixos.html" title="Linux Dev Center"&gt;the&lt;/a&gt; &lt;a href="http://www.linfo.org/command_line.html"&gt;command line&lt;/a&gt; for processing audio files?
As a set of command line utilities, SoX is especially fast for batch processing of audio
files. SoX commands can also be strung together with each other as
well as any other shell command on the command line as part of a
script. We'll get a flavor of this in the tutorial section on &lt;a href="#batch"&gt;batch
processing&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;Some materials to help get started with SoX include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://sox.sourceforge.net/Docs/Documentation"&gt;The official SoX documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://billposer.org/Linguistics/Computation/SoxTutorial.html"&gt;Bill Poser's SoX tutorial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.thegeekstuff.com/2009/05/sound-exchange-sox-15-examples-to-manipulate-audio-files/"&gt;Geek Stuff tutorial&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Check the official SoX website for the most up-to-date documentation. The two tutorials listed are a bit outdated, but still useful for getting started.&lt;/p&gt;
&lt;h3 id="the-command-line"&gt;The command line&lt;/h3&gt;
&lt;p&gt;For a command-line interface, Mac users can use the built-in &lt;a href="http://guides.macrumors.com/Terminal"&gt;Terminal application&lt;/a&gt;. Linux users have built-in &lt;a href="http://linuxcommand.org/lts0010.php#xterm"&gt;terminal emulators&lt;/a&gt; as well. PC Users need to install a terminal emulator like &lt;a href="http://www.cygwin.com/"&gt;cygwin&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We're not going to review using the command line here, but here is a list of some introductory tutorials.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://lifehacker.com/5633909/who-needs-a-mouse-learn-to-use-the-command-line-for-almost-anything"&gt;Lifehacker: A command line primer for beginners&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mac.tutsplus.com/tutorials/terminal/navigating-the-terminal-a-gentle-introduction/"&gt;mactuts: navigating the terminal&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://lifehacker.com/179514/geek-to-live--introduction-to-cygwin-part-i"&gt;Lifehacker: introduction to cygwin&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And here are a few more in-depth tutorials that are on-line:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://software-carpentry.org/4_0/shell/index.html"&gt;Software Carpentry: The shell&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.ee.surrey.ac.uk/Teaching/Unix/"&gt;University of Surrey&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For a book-length treatment, you might try the
&lt;a href="http://oreilly.com/"&gt;O'Reilly&lt;/a&gt; series book, &lt;a href="http://shop.oreilly.com/product/9780596002619.do"&gt;Learning the Unix Operating System&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="instructions-for-tutorials"&gt;Instructions for tutorials&lt;/h3&gt;
&lt;p&gt;The files for the tutorials can be found in
&lt;a href="http://media.krisyu.org/ldc-kiy"&gt;this directory&lt;/a&gt; under
&lt;code&gt;tutorials/processing-audio-files&lt;/code&gt; (&lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/processing-audio-files/"&gt;here&lt;/a&gt;). Once you've downloaded the ldc-kiy repository, you can enter commands yourself to follow along with the tutorial.&lt;/p&gt;
&lt;p&gt;In the ldc-kiy directory, change the working directory to the &lt;code&gt;tutorials/processing-audio-files&lt;/code&gt; directory with the &lt;code&gt;cd&lt;/code&gt; command and list the directory contents with &lt;code&gt;ls&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;#change working directory to tutorial directory&lt;/span&gt;
&lt;span class="nb"&gt;cd&lt;/span&gt; tutorials/processing-audio-files
ls &lt;span class="c1"&gt;# list directory contents&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You should see something like this in your terminal:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;amoebe@moebius :: ls
demo/      your-turn/
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The &lt;code&gt;demo/&lt;/code&gt; directory contains all the files used and generated during the tutorial for your reference. The &lt;code&gt;your-turn/&lt;/code&gt; directory is for you to play in and contains only the raw audio files the tutorial works with, and not any of the generated files from the tutorial. The rest of the tutorial will assume that the user starts in the directory &lt;code&gt;ldc-kiy/tutorials/processing-audio-files/your-turn/&lt;/code&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="wzxhzdk29wzxhzdk30displaying-audio-file-information"&gt;&lt;a id="display"&gt;&lt;/a&gt;Displaying audio file information&lt;/h2&gt;
&lt;p&gt;In the &lt;code&gt;your-turn/&lt;/code&gt; directory, navigate to &lt;code&gt;20111213/raw/&lt;/code&gt; and see
what's in there:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;cd&lt;/span&gt; &lt;span class="m"&gt;20111213&lt;/span&gt;/raw/ &lt;span class="c1"&gt;# navigate from the your-turn directory&lt;/span&gt;
ls &lt;span class="c1"&gt;# display directory contents&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You'll see that there is a wav file in &lt;code&gt;your-turn/20111213/raw&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;amoebe@moebius :: ls
20111213-1-kiy-ap-framedwordlist.wav
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We can use sox to display information about the wav file as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sox --i &lt;span class="m"&gt;20111213&lt;/span&gt;-1-kiy-ap-framedwordlist.wav &lt;span class="c1"&gt;# display audio file header info&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The output from the &lt;code&gt;sox --i&lt;/code&gt; command is given below. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Input File     : &lt;span class="s1"&gt;&amp;#39;20111213-1-kiy-ap-framedwordlist.wav&amp;#39;&lt;/span&gt;
Channels       : &lt;span class="m"&gt;2&lt;/span&gt;
Sample Rate    : &lt;span class="m"&gt;48000&lt;/span&gt;
Precision      : &lt;span class="m"&gt;16&lt;/span&gt;-bit
Duration       : &lt;span class="m"&gt;00&lt;/span&gt;:05:47.83 &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;16695936&lt;/span&gt; samples ~ &lt;span class="m"&gt;26087&lt;/span&gt;.4 CDDA sectors
File Size      : &lt;span class="m"&gt;66&lt;/span&gt;.8M
Bit Rate       : &lt;span class="m"&gt;1&lt;/span&gt;.54M
Sample Encoding: &lt;span class="m"&gt;16&lt;/span&gt;-bit Signed Integer PCM
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Input File&lt;/code&gt; lists the file name.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Channels&lt;/code&gt; indicates that there are 2 channels in the file (Channel 1 was for the consultant; Channel 2 for the translator/elicitor)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Sample rate&lt;/code&gt; indicates the audio file was sampled at 48000 Hz (or equivalently, 48 kHz)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Precision&lt;/code&gt; tells us the precision or bit depth of the file, 16-bit.&lt;/li&gt;
&lt;li&gt;Note that the &lt;code&gt;file size&lt;/code&gt; is 66.8 megabytes for a recording with a &lt;code&gt;duration&lt;/code&gt; of just &lt;code&gt;00:05.47.83&lt;/code&gt;, i.e., just under 6 minutes!&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The sample rate of 48kHz is much higher than needed for working with
speech so we can &lt;a href="#downsample"&gt;downsample&lt;/a&gt; the file to keep the file
size down. We also want to
extract just one of the 2 channels, the channel reserved for the
consultant (Channel 1), for further data analysis.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="wzxhzdk31wzxhzdk32downsampling"&gt;&lt;a id="downsample"&gt;&lt;/a&gt;Downsampling&lt;/h2&gt;
&lt;p&gt;Below, we downsample the sampling rate of the file
 &lt;code&gt;20111213-1-kiy-ap-framedwordlist.wav&lt;/code&gt; from 48kHz to 16kHz and write
 the downsampled file to a new file
 &lt;code&gt;20111213-1-kiy-ap-framedwordlist-stereo.wav&lt;/code&gt; in a new directory in
 &lt;code&gt;your-turn/20111213/1&lt;/code&gt; we call &lt;code&gt;data/&lt;/code&gt;. We give the new filename a
 &lt;code&gt;-stereo&lt;/code&gt; suffix to remind ourselves that this file still has 2
 channels. It's good to keep the stereo (2-channel) file around for
 reference, since it includes information about how items were
 elicited if we need to check those details later.&lt;/p&gt;
&lt;p&gt;Starting in &lt;code&gt;your-turn/20111213/1/raw/&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# create new data sub-directory in parent directory 1/&lt;/span&gt;
mkdir ../data 

&lt;span class="c1"&gt;# downsample to 16kHz and write to file in data/&lt;/span&gt;
&lt;span class="c1"&gt;# &amp;#39;-r 16k&amp;#39; specifies resampling at a 16kHz sampling rate&lt;/span&gt;
sox &lt;span class="m"&gt;20111213&lt;/span&gt;-1-kiy-ap-framedwordlist.wav -r 16k ../data/20111213-1-kiy-ap-framedwordlist-stereo.wav
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We can change the working directory to the directory with the new downsampled file and display the audio file information:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;cd&lt;/span&gt; ../data/ &lt;span class="c1"&gt;# change working directory to directory with downsampled file&lt;/span&gt;
sox --i &lt;span class="m"&gt;20111213&lt;/span&gt;-1-kiy-ap-framedwordlist-stereo.wav
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Note in the displayed info below that the the sample rate of this new file is 16000 Hz (16kHz), as desired. Moreover, the file size has dropped from 66.8 MB to 22.3MB.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Input File     : &lt;span class="s1"&gt;&amp;#39;20111213-1-kiy-ap-framedwordlist-stereo.wav&amp;#39;&lt;/span&gt;
Channels       : &lt;span class="m"&gt;2&lt;/span&gt;
Sample Rate    : &lt;span class="m"&gt;16000&lt;/span&gt;
Precision      : &lt;span class="m"&gt;16&lt;/span&gt;-bit
Duration       : &lt;span class="m"&gt;00&lt;/span&gt;:05:47.83 &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;5565312&lt;/span&gt; samples ~ &lt;span class="m"&gt;26087&lt;/span&gt;.4 CDDA sectors
File Size      : &lt;span class="m"&gt;22&lt;/span&gt;.3M
Bit Rate       : 512k
Sample Encoding: &lt;span class="m"&gt;16&lt;/span&gt;-bit Signed Integer PCM
&lt;/pre&gt;&lt;/div&gt;


&lt;hr&gt;
&lt;h2 id="wzxhzdk33wzxhzdk34reducing-bit-depth"&gt;&lt;a id="bit"&gt;&lt;/a&gt;Reducing bit depth&lt;/h2&gt;
&lt;p&gt;We can tweak the downsampling command slightly to get the command
needed to reduce the &lt;a href="http://wiki.audacityteam.org/wiki/Bit_Depth"&gt;bit depth&lt;/a&gt; of an audio file:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;cd&lt;/span&gt; ../raw/ &lt;span class="c1"&gt;# change back to the raw/ directory&lt;/span&gt;

&lt;span class="c1"&gt;# &amp;#39;-b 16&amp;#39; specifies reducing bit depth to 16 bit&lt;/span&gt;
sox &lt;span class="m"&gt;20111213&lt;/span&gt;-1-kiy-ap-framedwordlist.wav -b &lt;span class="m"&gt;16&lt;/span&gt; ../data/20111213-1-kiy-ap-framedwordlist-stereo.wav 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Since the original file precision was already &lt;code&gt;16-bit&lt;/code&gt;, there is no
change to the precision so the output from &lt;code&gt;sox --i&lt;/code&gt; in &lt;code&gt;data/&lt;/code&gt; would remain the same
as before. &lt;/p&gt;
&lt;p&gt;It is also possible to combine the commands for downsampling and
changing precision, as follows (starting in the &lt;code&gt;raw/&lt;/code&gt; directory):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# &amp;#39;-b 16&amp;#39; specifies converting to a bit depth of 16 and &amp;#39;r 16k&amp;#39; indicates converting to a sampling rate of 16kHz.&lt;/span&gt;
sox &lt;span class="m"&gt;20111213&lt;/span&gt;-1-kiy-ap-framedwordlist.wav -b &lt;span class="m"&gt;16&lt;/span&gt; -r 16k ../data/20111213-1-kiy-ap-framedwordlist-stereo.wav
&lt;/pre&gt;&lt;/div&gt;


&lt;hr&gt;
&lt;h2 id="wzxhzdk35wzxhzdk36extracting-a-channel"&gt;&lt;a id="channel"&gt;&lt;/a&gt;Extracting a channel&lt;/h2&gt;
&lt;p&gt;We recorded the elicitation session with two channels,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Channel 1 (left channel): consultant&lt;/li&gt;
&lt;li&gt;Channel 2 (right channel): elicitor/translator&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To extract a channel from the stereo audio file, we use the &lt;code&gt;remix&lt;/code&gt;
effect: for an input file with 2 channels, &lt;code&gt;remix 1 0&lt;/code&gt; selects Channel
1, while &lt;code&gt;remix 0 1&lt;/code&gt; selects Channel 2.&lt;sup id="fnref-2"&gt;&lt;a class="footnote-ref" href="#fn-2"&gt;2&lt;/a&gt;&lt;/sup&gt; Here, we select Channel 1
using &lt;code&gt;remix 1 0&lt;/code&gt; to extract the consultant's channel from the
downsampled stereo file &lt;code&gt;20111213-1-kiy-ap-framedwordlist-stereo.wav&lt;/code&gt;
in &lt;code&gt;data/&lt;/code&gt; and write to a new file in &lt;code&gt;data/&lt;/code&gt; we call
&lt;code&gt;20111213-1-kiy-ap-framedwordlist.wav&lt;/code&gt;. Starting from the &lt;code&gt;raw/&lt;/code&gt;
directory where we left off:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# change directory to data/ sub-directory from raw/ sub-directory&lt;/span&gt;
&lt;span class="nb"&gt;cd&lt;/span&gt; ../data/
sox &lt;span class="m"&gt;20111213&lt;/span&gt;-1-kiy-ap-framedwordlist-stereo.wav &lt;span class="m"&gt;20111213&lt;/span&gt;-1-kiy-ap-framedwordlist.wav remix &lt;span class="m"&gt;1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Alternatively, this command is less terse and does the same thing:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# &amp;#39;-c 1&amp;#39; specifies the output file to have 1 channel&lt;/span&gt;
&lt;span class="c1"&gt;# &amp;#39;remix&amp;#39; selects and mixes input audio channels into output audio channels&lt;/span&gt;
sox &lt;span class="m"&gt;20111213&lt;/span&gt;-1-kiy-ap-framedwordlist-stereo.wav -c &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="m"&gt;20111213&lt;/span&gt;-1-kiy-ap-framedwordlist.wav remix &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Putting all 3 changes together, we can also combine all of them as one
command as follows, sidestepping the creation of the downsampled
stereo file in &lt;code&gt;data/&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;cd&lt;/span&gt; ../raw
sox &lt;span class="m"&gt;20111213&lt;/span&gt;-1-kiy-ap-framedwordlist.wav -b &lt;span class="m"&gt;16&lt;/span&gt; -r 16k ../data/20111213-1-kiy-ap-framedwordlist-stereo.wav remix &lt;span class="m"&gt;1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;hr&gt;
&lt;h2 id="wzxhzdk37wzxhzdk38batch-processing"&gt;&lt;a id="batch"&gt;&lt;/a&gt;Batch processing&lt;/h2&gt;
&lt;p&gt;The real power of SoX comes when you're trying to perform the same
operation on a bunch of audio files at once. We present an example of
batch processing audio files with SoX below to give you a flavor.&lt;/p&gt;
&lt;p&gt;The relevant files for this demo are in &lt;code&gt;your-turn/batch-demo/&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Change the working directory to batch-demo/ from 20111213/1/data/ or 20111213/1/raw/&lt;/span&gt;
&lt;span class="nb"&gt;cd&lt;/span&gt; ../../batch-demo

ls &lt;span class="c1"&gt;# list directory contents&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You'll see there are 11 wav files in the directory:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;amoebe@moebius :: ls
&lt;span class="m"&gt;20111213&lt;/span&gt;-1-kiy-ap-framedwordlist-1.wav   &lt;span class="m"&gt;20111213&lt;/span&gt;-1-kiy-ap-framedwordlist-15.wav
&lt;span class="m"&gt;20111213&lt;/span&gt;-1-kiy-ap-framedwordlist-10.wav  &lt;span class="m"&gt;20111213&lt;/span&gt;-1-kiy-ap-framedwordlist-16.wav
&lt;span class="m"&gt;20111213&lt;/span&gt;-1-kiy-ap-framedwordlist-11.wav  &lt;span class="m"&gt;20111213&lt;/span&gt;-1-kiy-ap-framedwordlist-17.wav
&lt;span class="m"&gt;20111213&lt;/span&gt;-1-kiy-ap-framedwordlist-12.wav  &lt;span class="m"&gt;20111213&lt;/span&gt;-1-kiy-ap-framedwordlist-18.wav
&lt;span class="m"&gt;20111213&lt;/span&gt;-1-kiy-ap-framedwordlist-13.wav  &lt;span class="m"&gt;20111213&lt;/span&gt;-1-kiy-ap-framedwordlist-19.wav
&lt;span class="m"&gt;20111213&lt;/span&gt;-1-kiy-ap-framedwordlist-14.wav
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Suppose we'd like to find out the duration of each of these 11 wav
files. We can do this with an additional option for &lt;code&gt;sox --i&lt;/code&gt;, say,
for the file &lt;code&gt;20111213-1-kiy-ap-framedwordlist-1.wav&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sox --i -D &lt;span class="m"&gt;20111213&lt;/span&gt;-1-kiy-ap-framedwordlist-1.wav
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;and we find out that &lt;code&gt;20111213-1-kiy-ap-framedwordlist-1.wav&lt;/code&gt; has a
duration of 0.804 seconds:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;amoebe@moebius :: sox --i -D &lt;span class="m"&gt;20111213&lt;/span&gt;-1-kiy-ap-framedwordlist-1.wav
&lt;span class="m"&gt;0&lt;/span&gt;.804000
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We can do this for each of the 11 wav files with a single command,
using
&lt;a href="http://www.tldp.org/LDP/abs/html/globbingref.html"&gt;file globbing&lt;/a&gt;,
which allows use of the wildcard &lt;code&gt;*&lt;/code&gt; to perform filename expansion:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# The wildcard * allows any string of characters between - and .wav&lt;/span&gt;
&lt;span class="c1"&gt;# (with some hedges for `any&amp;#39;, see&lt;/span&gt;
&lt;span class="c1"&gt;# http://www.tldp.org/LDP/abs/html/globbingref.html for details)&lt;/span&gt;

sox --i -D &lt;span class="m"&gt;20111213&lt;/span&gt;-1-kiy-ap-framedwordlist-*.wav

&lt;span class="c1"&gt;# This is equivalent to a sequence of sox --i -D commands, one for&lt;/span&gt;
&lt;span class="c1"&gt;# each of the 11 files with filenames matching 20111213-1-kiy-ap-framedwordlist-*.wav&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;which gives us the output:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;amoebe@moebius :: sox --i -D &lt;span class="m"&gt;20111213&lt;/span&gt;-1-kiy-ap-framedwordlist-*.wav
&lt;span class="m"&gt;0&lt;/span&gt;.804000
&lt;span class="m"&gt;0&lt;/span&gt;.863500
&lt;span class="m"&gt;0&lt;/span&gt;.832625
&lt;span class="m"&gt;0&lt;/span&gt;.827750
&lt;span class="m"&gt;0&lt;/span&gt;.793188
&lt;span class="m"&gt;0&lt;/span&gt;.869062
&lt;span class="m"&gt;0&lt;/span&gt;.903687
&lt;span class="m"&gt;0&lt;/span&gt;.996812
&lt;span class="m"&gt;0&lt;/span&gt;.922500
&lt;span class="m"&gt;0&lt;/span&gt;.796438
&lt;span class="m"&gt;0&lt;/span&gt;.933625
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This is a lot faster than opening each audio file in some program and
checking how long each one is.&lt;/p&gt;
&lt;p&gt;We can also chain together shell commands. Suppose we want to save
these durations to a log file called &lt;code&gt;durations.txt&lt;/code&gt;. We can easily
create such a file, with the first column indicating which filenumber 1-11
the duration corresponds to.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;paste -d&lt;span class="s1"&gt;&amp;#39;\t&amp;#39;&lt;/span&gt; &amp;lt;&lt;span class="o"&gt;(&lt;/span&gt;jot &lt;span class="m"&gt;11&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &amp;lt;&lt;span class="o"&gt;(&lt;/span&gt;sox --i -D &lt;span class="m"&gt;20111213&lt;/span&gt;-1-kiy-ap-framedwordlist-*.wav&lt;span class="o"&gt;)&lt;/span&gt; &amp;gt; durations.txt
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We can use the &lt;code&gt;more&lt;/code&gt; command to view the content of the text file &lt;code&gt;durations.txt&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;amoebe@moebius :: more durations.txt
&lt;span class="m"&gt;1&lt;/span&gt;       &lt;span class="m"&gt;0&lt;/span&gt;.804000
&lt;span class="m"&gt;2&lt;/span&gt;       &lt;span class="m"&gt;0&lt;/span&gt;.863500
&lt;span class="m"&gt;3&lt;/span&gt;       &lt;span class="m"&gt;0&lt;/span&gt;.832625
&lt;span class="m"&gt;4&lt;/span&gt;       &lt;span class="m"&gt;0&lt;/span&gt;.827750
&lt;span class="m"&gt;5&lt;/span&gt;       &lt;span class="m"&gt;0&lt;/span&gt;.793188
&lt;span class="m"&gt;6&lt;/span&gt;       &lt;span class="m"&gt;0&lt;/span&gt;.869062
&lt;span class="m"&gt;7&lt;/span&gt;       &lt;span class="m"&gt;0&lt;/span&gt;.903687
&lt;span class="m"&gt;8&lt;/span&gt;       &lt;span class="m"&gt;0&lt;/span&gt;.996812
&lt;span class="m"&gt;9&lt;/span&gt;       &lt;span class="m"&gt;0&lt;/span&gt;.922500
&lt;span class="m"&gt;10&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt;.796438
&lt;span class="m"&gt;11&lt;/span&gt;      &lt;span class="m"&gt;0&lt;/span&gt;.933625
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn-1"&gt;
&lt;p&gt;SoX is used in the backend of
&lt;a href="https://github.com/langtech/toney"&gt;Toney&lt;/a&gt;, the tone classification
software developed by Haejoong Lee and Steven Bird as part of the NSF project &lt;a href="http://www.prosodicsystems.org/"&gt;Prosodic Systems in New Guinea&lt;/a&gt;.&amp;#160;&lt;a class="footnote-backref" href="#fnref-1" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn-2"&gt;
&lt;p&gt;SoX used to have an &lt;code&gt;avg&lt;/code&gt; effect you could use for this, which
is still listed in various SoX tutorials. The
&lt;code&gt;avg&lt;/code&gt; effect is now deprecated. Use &lt;code&gt;remix&lt;/code&gt; instead.&amp;#160;&lt;a class="footnote-backref" href="#fnref-2" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="ldc-kiy"></category><category term="fieldwork"></category><category term="coding"></category><category term="shell"></category><category term="sox"></category><category term="audio"></category></entry><entry><title>Recording in the field</title><link href="http://kmyu.github.io/blog/recording-in-the-field.html" rel="alternate"></link><published>2013-06-23T16:45:00-04:00</published><updated>2013-06-23T16:45:00-04:00</updated><author><name>Kristine Yu</name></author><id>tag:kmyu.github.io,2013-06-23:/blog/recording-in-the-field.html</id><summary type="html">&lt;p&gt;Tutorial for LDC paper: notes on recording in the field&lt;/p&gt;</summary><content type="html">&lt;p&gt;This tutorial sketches some suggestions for recording equipment, for
recording practices, and for
audio file specifications of recorded data in the field. The outline
for the tutorial is as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#practices"&gt;Notes on recording practices&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#equipment"&gt;Notes on recording equipment&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#mics"&gt;Microphones and accessories&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#recording"&gt;Audio recording devices&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#audio"&gt;Audio file specifications&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="wzxhzdk14wzxhzdk15notes-on-recording-practices"&gt;&lt;a id = "practices"&gt;&lt;/a&gt;Notes on recording practices&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Maximize the consultant's comfort.&lt;/strong&gt; Be culturally sensitive
   during recording and respect your consultant. For instance, your consultant might feel
   uncomfortable if you adjust recording equipment attached to his/her
   body. Walk them through everything you're doing and make sure they
   are okay with it. Try to keep the consultant's
   awareness of the recording equipment and procedure fairly low so
   that they can relax as much as possible and speak naturally. If
   possible, try to have some water handy so they can drink if they
   get thirsty. Take breaks.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Have your research questions in mind.&lt;/strong&gt; What the best recording
  practices are depends on your research questions, so keep those in
  mind. For instance, if you are interested in studying the acoustic
  realization of obstruents, it would be imperative to record in a
  quiet environment, a sound-attenuated booth if possible. This is
  because any background noise could easily swamp release bursts. However,
  if your research question only involves studying fundamental
  frequency, having a pristinely quiet environment isn't as crucial. It's more
  important to insure that the speech signal has a healthy amplitude
  in the recording. Low amplitude signals can make it difficult to
  identify repeating patterns for f0 estimation algorithms.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Don't forget to record the elicitor, too.&lt;/strong&gt; If the elicitation
  session involves back-and-forth between the elicitor and consultant,
  then a recording can be fairly useless without including what the
  elicitor said. For instance, I've done blick testing (Could this be
  a word in your language?) where I didn't pay attention to recording
  myself and ended up incomprehensible recordings of "Yes. No. Yes."
  etc. Fortunately, the recording just barely picked up what was being
  elicited, but it's better to purposely set up a recording environment to
  record both the consultant and the elicitor. One can do this either
  by miking up both the consultant and the elicitor and making a
  stereo recording with separate channels for the consultant and
  elicitor, or by using a separate recorder for recording both the
  consultant and the elicitor and whatever else is going on in the
  surrounding environment with the recorder's internal mics.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Maximize
  &lt;a href="http://www.dspguide.com/ch25/3.htm"&gt;signal to noise ratio&lt;/a&gt;.&lt;/strong&gt; Even
  if the speech signal is high amplitude, that's not enough for good
  signal quality. If the speech signal is high amplitude but there's
  torrential rain pouring down a few feet away, signal quality will be
  compromised. If the speech signal is low-level, but you're in a
  quiet room, signal quality could still be fine for analysis. The
  higher level the speech signal, the higher the signal to noise
  ratio. The higher the background noise level, the lower the signal
  to noise ratio.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Keep background noise to a minimum.&lt;/strong&gt; It's generally a good idea
  to try to record in a quiet environment. A quiet back room is good
  if available. Try to avoid overhead fans, construction, animal
  noises, etc. Sometimes it could be worth waiting out weather-related
  noise if practical.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Maximize amplitude of speech signal (but avoid
  &lt;a href="http://avp.stackexchange.com/questions/446/what-is-clipping-distortion-what-causes-it-and-how-to-avoid-it-when-recordin"&gt;clipping&lt;/a&gt;).&lt;/strong&gt;
  You want your recording setup (including distance from mic to
  speaker, preamp(lifier) setup, recorder setup) to maximize the speech signal
  level without causing signal distortion. The mic should be close to
  the consultant's mouth, a little off to the side to avoid pops from
  noise bursts. Having a &lt;a href="http://www.sweetwater.com/insync/mic-preamp-buying-guide/"&gt;preamp&lt;/a&gt; in
  your recording setup is essential both to boost the signal level and
  to allow for easy adjustment of input levels during recording. But if you overload the mic
  preamplifier, you can get signal distortion, including clipping,
  which occurs when the amplitude of the signal exceeds the capacity
  of the preamplifier, as shown below, when the recorded signal
  exceeds the maximum range ([-1.0, 1.0] for Audacity, as shown below). If clipping occurs, it
  introduces the artifact of high frequency components to the signal,
  which is particularly problematic if you're interested in any kind
  of spectral analysis of the speech.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div align = "center"&gt;
  &lt;figure&gt;
    &lt;img
  src="/img/2013/06/clipping-audacity.gif"
  alt = "Demonstration of clipping during recording in an audio file in Audacity"
  width = "1000"&gt;
  &lt;figcaption&gt; Demonstration of clipping during recording in an audio file in Audacity&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;Audio recording software and devices usually have a meter you can
 observe to monitor the input level to maximize the input level
 without clipping. We show an example of a
 &lt;a href="http://manual.audacityteam.org/man/Meter_Toolbar"&gt;meter tool&lt;/a&gt; from
 Audacity below. The red bar to the right shows the recording level. If it
 goes past the blue line, we get clipping. In other recording software
 and for other recording devices, sometimes the meter tool will change
 color from green to red when the input level is too high.&lt;/p&gt;
&lt;div align = "center"&gt;
  &lt;figure&gt;
    &lt;img
  src="/img/2013/06/meter-audacity.jpg"
  alt = "Meter tool in Audacity"
  width = "400"&gt;
  &lt;figcaption&gt; &lt;a href="http://manual.audacityteam.org/man/Meter_Toolbar"&gt;Meter tool&lt;/a&gt; in Audacity for monitoring input levels. &lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Keep recordings on the shorter side and consider making summary recordings.&lt;/strong&gt; Consider breaking up a
  recording of a longish elicitation session into several audio
  files. This keeps file sizes smaller and if for any reason the file
  is damaged in any way or some technical difficulties occur, those
  issues will be localized to a smaller portion of the elicitation
  session. I generally try to keep recordings no longer than 10-15
  minutes. The downtime between the recordings also gives you and the
  consultant the chance to take a break and perhaps change batteries
  or the memory card if needed.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It's a good idea to record
  entire elicitation sessions, but it may also be helpful to record
  "summary sessions", where you consolidate the elicitation items into
  a densely packed session. Such shorter densely packed sessions allow high
  quality recording with lossless file formats without having gigantic
  file sizes.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Keep your audio files organized and backed up.&lt;/strong&gt; Copy your
  recorded audio files to additional storage devices as soon as
  possible after an elicitation session. Name your audio files &lt;a href="../organizing-elicitation-items#files"&gt;systematically&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id="wzxhzdk16wzxhzdk17notes-on-recording-equipment"&gt;&lt;a id="equipment"&gt;&lt;/a&gt;Notes on recording equipment&lt;/h2&gt;
&lt;p&gt;Now that we have an idea of the issues involved in thinking about a
recording setup, we'll consider recording equipment:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#mics"&gt;Microphones and accessories&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#recording"&gt;Audio recording devices&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="wzxhzdk18wzxhzdk19-microphones-and-accessories"&gt;&lt;a id="mics"&gt;&lt;/a&gt; Microphones and accessories&lt;/h3&gt;
&lt;p&gt;Some general properties that are desirable for mics in the field are that they:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Are comfortable.&lt;/strong&gt; This helps reduce the consultant's awareness of
  the recording procedure and makes a potentially unfamiliar process
  more friendly.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Reject background noise.&lt;/strong&gt; To maximize signal to noise ratio
  especially in potentially unavoidably noisy field conditions.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Rugged.&lt;/strong&gt; To withstand wear and tear.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;An example of a mic that fits the bill is the
&lt;a
href="http://www.shure.com/americas/products/microphones/sm/sm10a-headworn-microphone"
title="Shure SM10A" target="_blank"&gt;Shure SM10A&lt;/a&gt; headworn mic,
pictured below (left).&lt;/p&gt;
&lt;div align = "center"&gt;
  &lt;figure&gt;
    &lt;img
  src="http://cdn.shure.com/product/main_image/3566/prod_img_sm10a_l.jpg"
  alt="http://cdn.shure.com/product/main_image/3566/prod_img_sm10a_l.jpg"
  width="300"&gt;
    &lt;img
  src="http://cdn.shure.com/product/main_image/3751/prod_img_x2u_l.jpg"
  alt="http://cdn.shure.com/product/main_image/3751/prod_img_x2u_l.jpg"
  width="300"&gt;
    &lt;figcaption&gt;Sample recording equipment for fieldwork:&lt;br&gt; (l-r) Shure SM10A
  microphone
  [&lt;a href = "http://cdn.shure.com/product/main_image/3566/prod_img_sm10a_l.jpg"&gt;Shure&lt;/a&gt;];
  Shure X2u XLR to USB adapter [&lt;a href = "http://cdn.shure.com/product/main_image/3751/prod_img_x2u_l.jpg"&gt;Shure&lt;/a&gt;]&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;It's headworn and lightweight and adjustable, and it is pretty comfortable for long periods of time. Another nice
property of headworn mics is that the distance from the mic to the
sound source is quite easy to keep constant. To keep the distance from
a tabletop mic to the sound source constant, you have to be careful
about exactly where the consultant is sitting and where his/her mouth
is, etc. and be strict about the consultant holding still. If the
distance between the mic and the soundsource fluctuates, the input level also fluctuates.&lt;/p&gt;
&lt;p&gt;One other nice property of the Shure SM10A is that it is a
&lt;a href="http://homerecording.about.com/od/microphones101/a/mic_types.htm"&gt;&lt;em&gt;dynamic&lt;/em&gt;&lt;/a&gt;
&lt;a href="http://shure.custhelp.com/app/answers/detail/a_id/742/"&gt;rather than&lt;/a&gt; &lt;a href="http://www.sweetwater.com/insync/studio-microphone-buying-guide/"&gt;a condenser microphone&lt;/a&gt;
and requires no power supply for the generation of the audio
signal. Dynamic mics tend to be more rugged and are
moisture-resistant---good properties for the field.&lt;/p&gt;
&lt;p&gt;The Shure SM10A is also &lt;em&gt;unidirectional&lt;/em&gt;, which makes it great at
rejecting background noise and indispensible for working in
unavoidably noisy field environments. One drawback as a consequence is that there
is a &lt;a href="http://shure.custhelp.com/app/answers/detail/a_id/2844"&gt;proximity effect&lt;/a&gt;,
a boost in bass frequencies when the microphone is very close to the
sound source. This proximity effect means that one should be cautious
about directly comparing absolute values of acoustic spectral
properties of the speech signal between recordings when different
recording equipment is used, but this is not something that is
typically done anyway, since it's the relative acoustic properties in
speech sound contrasts that is most often of interest.&lt;/p&gt;
&lt;p&gt;A more significant drawback because of the small size of the mic, in
particular, because of its
&lt;a href="http://shure.custhelp.com/app/answers/detail/a_id/1867/"&gt;small magnet&lt;/a&gt;,
the signal from the mic is usually
&lt;a href="http://www.sweetwater.com/sweetcare/articles/what-nominal-level-of-shure-sm10a-headworn-microphone-little/"&gt;fairly weak&lt;/a&gt;,
even if the mic is very close to the mouth as it should be, but this
is acceptable as long as the signal to noise ratio is high.&lt;/p&gt;
&lt;p&gt;For recording directly to computer, an additional valuable mic
accessory is an external A/D converter and preamp, as we discussed in
&lt;a href="#practices"&gt;Notes on recording practices&lt;/a&gt;. One such device is the &lt;a
href="http://www.shure.com/americas/products/accessories/microphones/microphone-problem-solvers/x2u-xlr-to-usb-signal-adapter"
title="Shure X2u XLR-to-USB" target="_blank"&gt;Shure X2u&lt;/a&gt; (see
picture above right), which
accepts a male XLR connector (shown below) and plugs into a USB
port. You may also want
&lt;a href="http://www.amazon.com/dp/B000068O58"&gt;a cable to connect two XLR outputs to one XLR input&lt;/a&gt; if you want to record two
channels at once, e.g. one for the consultant and one for the elicitor. &lt;/p&gt;
&lt;div align = "center"&gt;
  &lt;figure&gt;
    &lt;img
  src="http://upload.wikimedia.org/wikipedia/commons/1/15/Xlr-connectors.jpg"
  alt = "XLR connectors, from http://commons.wikimedia.org/wiki/File:Xlr-connectors.jpg"
  width = "300"&gt;
  &lt;figcaption&gt;XLR connectors, (l-r) female and male [&lt;a href="http://upload.wikimedia.org/wikipedia/commons/1/15/Xlr-connectors.jpg"&gt;wikimedia&lt;/a&gt;]&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;
&lt;h3 id="wzxhzdk26wzxhzdk27-audio-recording-devices"&gt;&lt;a id="recording"&gt;&lt;/a&gt; Audio recording devices&lt;/h3&gt;
&lt;div align = "center"&gt;
  &lt;figure&gt;
    &lt;img
  src="http://www.samsontech.com/site_media/cms/images/product/zoom/handheld-audio-recorders/handheld-audio-recorders/h4n/H4n_slant-display.jpg"
  alt = "http://www.samsontech.com/site_media/cms/images/product/zoom/handheld-audio-recorders/handheld-audio-recorders/h4n/H4n_slant-display.jpg
" width="350"&gt;
    &lt;img src="http://www.roland.com/products/en/R-44/images/top_L.jpg"
  alt = "http://www.roland.com/products/en/R-44/images/top_L.jpg" width="350"&gt;
    &lt;figcaption&gt;Sample audio recording devices for fieldwork:&lt;br&gt;
  (l-r) Zoom H4n handheld recorder
  [&lt;a href = "http://www.samsontech.com/site_media/cms/images/product/zoom/handheld-audio-recorders/handheld-audio-recorders/h4n/H4n_slant-display.jpg"&gt;Samsontech&lt;/a&gt;]; Roland R-44 field recorder [&lt;a href = "http://www.roland.com/products/en/R-44/images/top_L.jpg"&gt;Roland&lt;/a&gt;]&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;For audio recording devices, some general desirable properties for
recording in the field are that they:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Are portable and robust to mechanical stress.&lt;/strong&gt; To withstand the rigors of
  field environment. Portable recorders currently on the market generally accept
  &lt;a href="http://www.howstuffworks.com/secure-digital-memory-cards.htm"&gt;SD cards&lt;/a&gt;,
  which use
  &lt;a href="http://computer.howstuffworks.com/flash-memory.htm"&gt;flash memory&lt;/a&gt;
  for disk storage. Flash memory is great for the field since it uses
  no moving parts, and is thus noiseless as well as robust to mechanical stress.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Allow multichannel recording.&lt;/strong&gt; So you can record a dyad of two or
  more consultants or record the consultant and the elicitor.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Have good quality built-in preamps.&lt;/strong&gt; You can have separate
  preamps, but it's nice to have them built into your recorder.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Support lossless audio file formats and high-quality recording.&lt;/strong&gt;
  It's a very bad idea to perform phonetic analysis with lossy audio
  file formats like MP3s. But lossy audio file formats might be the
  only practical choice for recordings of hours of recording
  sessions. More on settings for audio files in the
  &lt;a href="#audio"&gt;next section&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Have inputs appropriate for your mic setup without any adaptors.&lt;/strong&gt;
  You want your recording device to work seamlessly with your mic
  setup. Each interface between devices can introduce noise into the signal.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Two examples of audio recorders with these properties that I've had good experiences with are the &lt;a href="http://www.samsontech.com/zoom/products/handheld-audio-recorders/h4n/"&gt;Zoom H4n handheld recorder&lt;/a&gt; and the &lt;a href="http://www.roland.com/products/en/R-44/"&gt;Roland R-44 field recorder&lt;/a&gt;, pictured above,
with specs listed below.&lt;/p&gt;
&lt;table&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;td&gt;Device&lt;/td&gt;
            &lt;td&gt;Precision/bit depth (bit)&lt;/td&gt;
            &lt;td&gt;Sampling rate (kHz)&lt;/td&gt;
            &lt;td&gt;Input&lt;/td&gt;
            &lt;td&gt;Memory storage&lt;/td&gt;
            &lt;td&gt;Power supply&lt;/td&gt;
            &lt;td&gt;Size/weight&lt;/td&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;a href="http://www.samsontech.com/zoom/products/handheld-audio-recorders/h4n/" title="Zoom H4n" target="_blank"&gt;Zoom H4n&lt;/a&gt;
&lt;/td&gt;
            &lt;td&gt;16, 24&lt;/td&gt;
            &lt;td&gt;44.1, 48, 96&lt;/td&gt;
            &lt;td&gt;4 XLR inputs with phantom power &lt;/td&gt;
            &lt;td&gt;SD, SDHC, up to 32GB cards&lt;/td&gt;
            &lt;td&gt;AC adaptor (DC5V/1A/center plus) &lt;br&gt; AA size (LR6) battery x 2&lt;/td&gt;
            &lt;td&gt;70(W) x 156.3(D) x 35(H)mm &lt;br&gt; 280g (without batteries)&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;a href = "http://www.roland.com/products/en/R-44/", title="Roland R-44" target="_blank"&gt;Roland R-44&lt;/a&gt;&lt;/td&gt;
            &lt;td&gt;16, 24&lt;/td&gt;
            &lt;td&gt;44.1, 48, 88.2, 96, 192&lt;/td&gt;
            &lt;td&gt;4 XLR inputs with phantom power &lt;/td&gt;
            &lt;td&gt;SD, SDHC, 64MB-32GB&lt;/td&gt;
            &lt;td&gt;AC adaptor (PSB-1U) &lt;br&gt; AA type battery x 4 (Alkaline or NiMH)&lt;/td&gt;
            &lt;td&gt;157(W) x 183(D) x 61(H) mm &lt;br&gt; 1.3 kg with batteries&lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;These recorders both have the properties listed above, including XLR
inputs which work with the Shure SM10A headworn mic. Both can record
WAV files at least up to 24-bit/96kHz, which is overkill
for the recording quality necessary in recording speech (most
recorders are designed for the music market). The Zoom H4n is small
but still accepts 2 channels. The Roland R-44 is bigger, but still
easily portable, and accepts 4 channels; it's overall higher-end, but
is rather pricey.&lt;/p&gt;
&lt;h3 id="recording-directly-to-the-computer"&gt;Recording directly to the computer&lt;/h3&gt;
&lt;p&gt;An alternative to dedicated audio recording devices is to &lt;strong&gt;record
directly to a computer&lt;/strong&gt;, i.e. a laptop can also serve as an audio
recording device in the field, especially if you're bringing it along
anyway for other reasons. A couple caveats for recording
directly to a computer are that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;You need to be careful about running other processes simultaneously
while you're recording.&lt;/strong&gt; If you have an anti-virus program
continually scanning your hard disk or your computer is backing up
tons of new audio files while you're recording, the system resources
allocated to the audio recording could be affected. This could affect
the fidelity of your recording in unpredictable ways.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;You should have a device to perform analog-to-digital conversion
  external to the computer's sound card and to serve as a preamp.&lt;/strong&gt; 
&lt;a href="http://www.hardwaresecrets.com/article/317"&gt;Analog-to-digital conversion&lt;/a&gt;
  (A/D conversion) 
  converts the continuously varying analog voltage output from a mic into a quantized
  digital signal for the computer. If the A/D conversion is performed
  by a sound card internal to the computer, it can also pick up
  computer-internal noise. A
  &lt;a href="http://www.sweetwater.com/insync/mic-preamp-buying-guide/"&gt;preamp&lt;/a&gt;
  boosts the microphone signal and is important to get the speech
  signal to level useable for signal processing like pitch tracking.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;You may need to be more careful about mechanical stress.&lt;/strong&gt; Many
laptops nowadays still come with spinning hard drives, which are
vulnerable to damage from mechanical stress like bumpy truck rides and
falling. If you record directly to the computer without backing up
somewhere else, you leave your recorded files vulnerable to being lost
from hard disk
failure. &lt;a href="http://www.pcmag.com/article2/0,2817,2404258,00.asp"&gt;Solid state drives&lt;/a&gt;
are becoming more and more common and more affordable and are more reliable under
significant mechanical insult.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There is versatile and powerful
&lt;a href="http://freeopensourcesoftware.org/index.php?title=Main_Page"&gt;free and open source&lt;/a&gt;,
cross-platform (Windows/Mac OS X/Linux) audio recording/editing
software such as &lt;a href="http://audacity.sourceforge.net/"&gt;Audacity&lt;/a&gt; and
&lt;a href="http://www.praat.org"&gt;Praat&lt;/a&gt; available to use if you record directly to the
computer. I've also gotten and continue to get good use out of a
simple little recording application (Mac OS X only),
&lt;a href="http://mac.softpedia.com/get/Audio/Audio-Recorder.shtml"&gt;Audio Recorder&lt;/a&gt;,
developed by Ben Shanfelder, but it hasn't been updated
since 2008. See a more extended list of free and open source audio
recording/editing software
&lt;a href="http://en.wikipedia.org/wiki/List_of_free_software_for_audio"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="wzxhzdk28wzxhzdk29audio-file-specifications"&gt;&lt;a id = "audio"&gt;&lt;/a&gt;Audio file specifications&lt;/h2&gt;
&lt;p&gt;For audio recording devices and software, there's a plethora of
options available for setting properties of the digital audio file. A good review of
digital audio is
&lt;a href="http://www.jiscdigitalmedia.ac.uk/guide/an-introduction-to-digital-audio/"&gt;here&lt;/a&gt;. We'll
sketch some
guidelines for the most important properties here. &lt;/p&gt;
&lt;h3 id="lossless-and-lossy-file-formats"&gt;Lossless and lossy file formats&lt;/h3&gt;
&lt;p&gt;There are a
   &lt;a href="http://www.digitalpreservation.gov/formats/fdd/sound_fdd.shtml"&gt;variety&lt;/a&gt;
   of digital file formats for sound. The most common file formats
   you'll see in software and recording devices are WAV and MP3. The
   main consideration for recording speech is whether the file format
   is &lt;em&gt;lossless&lt;/em&gt; or &lt;em&gt;lossy&lt;/em&gt;. Lossless file formats, e.g. WAV, AIFF,
   FLAC, ALAC may be
   &lt;a href="http://www.jiscdigitalmedia.ac.uk/guide/uncompressed-audio-file-formats"&gt;compressed or uncompressed&lt;/a&gt;,
   but preserve the original audio in the most accurate digital
   representation possible given the recording settings. Lossy file
   formats, e.g. MP3, MP4, AAC, OGG are all compressed and involve the
   removal of audio data such that the original audio is irrecoverable
   from the file.&lt;/p&gt;
&lt;p&gt;For phonetic data analysis, it's imperative to record with lossless
   file formats like WAV since lossy file formats alter the sound. If
   a recording is done purely for keeping a record of what happened in
   an elicitation, lossy file formats can be appropriate and can yield
   smaller file sizes than compressed lossless file formats. However,
   since space is cheap and ever cheaper, it's likely that file size
   won't be a limiting factor at some point in the forseeable
   future. In addition, someone else may be able to use your recorded
   material as well, who wants to do phonetic analysis, so it's always
   worth considering using lossless file formats when possible.    &lt;/p&gt;
&lt;h3 id="sampling-rate"&gt;Sampling rate&lt;/h3&gt;
&lt;p&gt;The sample or sampling rate for an audio file is
   a property of the analog-to-digital conversion of the sound and
   determines the temporal resolution of the recorded signal. In the
   figure below from &lt;a href="http://www.jiscdigitalmedia.ac.uk/images/ITDA-02-sampling1.jpg"&gt;JISC
   Digital Media&lt;/a&gt;, the sine wave in (a) is sampled at the indicated
   points, giving the digital representation in (b) and (c). (The plot
   in (d) shows the digital representation after some postprocessing).  &lt;/p&gt;
&lt;div align = "center"&gt;
  &lt;figure&gt;
    &lt;img
  src="http://www.jiscdigitalmedia.ac.uk/images/ITDA-02-sampling1.jpg"
  alt = "Sampling of a sine wave"
  width = "1000"&gt;
  &lt;figcaption&gt; The sampling rate of a sine wave controls the temporal
  resolution of its digital representation.
  [&lt;a href="http://www.jiscdigitalmedia.ac.uk/images/ITDA-02-sampling1.jpg"&gt;JISC Digital Media&lt;/a&gt;]&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;The main consideration for the sampling rate is what the highest
  frequency of interest is; the sampling rate needs to be at least
  twice this frequency to avoid
  &lt;a href="http://www.jiscdigitalmedia.ac.uk/guide/an-introduction-to-digital-audio/"&gt;aliasing&lt;/a&gt;,
  in which higher frequencies are indistinguishable from lower
  ones. The highest frequencies in speech generally aren't higher than
  5000-6000 Hz, so a sampling rate of 16 000, i.e. 16 kHz is
  sufficient for recording speech, and even 11 kHz can be acceptable,
  depending on the research question.&lt;/p&gt;
&lt;p&gt;However, since recorders are marketed for musicians, the lowest sample rate
  option offered for an audio recorder may be CD quality 44.1kHz. You
  may choose to &lt;em&gt;downsample&lt;/em&gt; the file later, after recording (see
  &lt;a href="../processing-audio-files-sox/#downsample"&gt;Sox&lt;/a&gt; and &lt;a href="../processing-audio-files-praat/#downsample"&gt;Praat&lt;/a&gt; tutorials), in order to reduce file size. &lt;/p&gt;
&lt;h3 id="precisionbit-depth"&gt;Precision/bit depth&lt;/h3&gt;
&lt;p&gt;Another property of the analog-to-digital
   audio conversion is the &lt;em&gt;precision&lt;/em&gt; or &lt;em&gt;bit depth&lt;/em&gt;. This regulates
   not temporal resolution, like sample rate, but the resolution in
   the &lt;em&gt;quantization&lt;/em&gt; of the amplitude of the speech signal, as shown
   below. The higher the bit depth is, the less grainy the
   representation of changes in the amplitude of the speech signal.&lt;/p&gt;
&lt;div align = "center"&gt;
  &lt;figure&gt;
    &lt;img
  src="http://www.jiscdigitalmedia.ac.uk/images/ITDA-05-bitdepth.jpg"
  alt = "Precision/bit depth"
  width = "500"&gt;
  &lt;figcaption&gt; Comparison of 2-bit (3 levels) with 5-bit (32 levels)
  of quantization.
  [&lt;a href="http://www.jiscdigitalmedia.ac.uk/images/ITDA-05-bitdepth.jpg"&gt;JISC Digital Media&lt;/a&gt;]&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;The options for precision/bit depth offered in software and recorders
are usually 16 or 24 bit. 16 bit is generally sufficient for recording
speech.&lt;/p&gt;</content><category term="ldc-kiy"></category><category term="fieldwork"></category><category term="tutorial"></category></entry><entry><title>Preparing elicitation items for presentation</title><link href="http://kmyu.github.io/blog/preparing-elicitation-items-for-presentation.html" rel="alternate"></link><published>2013-06-23T09:33:00-04:00</published><updated>2013-06-23T09:33:00-04:00</updated><author><name>Kristine Yu</name></author><id>tag:kmyu.github.io,2013-06-23:/blog/preparing-elicitation-items-for-presentation.html</id><summary type="html">&lt;p&gt;Tutorial for LDC paper: preparing elicitation items for presentation.&lt;/p&gt;</summary><content type="html">&lt;p&gt;For elicitation sessions designed to confirm hypotheses, the
elicitation items may be known in advance. In such cases, it can be
helpful to prepare a set of slides for elicitation in advance and to
run a "canned" elicitation session.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Why canned?&lt;/strong&gt; For blocking and randomizing stimuli (see Section
  2.3 of the paper), it's necessary
  to prepare stimulus presentation order in advance.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Why slides?&lt;/strong&gt; Slides can be beneficial relative to a list of words
  since they clearly separate one elicitation item from another for
  both the elicitor and the consultant. This can help with ordering
  effects, especially at the end of an elicitation session. With a
  list, the consultant is very aware of the impending end of the
  session and this awareness can induce changes in their pronunciation
  such as discourse/utterance-final prosody. The isolation of one
  elicitation from another can also help emphasize the sense of each
  elicitation item being in its own discourse context and help prevent
  list intonation. &lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this tutorial, we illustrate how to go from a spreadsheet of
elicitation items to slides for presentation during an elicitation
session. We use Microsoft Excel and Microsoft Word, but other
spreadsheet and word processing software programs can be used in a
similar way.&lt;/p&gt;
&lt;p&gt;All files referenced in the tutorial are in &lt;a href="http://media.krisyu.org/ldc-kiy/"&gt;this directory&lt;/a&gt; in
the &lt;code&gt;tutorials/preparing-stimuli/&lt;/code&gt; &lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-elicitation-items/"&gt;sub-directory&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We start with our spreadsheet for &lt;code&gt;20111215-kiy-2-framedwordlist&lt;/code&gt;.
To get from this spreadsheet to preparing stimuli for presentation in
an elicitation session, we need to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#order"&gt;Set and document an order for eliciting the stimulus set&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#format"&gt;Format the stimuli for visual presentation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="wzxhzdk4wzxhzdk5set-and-document-an-order-for-eliciting-the-stimulus-set"&gt;&lt;a id="order"&gt;&lt;/a&gt;Set and document an order for eliciting the stimulus set&lt;/h2&gt;
&lt;p&gt;You can follow along with the tutorial by starting with the file
&lt;code&gt;20111215-2-kiy-ap-framedwordlist.xlsx&lt;/code&gt; in the &lt;code&gt;tutorials/preparing-elicitation-items/&lt;/code&gt; &lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-elicitation-items/"&gt;directory&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The simplest kind of randomization of stimulus order you can do is a
pure randomization without any constraints, e.g. "no items of both
Tone 2 one after another". Here's a quick way to do this in
spreadsheets:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;In a new column, type a column header label "&lt;strong&gt;rand&lt;/strong&gt;". We'll fill
this column with randomly generated numbers.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In the first cell in the column, enter the &lt;a href="http://office.microsoft.com/en-us/excel-help/rand-function-HP010342816.aspx"&gt;&lt;code&gt;RAND()&lt;/code&gt;&lt;/a&gt;
command to fill the cell with a randomly generated number between 0 and 1:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Then double-click the right-bottom corner of this cell to have the &lt;code&gt;RAND()&lt;/code&gt; command be filled down the column. Now you've got a random number in each row of the hash table!&lt;/p&gt;
&lt;p&gt;&lt;p align="center"&gt;
&lt;a href="/img/2013/05/20111215-2-kiy-ap-rand1.png"&gt;&lt;img
class="size-full"  alt="Use RAND() to generate a column of random
numbers for sorting stimulus order."
src="/img/2013/05/20111215-2-kiy-ap-rand1.png"
width="700"/&gt;&lt;/a&gt;&lt;br&gt;
&lt;em&gt;Use &lt;code&gt;RAND()&lt;/code&gt; to generate a column of random numbers for sorting stimulus order.&lt;/em&gt;
&lt;/p&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A problem: Excel will recalculate the column of random numbers any time you do anything with them, include sorting with them. There are two ways to fix this:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;h4 id="method-1"&gt;Method 1&lt;/h4&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Change the calculation mode to &lt;code&gt;Manually&lt;/code&gt; in &lt;code&gt;Excel &amp;gt;
  Preferences&lt;/code&gt; under the preference settings for &lt;code&gt;Calculation&lt;/code&gt;. Also
  make sure that &lt;code&gt;Always calculate before saving workbook&lt;/code&gt; is &lt;strong&gt;not
  checked&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;p align="center"&gt;
  &lt;a href="/img/2013/05/excel-calc.jpg"&gt;&lt;img
  class="size-full"  alt="The Calculation preference pane."
  src="/img/2013/05/excel-calc.jpg" width="300"
  /&gt;&lt;/a&gt;&lt;br&gt;&lt;em&gt;The Calculation preference pane.&lt;/em&gt;
  &lt;/p&gt;&lt;/p&gt;
&lt;p&gt;&lt;p align="center"&gt;
  &lt;a href="/img/2013/05/excel-calculate-manual.png"&gt;&lt;img
  class="size-full"  alt="Setting calculation mode to manually."
  src="/img/2013/05/excel-calculate-manual.png"
  width="300" /&gt;&lt;/a&gt;&lt;br&gt;&lt;em&gt;Setting calculation mode to manually.&lt;/em&gt;
 &lt;/p&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;h4 id="method-2"&gt;Method 2&lt;/h4&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Copy the column of random numbers and use &lt;code&gt;Edit &amp;gt; Paste
  Special&lt;/code&gt; to paste just the &lt;code&gt;Values&lt;/code&gt;. Use this column to do
  the sorting in the next step.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Now we'll &lt;strong&gt;sort&lt;/strong&gt; the hash table by these random
    numbers. Double-click on the icon with a triangle on the right
    corner of the &lt;strong&gt;rand&lt;/strong&gt; column header cell to pop up a dialogue box
    for sorting. (If you don't see such an icon, then make sure that
    &lt;code&gt;Data &amp;gt; Filter&lt;/code&gt; is checked:&lt;/p&gt;
&lt;p&gt;&lt;p align = "center"&gt;
&lt;a href="/img/2013/05/excel-filter.png"&gt;&lt;img
class="size-medium wp-image-133" alt="Make sure that Filter is
checked so that the filter icons show up in the table header
cells." src="/img/2013/05/excel-filter.png" width="500"
height="183" /&gt;&lt;/a&gt;&lt;br&gt;
&lt;em&gt;Make sure that &lt;code&gt;Filter&lt;/code&gt; is checked so that the filter icons show
up in the table header cells.&lt;/em&gt;
&lt;/p&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Click on &lt;code&gt;Ascending&lt;/code&gt; (or &lt;code&gt;Descending&lt;/code&gt;, it doesn't matter) and then
close the dialogue box. Now your items are sorted by the random
numbers from least to greatest, i.e., your item order has been
randomized! Note that if we sort in ascending order by the &lt;strong&gt;item&lt;/strong&gt;
column, we'll get our original spreadsheet order back. So it's really
important that we have the elicitation item key (ID/barcode), as
discussed in
&lt;a href="../organizing-elicitation-items/"&gt;Organizing elicitation items&lt;/a&gt;, so
we always can keep tabs on an elicitation item, even if we randomize
the elicitation item order.&lt;/p&gt;
&lt;p&gt;&lt;p align = "center"&gt;
&lt;a href="/img/2013/05/20111215-2-kiy-ap-rand-sorted.png"&gt;&lt;img
class="size-full wp-image-135" alt="Items in hash table sorted by
the random numbers in Column M in ascending order"
src="/img/2013/05/20111215-2-kiy-ap-rand-sorted.png"
width="700" /&gt;&lt;/a&gt;&lt;br&gt; &lt;em&gt;Items in spreadsheet sorted by the
random numbers in Column M in ascending order&lt;/em&gt;
&lt;/p&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Make sure you &lt;strong&gt;save&lt;/strong&gt; your stimuli in randomized order, e.g. as a
   new file &lt;code&gt;20111215-2-kiy-ap-framedwordlist-rand.xlsx&lt;/code&gt;. Note that
   your final spreadsheet may look different from the file
   &lt;code&gt;20111215-2-kiy-ap-framedwordlist-rand.xlsx&lt;/code&gt; in the
   &lt;code&gt;tutorials/preparing-elicitation-items/&lt;/code&gt;
   &lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-elicitation-items/"&gt;directory&lt;/a&gt;
   since your randomized order will be different.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id="wzxhzdk6wzxhzdk7format-the-stimuli-for-visual-presentation"&gt;&lt;a id="format"&gt;&lt;/a&gt;Format the stimuli for visual presentation&lt;/h2&gt;
&lt;p&gt;Now you can copy your stimuli from Excel into Word to generate a slideshow for your elicitation session! Since the spreadsheet &lt;code&gt;20111215-2-kiy-ap-framedwordlist-rand.xlsx&lt;/code&gt; preserves the association of each stimulus item to its properties, e.g. &lt;code&gt;word.1&lt;/code&gt;, &lt;code&gt;word.2&lt;/code&gt;, &lt;code&gt;verb&lt;/code&gt;, etc., we don't need to worry about keeping track about these properties in creating the slideshow---all we need to copy over is, minimally, the English free translations in the &lt;code&gt;sent.eng&lt;/code&gt; column, since we need a prompt to elicit each item during the elicitation session. &lt;/p&gt;
&lt;p&gt;We might also want to copy over the Kirikiri sentences in &lt;code&gt;sent.kiy&lt;/code&gt; and the targeted tonal patterns in &lt;code&gt;bitone&lt;/code&gt; so we have an idea of what we're expecting the consultant to utter for each elicitation item, to help check as we go along in the elicitation session that we're actually eliciting what we intend to elicit.&lt;/p&gt;
&lt;p&gt;Here's how to turn your Excel data into slides to present in
elicitation in Word, in two steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="#copy"&gt;Copy the stimuli from the Excel spreadsheet into Word&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#word"&gt;Re-formatting the Word document to create slides&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="wzxhzdk8wzxhzdk9-copy-the-stimuli-from-the-excel-spreadsheet-into-word"&gt;&lt;a id="copy"&gt;&lt;/a&gt; Copy the stimuli from the Excel spreadsheet into Word&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Select the columns you want in your slides and copy them to the system clipboard by clicking on &lt;code&gt;Copy&lt;/code&gt; in the &lt;code&gt;Edit&lt;/code&gt; menu:&lt;/p&gt;
&lt;p&gt;&lt;p align = "center"&gt;
&lt;a href="/img/2013/05/excel-copy1.jpg"&gt;&lt;img
src="/img/2013/05/excel-copy1.jpg" alt="Select the
columns you want  to appear in your slides for presentation and
copy." width ="625" height="267" class="size-large
wp-image-187"/&gt;&lt;/a&gt;&lt;br&gt;
&lt;em&gt;Select the columns you want  to appear in your slides for
presentation and copy.&lt;/em&gt;
&lt;/p&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Open Microsoft Word and select &lt;code&gt;Paste Special...&lt;/code&gt; in the &lt;code&gt;Edit&lt;/code&gt; menu.&lt;/p&gt;
&lt;p&gt;&lt;p align = "center"&gt;
&lt;a href="/img/2013/05/word-paste-special.jpg"&gt;&lt;img
src="/img/2013/05/word-paste-special.jpg" alt="Paste the copied Excel
data as unformatted text" width="366" height="326" class="size-full
wp-image-196" /&gt;&lt;/a&gt;&lt;br&gt;
&lt;em&gt;Paste the copied Excel data as unformatted text&lt;/em&gt;
&lt;/p&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Now you should have a bunch of text in your Word document, with one item per line, in your randomized order from &lt;code&gt;20111215-2-kiy-ap-framedwordlist-rand.xlsx&lt;/code&gt;. Note that the original column breaks in Excel are preserved here with &lt;em&gt;tab-delimited&lt;/em&gt; formatting: in each row, tab characters separate the original Excel columns. Also, each line ends in a &lt;em&gt;newline&lt;/em&gt; (paragraph symbol) which indicates a line break. If you don't see any of these special characters, make sure that you have set the option &lt;code&gt;Show all non-printing characters&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p align = "center"&gt;
&lt;a href="/img/2013/05/word-stims-unformatted.jpg"&gt;&lt;img src="/img/2013/05/word-stims-unformatted.jpg" alt="Pasted text from Excel. Pay special attention to the special characters separating columns (tabs) and lines (newline/paragraph symbol)." width="560" height="229" class="size-full wp-image-201" /&gt;&lt;/a&gt;&lt;br&gt;
&lt;i&gt;Pasted text from Excel. Pay special attention to the special characters separating columns (tabs) and lines (newline/paragraph symbol).&lt;/i&gt;
&lt;/p&gt;

&lt;p align = "center"&gt;
&lt;a href="/img/2013/05/word-special-char.jpg"&gt;&lt;img src="/img/2013/05/word-special-char.jpg" alt="Click on the paragraph
symbol icon to show the special characters." width="482" height="175"
class="size-full wp-image-204" /&gt;&lt;/a&gt;&lt;br&gt;
Click on the paragraph symbol icon to show the special characters.
&lt;/p&gt;

&lt;h3 id="wzxhzdk10wzxhzdk11-re-formatting-the-word-document-to-create-slides"&gt;&lt;a id="word"&gt;&lt;/a&gt; Re-formatting the Word document to create slides&lt;/h3&gt;
&lt;p&gt;Now we're all set to start re-formatting the Word document,
&lt;code&gt;20111215-2-kiy-ap-framedwordlist-slides0.docx&lt;/code&gt; (in the &lt;code&gt;tutorials/preparing-elicitation-items/&lt;/code&gt; &lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-elicitation-items/"&gt;directory&lt;/a&gt;.
) to create slides. We'll be making PDF slides that look like the figure below:&lt;/p&gt;
&lt;p align = "center"&gt;
&lt;a href="/img/2013/06/slide-for-elicitor.jpg"&gt;&lt;img
src="/img/2013/06/slides-for-elicitor.jpg"
alt="Slides for elicitor." width="560" /&gt;&lt;/a&gt;&lt;br&gt;
&lt;i&gt;Slides for the elicitor, including the bitone, Kirikiri sentence,
and English translation.&lt;/i&gt;
&lt;/p&gt;

&lt;p&gt;The slides are for the elicitor and/or translator and thus include
information beyond the Kirikiri sentence or the English
translation. &lt;/p&gt;
&lt;p&gt;The screencast below illustrates the steps for creating the slides
&lt;code&gt;20111215-2-kiy-ap-framedwordlist-slides.pdf&lt;/code&gt; and
&lt;code&gt;20111215-2-kiy-ap-framedwordlist-slides.docx&lt;/code&gt; from
&lt;code&gt;20111215-2-kiy-ap-framedwordlist-slides0.docx&lt;/code&gt;. All files are in the
&lt;code&gt;tutorials/preparing-elicitation-items/&lt;/code&gt;
&lt;a href="http://media.krisyu.org/ldc-kiy/tutorials/preparing-elicitation-times/"&gt;directory&lt;/a&gt;. The
steps are also outlined below in the tutorial body.&lt;/p&gt;
&lt;p align = "center"&gt;
&lt;video controls&gt;
  &lt;source src="http://media.krisyu.org/ldc-kiy/videos/20111215-2-kiy-ap-framedwordlist-slides.mp4" type="video/mp4"&gt;
  &lt;source src="http://media.krisyu.org/ldc-kiy/videos/20111215-2-kiy-ap-framedwordlist-slides.ogv" type="video/ogg"&gt;
  Your browser does not support the video tag.
&lt;/video&gt;
Screencast:creating slides for presentation of elicitation items to consultant.
&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;We'll use the &lt;a href="http://support.microsoft.com/kb/214204"&gt;special characters&lt;/a&gt; to help us format the slides using the &lt;code&gt;Find and Replace&lt;/code&gt; command. Make sure the cursor is set at the beginning of the document. Now click on &lt;code&gt;Edit &amp;gt; Find &amp;gt; Replace&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;&lt;p align = "center"&gt;
&lt;a href="/img/2013/05/word-find-replace.jpg"&gt;&lt;img
src="/img/2013/05/word-find-replace.jpg"
alt="Select Edit &amp;gt; Find &amp;gt;Replace." width="466" height="337"
class="size-full wp-image-206" /&gt;&lt;/a&gt;&lt;br&gt; 
&lt;i&gt;Select &lt;code&gt;Edit &amp;gt; Find &amp;gt; Replace&lt;/code&gt;.&lt;/i&gt;
&lt;/p&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use &lt;code&gt;Find &amp;gt; Replace&lt;/code&gt; to make the following replacements, in the stated order (order matters!):&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Replace &lt;em&gt;carriage return/paragraph mark&lt;/em&gt; &lt;code&gt;^p&lt;/code&gt; with &lt;em&gt;pagebreak&lt;/em&gt;
   &lt;code&gt;^m&lt;/code&gt; followed by a few &lt;em&gt;carriage return/paragraph marks&lt;/em&gt;
   &lt;code&gt;^p^p&lt;/code&gt;, i.e., with &lt;code&gt;^m^p^p&lt;/code&gt;. (The carriage return/paragraph
   mark &lt;code&gt;^p&lt;/code&gt; behaves effectively like a newline/line break character.)&lt;/li&gt;
&lt;li&gt;Replace &lt;em&gt;tab&lt;/em&gt; &lt;code&gt;^t&lt;/code&gt; with &lt;em&gt;carriage return/paragraph mark&lt;/em&gt; &lt;code&gt;^p&lt;/code&gt; 
&lt;p&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This replaces: (1) the carriage returns with page breaks, plus a few
extra carriage returns to help vertically center the text on the slide,
and (2) the tabs with carriage returns, so that each different field
(bitone, sent.kiy, sent.eng) ends up on a different line. So now
each elicitation item gets its own slide.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Increase the font size of the text in the document. Go to &lt;code&gt;Edit &amp;gt;
   Select all&lt;/code&gt; and then change the font size to something that easily
   readable but also not so gigantic that it's hard to fit much text
   into a line. Something like 24 or 36 might work well.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Change the orientation of the document from portrait to
   landscape. Go to &lt;code&gt;Format &amp;gt; Document &amp;gt; Page Setup&lt;/code&gt; and click on
   the &lt;em&gt;landscape&lt;/em&gt; orientation icon. Now your slides will be in
   landscape mode.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Finally, make sure you save your Word document. You might also save
   the slides in a PDF file.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If you want your &lt;strong&gt;consultant&lt;/strong&gt; to be looking at your slides for
   elicitation, you might just want each slide to show the
   sentence/word written in the language to be elicited or the
   sentence/word in the contact language. In this case, you would copy
   only the relevant column, e.g. &lt;em&gt;sent.kiy&lt;/em&gt;, over from the spreadsheet
   to Word and repeat the steps 1-5 above.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;</content><category term="ldc-kiy"></category><category term="fieldwork"></category><category term="tutorial"></category></entry><entry><title>Markdown and LaTeX reference</title><link href="http://kmyu.github.io/blog/markdown-and-latex-reference.html" rel="alternate"></link><published>2013-06-21T09:33:00-04:00</published><updated>2013-06-21T09:33:00-04:00</updated><author><name>Kristine Yu</name></author><id>tag:kmyu.github.io,2013-06-21:/blog/markdown-and-latex-reference.html</id><summary type="html">&lt;p&gt;Practice with markdown based on
&lt;a href="http://daringfireball.net/projects/markdown/"&gt;John Gruber's Markdown page&lt;/a&gt;. Pelican
works with the &lt;a href="http://pythonhosted.org/Markdown/"&gt;Python Markdown&lt;/a&gt;
Markdown processor. Also some practice with $\LaTeX$ using the
&lt;a href="https://github.com/getpelican/pelican-plugins/tree/master/latex"&gt;Pelican latex plugin&lt;/a&gt;,
which uses &lt;a href="http://www.mathjax.org/"&gt;MathJaX&lt;/a&gt;. &lt;strong&gt;Update: 04/2015: the latex
plugin is deprecated and has been superseded by the
&lt;a href="https://github.com/getpelican/pelican-plugins/tree/master/render_math"&gt;render_math plug-in&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#core-markdown"&gt;Core Markdown&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#py-markdown"&gt;Python Markdown …&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;p&gt;Practice with markdown based on
&lt;a href="http://daringfireball.net/projects/markdown/"&gt;John Gruber's Markdown page&lt;/a&gt;. Pelican
works with the &lt;a href="http://pythonhosted.org/Markdown/"&gt;Python Markdown&lt;/a&gt;
Markdown processor. Also some practice with $\LaTeX$ using the
&lt;a href="https://github.com/getpelican/pelican-plugins/tree/master/latex"&gt;Pelican latex plugin&lt;/a&gt;,
which uses &lt;a href="http://www.mathjax.org/"&gt;MathJaX&lt;/a&gt;. &lt;strong&gt;Update: 04/2015: the latex
plugin is deprecated and has been superseded by the
&lt;a href="https://github.com/getpelican/pelican-plugins/tree/master/render_math"&gt;render_math plug-in&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#core-markdown"&gt;Core Markdown&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#py-markdown"&gt;Python Markdown extensions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#code"&gt;Code blocks and syntax highlighting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#latex"&gt;LaTeX&lt;/a&gt;
&lt;!-- PELICAN_END_SUMMARY --&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="wzxhzdk42wzxhzdk43-core-markdown-reference"&gt;&lt;a id = "core-markdown"&gt;&lt;/a&gt; Core Markdown reference&lt;/h2&gt;
&lt;h3 id="text-formatting"&gt;Text formatting&lt;/h3&gt;
&lt;h4 id="headlines-and-horizontal-rules"&gt;Headlines and horizontal rules&lt;/h4&gt;
&lt;p&gt;Headline depth can be indicated with #, e.g.&lt;/p&gt;
&lt;h1 id="h1-with"&gt;H1, with '#'&lt;/h1&gt;
&lt;h2 id="h2-with"&gt;H2, with '##'&lt;/h2&gt;
&lt;h3 id="h3-with"&gt;H3, with '###'&lt;/h3&gt;
&lt;p&gt;Headlines for H1 and H2 can also be indicated with "underlining":&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;H1
====

H2
-----
&lt;/pre&gt;&lt;/div&gt;


&lt;h1 id="h1"&gt;H1&lt;/h1&gt;
&lt;h2 id="h2"&gt;H2&lt;/h2&gt;
&lt;p&gt;Horizontal rules can be indicated with 3+ of *, - or _:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gh"&gt;***&lt;/span&gt;
&lt;span class="gh"&gt;---&lt;/span&gt;
___
&lt;/pre&gt;&lt;/div&gt;


&lt;hr&gt;
&lt;hr&gt;
&lt;hr&gt;
&lt;h4 id="emphasis"&gt;Emphasis&lt;/h4&gt;
&lt;p&gt;Emphasized text can be indicated with * or _&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Emphasized text looks like &lt;em&gt;this&lt;/em&gt; or &lt;em&gt;this&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Strong text can be indicated with double * or _,
e.g. &lt;strong&gt;this&lt;/strong&gt; or &lt;strong&gt;this&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Strong and emphasized text can be indicate with triple asterisks,
&lt;strong&gt;&lt;em&gt;like this&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id="blockquotes"&gt;Blockquotes&lt;/h4&gt;
&lt;p&gt;Blockquotes can be indicated with &amp;gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Here's a blockquote.&lt;/p&gt;
&lt;p&gt;Here's another blockquote.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id="lists"&gt;Lists&lt;/h4&gt;
&lt;p&gt;Items in itemized lists can be enumerated with +, -, * for unordered lists or with 1., 2., 3. for ordered lists.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;* Unordered item
* Another unordered item
* Yet another unordered item
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;Unordered item&lt;/li&gt;
&lt;li&gt;Another unordered item&lt;/li&gt;
&lt;li&gt;Yet another unordered item&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;1. Item 1
2. Item 2
3. Item 3
&lt;/pre&gt;&lt;/div&gt;


&lt;ol&gt;
&lt;li&gt;Item 1&lt;/li&gt;
&lt;li&gt;Item 2&lt;/li&gt;
&lt;li&gt;Item 3&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;* Item, followed by blank line

* Item with new paragraph
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Item, followed by blank line&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Item with new paragraph&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="links"&gt;Links&lt;/h3&gt;
&lt;h4 id="in-line-link"&gt;In-line link&lt;/h4&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;link&lt;/span&gt; &lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;](&lt;/span&gt;&lt;span class="n"&gt;link&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Optional title&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;blog&lt;/span&gt;&lt;span class="p"&gt;](&lt;/span&gt;&lt;span class="nl"&gt;http&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="c1"&gt;//www.krisyu.org &amp;quot;blog&amp;quot;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;a href="http://www.krisyu.org" title="blog"&gt;Kristine's blog&lt;/a&gt;&lt;/p&gt;
&lt;h4 id="referenced-link"&gt;Referenced link&lt;/h4&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Here&amp;#39;s a link to [UMass Linguistics][1] and here&amp;#39;s one to [UCLA
Linguistics][2]

[1]: http://www.umass.edu/linguist &amp;quot;UMass Linguistics&amp;quot;
[2]: http://www.linguistics.ucla.edu &amp;quot;UCLA Linguistics&amp;quot;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Here's a link to &lt;a href="http://www.umass.edu/linguist" title="UMass Linguistics"&gt;UMass Linguistics&lt;/a&gt; and here's one to &lt;a href="http://www.linguistics.ucla.edu" title="UCLA Linguistics"&gt;UCLA Linguistics&lt;/a&gt;&lt;/p&gt;
&lt;h3 id="images"&gt;Images&lt;/h3&gt;
&lt;p&gt;In-line images: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;![Sideways kitties](/static/blog/img/2013/06/emmy-sophie-sideways.jpg &amp;quot;Emmy and Sophie&amp;quot;)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="Sideways kitties" src="/static/blog/img/2013/06/emmy-sophie-sideways.jpg" title="Emmy and Sophie"&gt;&lt;/p&gt;
&lt;p&gt;Reference-style images: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;![Young Indie][indie]
![Baby Hunter][hunter]

[indie]: /static/blog/img/2013/06/indie.jpg &amp;quot;Young Indie&amp;quot;
[hunter]: /static/blog/img/2013/06/hunter.jpg &amp;quot;Baby Hunter&amp;quot;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="Young Indie" src="/static/blog/img/2013/06/indie.jpg" title="Young Indie"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="Baby Hunter" src="/static/blog/img/2013/06/hunter.jpg" title="Baby Hunter"&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="wzxhzdk44python-markdown-extensions"&gt;&lt;a id = "py-markdown"&lt;/a&gt;Python Markdown extensions&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://docs.getpelican.com/en/3.2/settings.html"&gt;Pelican settings documentation&lt;/a&gt;
lists &lt;code&gt;MD_EXTENSIONS&lt;/code&gt; as a configurable setting, with the default:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;MD_EXTENSIONS (['codehilite(css_class=highlight)','extra'])&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Supported Python Markdown extensions are listed
&lt;a href="http://pythonhosted.org/Markdown/extensions/"&gt;here&lt;/a&gt;. The default
setting of &lt;code&gt;extra&lt;/code&gt; for &lt;code&gt;MD_EXTENSIONS&lt;/code&gt; includes the following set of extensions:&lt;/p&gt;
&lt;h3 id="attribute-lists"&gt;&lt;a href="http://pythonhosted.org/Markdown/extensions/attr_list.html"&gt;Attribute lists&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Here's an example of specifying the &lt;em&gt;id&lt;/em&gt; for a header:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;### A hash style header ### {: #barcode }
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;is rendered as&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;h3&lt;/span&gt; &lt;span class="na"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;barcode&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;A hash style header&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;h3&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Here's an example of specifying the &lt;em&gt;id&lt;/em&gt; and &lt;em&gt;class&lt;/em&gt; for a paragraph
element:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;This is a paragraph.
{: #an_id .a_class }
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;is rendered as&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;p&lt;/span&gt; &lt;span class="na"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;an_id&amp;quot;&lt;/span&gt; &lt;span class="na"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;a_class&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;This is a paragraph.&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;p&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;[link](http://example.com){: class=&amp;quot;class_name&amp;quot; title=&amp;quot;link title&amp;quot; }
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;is rendered as&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;p&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;a&lt;/span&gt; &lt;span class="na"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;http://example.com&amp;quot;&lt;/span&gt; &lt;span class="na"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;foo bar&amp;quot;&lt;/span&gt; &lt;span class="na"&gt;title&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Some title!&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;link&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;a&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;p&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3 id="footnotes"&gt;&lt;a href="http://pythonhosted.org/Markdown/extensions/footnotes.html"&gt;Footnotes&lt;/a&gt;&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;The cat that chased the rat meowed.[^1]

[^1]: Whoa, is this some embedding?
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The cat that chased the rat meowed.&lt;sup id="fnref-1"&gt;&lt;a class="footnote-ref" href="#fn-1"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;h3 id="tables"&gt;&lt;a href="http://pythonhosted.org/Markdown/extensions/tables.html"&gt;Tables&lt;/a&gt;&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Lexer  | shortname | file extensions
------------- | ------------- | ----------
`Python3Lexer`  | python3, py3 |
`PythonLexer`  | python, py | \*.py, \*.pyw, \*.sc, SConstruct, SConscript, \*.tac, \*.sage
`PythonConsoleLexer`  | pycon |
`PrologLexer` | prolog | \*.prolog, \*.pro, \*.pl
&lt;/pre&gt;&lt;/div&gt;


&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Lexer&lt;/th&gt;
&lt;th&gt;shortname&lt;/th&gt;
&lt;th&gt;file extensions&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;Python3Lexer&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;python3, py3&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;PythonLexer&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;python, py&lt;/td&gt;
&lt;td&gt;*.py, *.pyw, *.sc, SConstruct, SConscript, *.tac, *.sage&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;PythonConsoleLexer&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;pycon&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;PrologLexer&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;prolog&lt;/td&gt;
&lt;td&gt;*.prolog, *.pro, *.pl&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="smart-strong"&gt;&lt;a href="http://pythonhosted.org/Markdown/extensions/smart_strong.html"&gt;Smart Strong&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;This treats double underscores within words intelligently??&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;___first___second____third
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;&lt;em&gt;first&lt;/em&gt;&lt;/strong&gt;second____third&lt;/p&gt;
&lt;h3 id="abbreviations"&gt;&lt;a href="http://pythonhosted.org/Markdown/extensions/abbreviations.html"&gt;Abbreviations&lt;/a&gt;&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;*[ATP]: adenosine triphosphate
*[PDCB]: paradichlorobenzene

The molecule ATP provides energy to molecular motors. PDCB is a
common ingredient in mothballs.
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The molecule &lt;abbr title="adenosine triphosphate"&gt;ATP&lt;/abbr&gt; provides energy to molecular motors. &lt;abbr title="paradichlorobenzene"&gt;PDCB&lt;/abbr&gt; is a
common ingredient in mothballs.&lt;/p&gt;
&lt;h3 id="definition-lists"&gt;&lt;a href="http://pythonhosted.org/Markdown/extensions/definition_lists.html"&gt;Definition lists&lt;/a&gt;&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;ineffable&lt;/span&gt;
&lt;span class="o"&gt;:&lt;/span&gt;   &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;property&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;being&lt;/span&gt; &lt;span class="n"&gt;undefinable&lt;/span&gt;

&lt;span class="n"&gt;ambisinistrous&lt;/span&gt;
&lt;span class="o"&gt;:&lt;/span&gt;   &lt;span class="n"&gt;equally&lt;/span&gt; &lt;span class="n"&gt;clumsy&lt;/span&gt; &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;both&lt;/span&gt; &lt;span class="n"&gt;hands&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;from&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;Latin&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="err"&gt;`&lt;/span&gt;&lt;span class="n"&gt;both&lt;/span&gt; &lt;span class="n"&gt;left&lt;/span&gt;&lt;span class="err"&gt;`&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;dl&gt;
&lt;dt&gt;ineffable&lt;/dt&gt;
&lt;dd&gt;the property of being undefinable&lt;/dd&gt;
&lt;dt&gt;ambisinistrous&lt;/dt&gt;
&lt;dd&gt;equally clumsy with both hands, from &lt;em&gt;Latin&lt;/em&gt; `both left'&lt;/dd&gt;
&lt;/dl&gt;
&lt;hr&gt;
&lt;h3 id="wzxhzdk45wzxhzdk46fenced-code-blocks-and-syntax-highlighting"&gt;&lt;a id = "code"&gt;&lt;/a&gt;&lt;a href="http://pythonhosted.org/Markdown/extensions/fenced_code_blocks.html"&gt;Fenced Code Blocks&lt;/a&gt; and &lt;a href="http://pythonhosted.org/Markdown/extensions/code_hilite.html"&gt;syntax highlighting&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Core Markdown syntax uses
&lt;a href="http://daringfireball.net/projects/markdown/syntax#precode"&gt;indenting&lt;/a&gt;
for code blocks. John Gruber's documentation says:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;To produce a code block in Markdown, simply indent every line of the block by at least 4 spaces or 1 tab. &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;but Python Markdown extensions allow
&lt;a href="http://pythonhosted.org/Markdown/extensions/fenced_code_blocks.html"&gt;fenced code blocks&lt;/a&gt;,
which play nice with list indentation. From the &lt;a href="http://pythonhosted.org/Markdown/extensions/fenced_code_blocks.html"&gt;documentation&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Fenced code blocks can have a blank line as the first and/or last line of a code block and they can also come immediately after a list item without becoming part of the list.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h5 id="fenced-code-blocks"&gt;Fenced code blocks&lt;/h5&gt;
&lt;p&gt;With &lt;code&gt;~~~~{.python} ... ~~~~&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;~~~~{.python} # block open (don&amp;#39;t include this comment in your code)
# python code
print &amp;#39;Hello world&amp;#39;
~~~~ # block close (don&amp;#39;t include this comment in your code)
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# python code&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;Hello world&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;With Github-flavored backticks: &lt;code&gt;```python ... ```&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;```python # block open (don&amp;#39;t include this comment in your code)
# python code
print &amp;#39;Hello world&amp;#39;
``` # block close (don&amp;#39;t include this comment in your code)
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# python code&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;Hello world&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h4 id="syntax-highlighting"&gt;Syntax highlighting&lt;/h4&gt;
&lt;p&gt;Syntax highlighting is enabled by default in Pelican with the
    extension
    &lt;a href="http://pythonhosted.org/Markdown/extensions/code_hilite.html"&gt;&lt;code&gt;CodeHilite&lt;/code&gt;&lt;/a&gt;,
    which uses the Python syntax highlighter
    &lt;a href="http://pygments.org/"&gt;Pygments&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You can &lt;strong&gt;have line numbers shown&lt;/strong&gt; if the first line contains a
&lt;a href="http://www.in-ulm.de/~mascheck/various/shebang/"&gt;shebang&lt;/a&gt;, &lt;code&gt;#!&lt;/code&gt;. Here's an example with a fenced code block:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;~~~~ # opening fence (don&amp;#39;t include this comment in your code)
#!/usr/bin/python
# python code, line numbers and shebang line shown
print &amp;#39;Hello world&amp;#39;
~~~~ # closing fence (don&amp;#39;t include this comment in your code)
&lt;/pre&gt;&lt;/div&gt;


&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt;1
2
3&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!/usr/bin/python&lt;/span&gt;
&lt;span class="c1"&gt;# python code, line numbers and shebang line shown&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;Hello world&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

&lt;p&gt;And here's an example with line numbers shown using an indented code block:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    #!/usr/bin/python
    # python code, line numbers and shebang line shown
    print &amp;#39;Hello world&amp;#39;
&lt;/pre&gt;&lt;/div&gt;


&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt;1
2
3&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!/usr/bin/python&lt;/span&gt;
&lt;span class="c1"&gt;# python code, line numbers and shebang line shown&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;Hello world&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;Without a path in the shebang line, i.e. &lt;code&gt;#!python&lt;/code&gt; the shebang line
is removed. So there are only 2 lines in the code below, not 3.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;~~~~ # opening fence (don&amp;#39;t include this comment in your code)
#!python
# python code, line numbers and shebang line not shown
print &amp;#39;Hello world&amp;#39;
~~~~ # closing fence (don&amp;#39;t include this comment in your code)
&lt;/pre&gt;&lt;/div&gt;


&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt;1
2&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# python code, line numbers and shebang line shown&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;Hello world&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;For &lt;strong&gt;no&lt;/strong&gt; line numbers, and without the first line being displayed,
you can use a triple colon, &lt;code&gt;:::python&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Here's an example with a fenced code block:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;~~~~ # opening fence (don&amp;#39;t include this comment in your code)
:::python
# python code, no line numbers, first line not shown
print &amp;#39;Hello world&amp;#39;
~~~~ # closing fence (don&amp;#39;t include this comment in your code)
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# python code, no line numbers, first line not shown&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;Hello world&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And here's an example with an indented code block:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    :::python
    # python code, no line numbers, first line not shown
    print &amp;#39;Hello world&amp;#39;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# python code, no line numbers, first line not shown&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;Hello world&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h4 id="syntax-highlighting-languages-supported-by-pygments"&gt;Syntax highlighting: languages supported by pygments&lt;/h4&gt;
&lt;p&gt;The &lt;a href="http://pygments.org/languages/"&gt;list of supported languages&lt;/a&gt;
includes Awk, C, C++, F#, Haskell, Java, Javascript, Matlab,
Octave, OCaml, Prolog, Python,  S/S+/R, Bash shell scripts,
Gnuplot scripts, HTML, MySQL, TeX, XML. Here is a table of some
&lt;a href="http://pygments.org/docs/lexers/"&gt;shortnames&lt;/a&gt; for some lexers for
languages I use or could imagine using:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Lexer&lt;/th&gt;
&lt;th&gt;shortname&lt;/th&gt;
&lt;th&gt;file extensions&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;Python3Lexer&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;python3, py3&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;PythonLexer&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;python, py&lt;/td&gt;
&lt;td&gt;*.py, *.pyw, *.sc, SConstruct, SConscript, *.tac, *.sage&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;PythonConsoleLexer&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;pycon&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;PrologLexer&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;prolog&lt;/td&gt;
&lt;td&gt;*.prolog, *.pro, *.pl&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;CommonLispLexer&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;common-lisp, cl, lisp&lt;/td&gt;
&lt;td&gt;*.cl, *.lisp, *.el&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;CoqLexer&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;coq&lt;/td&gt;
&lt;td&gt;*.v&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;OcamlLexer&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;ocaml&lt;/td&gt;
&lt;td&gt;*.ml, *.mli, *.mll, *.mly&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;SchemeLexer&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;scheme, scm&lt;/td&gt;
&lt;td&gt;*.scm, *.ss&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;MatlabLexer&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;matlab&lt;/td&gt;
&lt;td&gt;*.m&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;MatlabSessionLexer&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;matlabsession&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;NumPyLexer&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;numpy&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;OctaveLexer&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;octave&lt;/td&gt;
&lt;td&gt;*.m&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;RConsoleLexer&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;rconsole, rout&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;SLexer&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;splus, s, r&lt;/td&gt;
&lt;td&gt;*.S, *.R, .Rhistory, .Rprofile&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;AwkLexer&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;awk, gawk, mawk, nawk&lt;/td&gt;
&lt;td&gt;*.awk&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;GnuplotLexer&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;gnuplot&lt;/td&gt;
&lt;td&gt;*.plot, *.plt&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;BashLexer&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;bash, sh, ksh&lt;/td&gt;
&lt;td&gt;*.sh, *.ksh, *.bash, *.ebuild, *.eclass, .bashrc, bashrc, .bash\&lt;em&gt;, bash\&lt;/em&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;BashSessionLexer&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;console&lt;/td&gt;
&lt;td&gt;*.sh-session&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;ShellSessionLexer&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;shell-session&lt;/td&gt;
&lt;td&gt;*.shell-session&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;TextLexer&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;text&lt;/td&gt;
&lt;td&gt;*.txt&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;MySqlLexer&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;mysql&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;IrcLogsLexer&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;irc&lt;/td&gt;
&lt;td&gt;*.weechatlog&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;MakefileLexer&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;make, makefile, mf, bsdmake&lt;/td&gt;
&lt;td&gt;*.mak, Makefile, makefile, Makefile.*, GNUmakefile&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;TexLexer&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;tex, latex&lt;/td&gt;
&lt;td&gt;*.tex, *.aux, *.toc&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;CssLexer&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;css&lt;/td&gt;
&lt;td&gt;*.css&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;HtmlLexer&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;html&lt;/td&gt;
&lt;td&gt;*.html, *.htm, *.xhtml, *.xslt&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Some R with &lt;code&gt;~~~~ {.R}&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# R code&lt;/span&gt;
a &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;8&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
b &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
variable &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kp"&gt;rbind&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;a&lt;span class="p"&gt;,&lt;/span&gt;b&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Some Matlab, using &lt;code&gt;```matlab&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# &lt;span class="n"&gt;MATLAB&lt;/span&gt; &lt;span class="n"&gt;code&lt;/span&gt;
&lt;span class="c"&gt;% praat call was successful, return F0 values&lt;/span&gt;
&lt;span class="n"&gt;F0&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;datalen&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;NaN&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; 

&lt;span class="n"&gt;fid&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="n"&gt;fopen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f0file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;rt&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

&lt;span class="c"&gt;% read the rest&lt;/span&gt;
&lt;span class="n"&gt;C&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="n"&gt;textscan&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fid&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;%f %f&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;delimiter&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;\n&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;TreatAsEmpty&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;--undefined--&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="n"&gt;fclose&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fid&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

&lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="p"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;round&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;  &lt;span class="c"&gt;% time locations from praat pitch track&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;A bash session:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gp"&gt;#&lt;/span&gt; Extract from output of cat &lt;span class="nb"&gt;command&lt;/span&gt; after flip line ending conversion
&lt;span class="go"&gt;amoebe@moebius :: cat 20111215-2-kiy-ap-framedwordlist.txt.unix&lt;/span&gt;
&lt;span class="go"&gt;item    word.1  word.2  verb    gloss.1 gloss.2 gloss.verb  tone.1  tone.2  bitone  sent.kiy    sent.eng&lt;/span&gt;
&lt;span class="go"&gt;1   kE  ndE fuwa    ant centipede   sees    T1  T1  T1.T1   kE ndE fuwa.    The ant sees the centipede.&lt;/span&gt;
&lt;span class="go"&gt;2   kE  fa  fuwa    ant younger.sibling sees    T1  T2  T1.T2   kE fa fuwa. The ant sees the younger.sibling.&lt;/span&gt;
&lt;span class="go"&gt;3   kE  nO  fuwa    ant meat    sees    T1  T2  T1.T2   kE nO fuwa. The ant sees the meat.&lt;/span&gt;
&lt;span class="go"&gt;4   kE  fO  fuwa    ant wallaby sees    T1  T3  T1.T3   kE fO fuwa. The ant sees the wallaby.&lt;/span&gt;
&lt;span class="go"&gt;5   kE  fO  fuwa    ant honeybee    sees    T1  T3  T1.T3   kE fO fuwa. The ant sees the honeybee.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;hr&gt;
&lt;h2 id="wzxhzdk49wzxhzdk50-latex"&gt;&lt;a id = "latex"&gt;&lt;/a&gt; $\LaTeX$&lt;/h2&gt;
&lt;p&gt;The Pelican $\LaTeX$
&lt;a href="https://github.com/getpelican/pelican-plugins/tree/master/latex"&gt;plug-in&lt;/a&gt;
uses &lt;a href="http://www.mathjax.org/"&gt;MathJaX&lt;/a&gt;. &lt;strong&gt;Update: 04/2015: the latex
plugin is deprecated and has been superseded by the
&lt;a href="https://github.com/getpelican/pelican-plugins/tree/master/render_math"&gt;render_math plug-in&lt;/a&gt;.&lt;/strong&gt; Here is a list of
&lt;a href="http://www.onemathematicalcat.org/MathJaxDocumentation/TeXSyntax.htm"&gt;available commands&lt;/a&gt;. It
seems that you need to type &lt;code&gt;\\&lt;/code&gt; for &lt;code&gt;\&lt;/code&gt;. Some more MathJaX
troubleshooting tips are &lt;a href="http://www.wikidot.com/doc:math"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;```latex
Here is an in-line equation $\sqrt{3x-1}+(1+x)^2$ in the body of the text.
```
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Here is an in-line equation $\sqrt{3x-1}+(1+x)^2$ in the body of the text.&lt;/p&gt;
&lt;p&gt;Here is an equation:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="s"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;\left&lt;/span&gt;&lt;span class="nb"&gt; &lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="nb"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nb"&gt; &lt;/span&gt;&lt;span class="nv"&gt;\frac&lt;/span&gt;&lt;span class="nb"&gt;{&lt;/span&gt;&lt;span class="nv"&gt;\hbar&lt;/span&gt;&lt;span class="nb"&gt;^&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="nb"&gt;}{&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="nb"&gt; m} &lt;/span&gt;&lt;span class="nv"&gt;\frac&lt;/span&gt;&lt;span class="nb"&gt;{&lt;/span&gt;&lt;span class="nv"&gt;\partial&lt;/span&gt;&lt;span class="nb"&gt;^&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="nb"&gt;}{&lt;/span&gt;&lt;span class="nv"&gt;\partial&lt;/span&gt;&lt;span class="nb"&gt; x^&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="nb"&gt;} &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nb"&gt; V &lt;/span&gt;&lt;span class="nv"&gt;\right&lt;/span&gt;&lt;span class="nb"&gt; &lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="nb"&gt; &lt;/span&gt;&lt;span class="nv"&gt;\Psi&lt;/span&gt;&lt;span class="nb"&gt;&lt;/span&gt;
&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt; i &lt;/span&gt;&lt;span class="nv"&gt;\hbar&lt;/span&gt;&lt;span class="nb"&gt; &lt;/span&gt;&lt;span class="nv"&gt;\frac&lt;/span&gt;&lt;span class="nb"&gt;{&lt;/span&gt;&lt;span class="nv"&gt;\partial&lt;/span&gt;&lt;span class="nb"&gt;}{&lt;/span&gt;&lt;span class="nv"&gt;\partial&lt;/span&gt;&lt;span class="nb"&gt; t} &lt;/span&gt;&lt;span class="nv"&gt;\Psi&lt;/span&gt;&lt;span class="s"&gt;$&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;$\left [ - \frac{\hbar^2}{2 m} \frac{\partial^2}{\partial x^2} + V \right ] \Psi
= i \hbar \frac{\partial}{\partial t} \Psi$&lt;/p&gt;
&lt;p&gt;You can use the &lt;code&gt;array&lt;/code&gt; environment for tables, since the &lt;code&gt;tabular&lt;/code&gt;
environment is
&lt;a href="http://meta.math.stackexchange.com/questions/2016/tabular-in-mathjax"&gt;not supported by MathJaX&lt;/a&gt;. There's
an
&lt;a href="https://groups.google.com/forum/#!msg/mathjax-users/4btEfmThia0/GqH99mEZGLwJ"&gt;example of an &lt;code&gt;array&lt;/code&gt; environment substitute&lt;/a&gt;
at the MathJax Google Group, repeated here:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="s"&gt;$&lt;/span&gt;&lt;span class="nb"&gt;&lt;/span&gt;
&lt;span class="nv"&gt;\newcommand\\&lt;/span&gt;&lt;span class="nb"&gt;T{&lt;/span&gt;&lt;span class="nv"&gt;\\&lt;/span&gt;&lt;span class="nb"&gt;Rule{&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="nb"&gt;pt}{&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="nb"&gt;em}{.&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="nb"&gt;em}}&lt;/span&gt;
&lt;span class="nv"&gt;\\&lt;/span&gt;&lt;span class="nb"&gt;begin{array}{|c|c|}&lt;/span&gt;
&lt;span class="nv"&gt;\\&lt;/span&gt;&lt;span class="nb"&gt;hline X &amp;amp; P&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;X &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt; i&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;&lt;span class="nb"&gt; &lt;/span&gt;&lt;span class="nv"&gt;\\&lt;/span&gt;&lt;span class="nb"&gt;T &lt;/span&gt;&lt;span class="nv"&gt;\\\\\\&lt;/span&gt;&lt;span class="nb"&gt;hline&lt;/span&gt;
&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="nb"&gt; &lt;/span&gt;&lt;span class="nv"&gt;\\&lt;/span&gt;&lt;span class="nb"&gt;T &amp;amp; &lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="m"&gt;6&lt;/span&gt;&lt;span class="nb"&gt; &lt;/span&gt;&lt;span class="nv"&gt;\\\\\\&lt;/span&gt;&lt;span class="nb"&gt;hline&lt;/span&gt;
&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="nb"&gt; &lt;/span&gt;&lt;span class="nv"&gt;\\&lt;/span&gt;&lt;span class="nb"&gt;T &amp;amp; &lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="m"&gt;6&lt;/span&gt;&lt;span class="nb"&gt; &lt;/span&gt;&lt;span class="nv"&gt;\\\\\\&lt;/span&gt;&lt;span class="nb"&gt;hline&lt;/span&gt;
&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="nb"&gt; &lt;/span&gt;&lt;span class="nv"&gt;\\&lt;/span&gt;&lt;span class="nb"&gt;T &amp;amp; &lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="m"&gt;6&lt;/span&gt;&lt;span class="nb"&gt; &lt;/span&gt;&lt;span class="nv"&gt;\\\\\\&lt;/span&gt;&lt;span class="nb"&gt;hline&lt;/span&gt;
&lt;span class="m"&gt;4&lt;/span&gt;&lt;span class="nb"&gt; &lt;/span&gt;&lt;span class="nv"&gt;\\&lt;/span&gt;&lt;span class="nb"&gt;T &amp;amp; &lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="m"&gt;6&lt;/span&gt;&lt;span class="nb"&gt; &lt;/span&gt;&lt;span class="nv"&gt;\\\\\\&lt;/span&gt;&lt;span class="nb"&gt;hline&lt;/span&gt;
&lt;span class="m"&gt;5&lt;/span&gt;&lt;span class="nb"&gt; &lt;/span&gt;&lt;span class="nv"&gt;\\&lt;/span&gt;&lt;span class="nb"&gt;T &amp;amp; &lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="m"&gt;6&lt;/span&gt;&lt;span class="nb"&gt; &lt;/span&gt;&lt;span class="nv"&gt;\\\\\\&lt;/span&gt;&lt;span class="nb"&gt;hline&lt;/span&gt;
&lt;span class="m"&gt;6&lt;/span&gt;&lt;span class="nb"&gt; &lt;/span&gt;&lt;span class="nv"&gt;\\&lt;/span&gt;&lt;span class="nb"&gt;T &amp;amp; &lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="m"&gt;6&lt;/span&gt;&lt;span class="nb"&gt; &lt;/span&gt;&lt;span class="nv"&gt;\\\\\\&lt;/span&gt;&lt;span class="nb"&gt;hline&lt;/span&gt;
&lt;span class="nv"&gt;\\&lt;/span&gt;&lt;span class="nb"&gt;end{array}&lt;/span&gt;
&lt;span class="s"&gt;$&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;$
\newcommand\T{\Rule{0pt}{1em}{.3em}}
\begin{array}{|c|c|}
\hline X &amp;amp; P(X = i) \T \\\hline
1 \T &amp;amp; 1/6 \\\hline
2 \T &amp;amp; 1/6 \\\hline
3 \T &amp;amp; 1/6 \\\hline
4 \T &amp;amp; 1/6 \\\hline
5 \T &amp;amp; 1/6 \\\hline
6 \T &amp;amp; 1/6 \\\hline
\end{array}
$&lt;/p&gt;
&lt;p&gt;Another &lt;code&gt;array&lt;/code&gt; environment table
&lt;a href="http://math.stackexchange.com/questions/15008/sum-of-series-fracxkn-k#15026"&gt;example&lt;/a&gt;
from &lt;a href="math.stackexchange.com"&gt;math.stackexchange.com&lt;/a&gt; is shown below:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="s"&gt;$&lt;/span&gt;&lt;span class="nb"&gt;&lt;/span&gt;
&lt;span class="nv"&gt;\\&lt;/span&gt;&lt;span class="nb"&gt;begin{array}{ccc}x&amp;amp;S&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;n,x&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;&lt;span class="nb"&gt;&amp;amp;x^n&lt;/span&gt;
&lt;span class="nv"&gt;\\&lt;/span&gt;&lt;span class="nb"&gt;log&lt;/span&gt;&lt;span class="nv"&gt;\\&lt;/span&gt;&lt;span class="nb"&gt;left&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;\\&lt;/span&gt;&lt;span class="nb"&gt;frac{x}{x&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="nb"&gt;}&lt;/span&gt;&lt;span class="nv"&gt;\\&lt;/span&gt;&lt;span class="nb"&gt;right&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;&lt;span class="nv"&gt;\\\\&lt;/span&gt;&lt;span class="nb"&gt;&lt;/span&gt;
&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="m"&gt;5&lt;/span&gt;&lt;span class="nb"&gt;&amp;amp;&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="m"&gt;1780484&lt;/span&gt;&lt;span class="nb"&gt;.&lt;/span&gt;&lt;span class="m"&gt;04&lt;/span&gt;&lt;span class="nb"&gt;&amp;amp;&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="m"&gt;1780483&lt;/span&gt;&lt;span class="nb"&gt;.&lt;/span&gt;&lt;span class="m"&gt;95&lt;/span&gt;&lt;span class="nv"&gt;\\\\&lt;/span&gt;&lt;span class="nb"&gt;&lt;/span&gt;
&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="nb"&gt;&amp;amp;&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="m"&gt;16987&lt;/span&gt;&lt;span class="nb"&gt;.&lt;/span&gt;&lt;span class="m"&gt;42&lt;/span&gt;&lt;span class="nb"&gt;&amp;amp;&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="m"&gt;16987&lt;/span&gt;&lt;span class="nb"&gt;.&lt;/span&gt;&lt;span class="m"&gt;34&lt;/span&gt;&lt;span class="nv"&gt;\\\\&lt;/span&gt;&lt;span class="nb"&gt;&lt;/span&gt;
&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="nb"&gt;&amp;amp;&lt;/span&gt;&lt;span class="m"&gt;709&lt;/span&gt;&lt;span class="nb"&gt;.&lt;/span&gt;&lt;span class="m"&gt;598&lt;/span&gt;&lt;span class="nb"&gt;&amp;amp;&lt;/span&gt;&lt;span class="m"&gt;709&lt;/span&gt;&lt;span class="nb"&gt;.&lt;/span&gt;&lt;span class="m"&gt;783&lt;/span&gt;&lt;span class="nv"&gt;\\\\&lt;/span&gt;&lt;span class="nb"&gt;&lt;/span&gt;
&lt;span class="m"&gt;4&lt;/span&gt;&lt;span class="nb"&gt;&amp;amp;&lt;/span&gt;&lt;span class="m"&gt;301656&lt;/span&gt;&lt;span class="nb"&gt;.&lt;/span&gt;&lt;span class="m"&gt;39&lt;/span&gt;&lt;span class="nb"&gt;&amp;amp;&lt;/span&gt;&lt;span class="m"&gt;301656&lt;/span&gt;&lt;span class="nb"&gt;.&lt;/span&gt;&lt;span class="m"&gt;52&lt;/span&gt;&lt;span class="nv"&gt;\\\\&lt;/span&gt;&lt;span class="nb"&gt;&lt;/span&gt;
&lt;span class="m"&gt;6&lt;/span&gt;&lt;span class="nb"&gt;&amp;amp;&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="nb"&gt;.&lt;/span&gt;&lt;span class="m"&gt;102428722&lt;/span&gt;&lt;span class="nb"&gt; &lt;/span&gt;&lt;span class="nv"&gt;\\&lt;/span&gt;&lt;span class="nb"&gt;times &lt;/span&gt;&lt;span class="m"&gt;10&lt;/span&gt;&lt;span class="nb"&gt;^&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;&lt;span class="nb"&gt;&amp;amp;&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="nb"&gt;.&lt;/span&gt;&lt;span class="m"&gt;102428734&lt;/span&gt;&lt;span class="nb"&gt; &lt;/span&gt;&lt;span class="nv"&gt;\\&lt;/span&gt;&lt;span class="nb"&gt;times&lt;/span&gt;
&lt;span class="m"&gt;10&lt;/span&gt;&lt;span class="nb"&gt;^&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;&lt;span class="nb"&gt;&lt;/span&gt;
&lt;span class="nv"&gt;\\&lt;/span&gt;&lt;span class="nb"&gt;end{array}&lt;/span&gt;
&lt;span class="s"&gt;$&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;$
\begin{array}{ccc}x&amp;amp;S(n,x)&amp;amp;x^n
\log\left(\frac{x}{x-1}\right)\\
-5&amp;amp;-1780484.04&amp;amp;-1780483.95\\
-3&amp;amp;-16987.42&amp;amp;-16987.34\\
2&amp;amp;709.598&amp;amp;709.783\\
4&amp;amp;301656.39&amp;amp;301656.52\\
6&amp;amp;1.102428722 \times 10^7&amp;amp;1.102428734 \times
10^7
\end{array}
$&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn-1"&gt;
&lt;p&gt;Whoa, is this some embedding?&amp;#160;&lt;a class="footnote-backref" href="#fnref-1" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="coding"></category><category term="markdown"></category><category term="tutorial"></category></entry></feed>